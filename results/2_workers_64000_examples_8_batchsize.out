2021-12-03 20:17:45.117450: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/lang/Python/3.7.2-intel-2018.5.274/lib:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib64:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib:/opt/apps/software/math/GMP/6.1.2-GCCcore-6.3.0/lib:/opt/apps/software/tools/XZ/5.2.4-GCCcore-6.3.0/lib:/opt/apps/software/devel/SQLite/3.27.2-GCCcore-6.3.0/lib:/opt/apps/software/lang/Tcl/8.6.9-GCCcore-6.3.0/lib:/opt/apps/software/devel/ncurses/6.1-intel-2018.5.274/lib:/opt/apps/software/lib/libreadline/7.0-GCCcore-6.3.0/lib:/opt/apps/software/lib/zlib/1.2.11-GCCcore-6.3.0/lib:/opt/apps/software/tools/bzip2/1.0.6/lib:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/mkl/lib/intel64:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/lib/intel64:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/lib64:/opt/apps/software/lib/libfabric/1.9.1/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/tbb/lib/intel64/gcc4.4:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/tools/binutils/2.26-GCCcore-6.3.0/lib:/opt/apps/software/compiler/GCCcore/6.3.0/lib/gcc/x86_64-pc-linux-gnu/6.3.0:/opt/apps/software/compiler/GCCcore/6.3.0/lib64:/opt/apps/software/compiler/GCCcore/6.3.0/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/mic/lib
2021-12-03 20:17:45.117556: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-03 20:17:45.219322: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/lang/Python/3.7.2-intel-2018.5.274/lib:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib64:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib:/opt/apps/software/math/GMP/6.1.2-GCCcore-6.3.0/lib:/opt/apps/software/tools/XZ/5.2.4-GCCcore-6.3.0/lib:/opt/apps/software/devel/SQLite/3.27.2-GCCcore-6.3.0/lib:/opt/apps/software/lang/Tcl/8.6.9-GCCcore-6.3.0/lib:/opt/apps/software/devel/ncurses/6.1-intel-2018.5.274/lib:/opt/apps/software/lib/libreadline/7.0-GCCcore-6.3.0/lib:/opt/apps/software/lib/zlib/1.2.11-GCCcore-6.3.0/lib:/opt/apps/software/tools/bzip2/1.0.6/lib:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/mkl/lib/intel64:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/lib/intel64:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/lib64:/opt/apps/software/lib/libfabric/1.9.1/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/tbb/lib/intel64/gcc4.4:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/tools/binutils/2.26-GCCcore-6.3.0/lib:/opt/apps/software/compiler/GCCcore/6.3.0/lib/gcc/x86_64-pc-linux-gnu/6.3.0:/opt/apps/software/compiler/GCCcore/6.3.0/lib64:/opt/apps/software/compiler/GCCcore/6.3.0/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/mic/lib
2021-12-03 20:17:45.219521: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-03 20:17:49.397636: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/lang/Python/3.7.2-intel-2018.5.274/lib:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib64:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib:/opt/apps/software/math/GMP/6.1.2-GCCcore-6.3.0/lib:/opt/apps/software/tools/XZ/5.2.4-GCCcore-6.3.0/lib:/opt/apps/software/devel/SQLite/3.27.2-GCCcore-6.3.0/lib:/opt/apps/software/lang/Tcl/8.6.9-GCCcore-6.3.0/lib:/opt/apps/software/devel/ncurses/6.1-intel-2018.5.274/lib:/opt/apps/software/lib/libreadline/7.0-GCCcore-6.3.0/lib:/opt/apps/software/lib/zlib/1.2.11-GCCcore-6.3.0/lib:/opt/apps/software/tools/bzip2/1.0.6/lib:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/mkl/lib/intel64:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/lib/intel64:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/lib64:/opt/apps/software/lib/libfabric/1.9.1/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/tbb/lib/intel64/gcc4.4:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/tools/binutils/2.26-GCCcore-6.3.0/lib:/opt/apps/software/compiler/GCCcore/6.3.0/lib/gcc/x86_64-pc-linux-gnu/6.3.0:/opt/apps/software/compiler/GCCcore/6.3.0/lib64:/opt/apps/software/compiler/GCCcore/6.3.0/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/mic/lib
2021-12-03 20:17:49.406704: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-03 20:17:49.406772: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node-0001): /proc/driver/nvidia/version does not exist
2021-12-03 20:17:49.434520: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2021-12-03 20:17:49.434572: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: gpu-0001
2021-12-03 20:17:49.434586: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: gpu-0001
2021-12-03 20:17:49.434655: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 465.19.1
2021-12-03 20:17:49.434726: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 465.19.1
2021-12-03 20:17:49.434738: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 465.19.1
2021-12-03 20:17:49.435432: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
===========
rank: 0
Batch size: 8
Total number of batches: 8000
Total training examples: 64000
Num of workers: 2
===========
Step #0 (total examples = 0)	Loss: 2.327902
Step #10 (total examples = 80)	Loss: 2.178617
Step #20 (total examples = 160)	Loss: 1.189939
Step #30 (total examples = 240)	Loss: 0.322823
Step #40 (total examples = 320)	Loss: 0.600417
Step #50 (total examples = 400)	Loss: 0.718660
Step #60 (total examples = 480)	Loss: 0.466255
Step #70 (total examples = 560)	Loss: 0.181745
Step #80 (total examples = 640)	Loss: 0.936022
Step #90 (total examples = 720)	Loss: 0.232881
Step #100 (total examples = 800)	Loss: 0.314292
Step #110 (total examples = 880)	Loss: 0.231428
Step #120 (total examples = 960)	Loss: 0.132322
Step #130 (total examples = 1040)	Loss: 0.317915
Step #140 (total examples = 1120)	Loss: 0.892948
Step #150 (total examples = 1200)	Loss: 0.150919
Step #160 (total examples = 1280)	Loss: 0.043748
Step #170 (total examples = 1360)	Loss: 0.042679
Step #180 (total examples = 1440)	Loss: 1.306178
Step #190 (total examples = 1520)	Loss: 0.195501
Step #200 (total examples = 1600)	Loss: 0.740960
Step #210 (total examples = 1680)	Loss: 0.187876
Step #220 (total examples = 1760)	Loss: 0.139282
Step #230 (total examples = 1840)	Loss: 0.052160
Step #240 (total examples = 1920)	Loss: 0.002084
Step #250 (total examples = 2000)	Loss: 0.089098
Step #260 (total examples = 2080)	Loss: 0.727090
Step #270 (total examples = 2160)	Loss: 0.260931
Step #280 (total examples = 2240)	Loss: 0.113698
Step #290 (total examples = 2320)	Loss: 0.014965
Step #300 (total examples = 2400)	Loss: 0.307695
Step #310 (total examples = 2480)	Loss: 0.017038
Step #320 (total examples = 2560)	Loss: 0.414474
Step #330 (total examples = 2640)	Loss: 0.945055
Step #340 (total examples = 2720)	Loss: 0.658731
Step #350 (total examples = 2800)	Loss: 0.137742
Step #360 (total examples = 2880)	Loss: 0.195912
Step #370 (total examples = 2960)	Loss: 0.455103
Step #380 (total examples = 3040)	Loss: 0.411566
Step #390 (total examples = 3120)	Loss: 0.015163
Step #400 (total examples = 3200)	Loss: 0.019613
Step #410 (total examples = 3280)	Loss: 0.314762
Step #420 (total examples = 3360)	Loss: 0.315374
Step #430 (total examples = 3440)	Loss: 0.011675
Step #440 (total examples = 3520)	Loss: 0.421751
Step #450 (total examples = 3600)	Loss: 0.016912
Step #460 (total examples = 3680)	Loss: 0.023233
Step #470 (total examples = 3760)	Loss: 0.168015
Step #480 (total examples = 3840)	Loss: 0.066568
Step #490 (total examples = 3920)	Loss: 1.138764
Step #500 (total examples = 4000)	Loss: 0.024223
Step #510 (total examples = 4080)	Loss: 0.100743
Step #520 (total examples = 4160)	Loss: 0.042996
Step #530 (total examples = 4240)	Loss: 0.112573
Step #540 (total examples = 4320)	Loss: 0.018317
Step #550 (total examples = 4400)	Loss: 0.066637
Step #560 (total examples = 4480)	Loss: 0.297876
Step #570 (total examples = 4560)	Loss: 0.048867
Step #580 (total examples = 4640)	Loss: 0.069804
Step #590 (total examples = 4720)	Loss: 0.053995
Step #600 (total examples = 4800)	Loss: 0.341564
Step #610 (total examples = 4880)	Loss: 0.046053
Step #620 (total examples = 4960)	Loss: 0.123374
Step #630 (total examples = 5040)	Loss: 0.055254
Step #640 (total examples = 5120)	Loss: 0.255841
Step #650 (total examples = 5200)	Loss: 0.030018
Step #660 (total examples = 5280)	Loss: 0.141785
Step #670 (total examples = 5360)	Loss: 0.020206
Step #680 (total examples = 5440)	Loss: 0.227328
Step #690 (total examples = 5520)	Loss: 0.049037
Step #700 (total examples = 5600)	Loss: 0.038815
Step #710 (total examples = 5680)	Loss: 0.051504
Step #720 (total examples = 5760)	Loss: 0.125921
Step #730 (total examples = 5840)	Loss: 0.032158
Step #740 (total examples = 5920)	Loss: 0.019841
Step #750 (total examples = 6000)	Loss: 0.041581
Step #760 (total examples = 6080)	Loss: 0.064746
Step #770 (total examples = 6160)	Loss: 0.081629
Step #780 (total examples = 6240)	Loss: 0.087484
Step #790 (total examples = 6320)	Loss: 0.006052
Step #800 (total examples = 6400)	Loss: 0.416759
Step #810 (total examples = 6480)	Loss: 0.103105
Step #820 (total examples = 6560)	Loss: 0.210577
Step #830 (total examples = 6640)	Loss: 0.136767
Step #840 (total examples = 6720)	Loss: 0.211273
Step #850 (total examples = 6800)	Loss: 0.021902
Step #860 (total examples = 6880)	Loss: 0.060117
Step #870 (total examples = 6960)	Loss: 0.036283
Step #880 (total examples = 7040)	Loss: 0.018535
Step #890 (total examples = 7120)	Loss: 0.015483
Step #900 (total examples = 7200)	Loss: 0.025723
Step #910 (total examples = 7280)	Loss: 0.099423
Step #920 (total examples = 7360)	Loss: 0.023744
Step #930 (total examples = 7440)	Loss: 0.011097
Step #940 (total examples = 7520)	Loss: 0.092525
Step #950 (total examples = 7600)	Loss: 0.007908
Step #960 (total examples = 7680)	Loss: 0.086199
Step #970 (total examples = 7760)	Loss: 0.580729
Step #980 (total examples = 7840)	Loss: 0.006163
Step #990 (total examples = 7920)	Loss: 0.279386
Step #1000 (total examples = 8000)	Loss: 0.029741
Step #1010 (total examples = 8080)	Loss: 0.040203
Step #1020 (total examples = 8160)	Loss: 0.002500
Step #1030 (total examples = 8240)	Loss: 0.375062
Step #1040 (total examples = 8320)	Loss: 0.182138
Step #1050 (total examples = 8400)	Loss: 0.011626
Step #1060 (total examples = 8480)	Loss: 0.015553
Step #1070 (total examples = 8560)	Loss: 0.109909
Step #1080 (total examples = 8640)	Loss: 0.224253
Step #1090 (total examples = 8720)	Loss: 0.014163
Step #1100 (total examples = 8800)	Loss: 0.004484
Step #1110 (total examples = 8880)	Loss: 0.079264
Step #1120 (total examples = 8960)	Loss: 0.007721
Step #1130 (total examples = 9040)	Loss: 0.023560
Step #1140 (total examples = 9120)	Loss: 0.019615
Step #1150 (total examples = 9200)	Loss: 0.085682
Step #1160 (total examples = 9280)	Loss: 0.008565
Step #1170 (total examples = 9360)	Loss: 0.301271
Step #1180 (total examples = 9440)	Loss: 0.045572
Step #1190 (total examples = 9520)	Loss: 0.055613
Step #1200 (total examples = 9600)	Loss: 0.047164
Step #1210 (total examples = 9680)	Loss: 0.056674
Step #1220 (total examples = 9760)	Loss: 0.085608
Step #1230 (total examples = 9840)	Loss: 0.029502
Step #1240 (total examples = 9920)	Loss: 0.244982
Step #1250 (total examples = 10000)	Loss: 0.047699
Step #1260 (total examples = 10080)	Loss: 0.187824
Step #1270 (total examples = 10160)	Loss: 0.005535
Step #1280 (total examples = 10240)	Loss: 0.000857
Step #1290 (total examples = 10320)	Loss: 0.065151
Step #1300 (total examples = 10400)	Loss: 0.120323
Step #1310 (total examples = 10480)	Loss: 0.000585
Step #1320 (total examples = 10560)	Loss: 0.190563
Step #1330 (total examples = 10640)	Loss: 0.004670
Step #1340 (total examples = 10720)	Loss: 0.003324
Step #1350 (total examples = 10800)	Loss: 0.208453
Step #1360 (total examples = 10880)	Loss: 0.017759
Step #1370 (total examples = 10960)	Loss: 0.151265
Step #1380 (total examples = 11040)	Loss: 0.147695
Step #1390 (total examples = 11120)	Loss: 0.012046
Step #1400 (total examples = 11200)	Loss: 0.052628
Step #1410 (total examples = 11280)	Loss: 0.349347
Step #1420 (total examples = 11360)	Loss: 0.004680
Step #1430 (total examples = 11440)	Loss: 0.017095
Step #1440 (total examples = 11520)	Loss: 0.153455
Step #1450 (total examples = 11600)	Loss: 0.192178
Step #1460 (total examples = 11680)	Loss: 0.035169
Step #1470 (total examples = 11760)	Loss: 0.015410
Step #1480 (total examples = 11840)	Loss: 0.152311
Step #1490 (total examples = 11920)	Loss: 0.025118
Step #1500 (total examples = 12000)	Loss: 0.032036
Step #1510 (total examples = 12080)	Loss: 0.000347
Step #1520 (total examples = 12160)	Loss: 0.017364
Step #1530 (total examples = 12240)	Loss: 0.004572
Step #1540 (total examples = 12320)	Loss: 0.004201
Step #1550 (total examples = 12400)	Loss: 0.759275
Step #1560 (total examples = 12480)	Loss: 0.000587
Step #1570 (total examples = 12560)	Loss: 0.005782
Step #1580 (total examples = 12640)	Loss: 0.023506
Step #1590 (total examples = 12720)	Loss: 0.020424
Step #1600 (total examples = 12800)	Loss: 0.002267
Step #1610 (total examples = 12880)	Loss: 0.229989
Step #1620 (total examples = 12960)	Loss: 0.001278
Step #1630 (total examples = 13040)	Loss: 0.019892===========
rank: 1
===========
Step #0 (total examples = 0)	Loss: 2.290018
Step #10 (total examples = 80)	Loss: 2.292623
Step #20 (total examples = 160)	Loss: 0.637614
Step #30 (total examples = 240)	Loss: 0.954576
Step #40 (total examples = 320)	Loss: 1.135082
Step #50 (total examples = 400)	Loss: 0.385529
Step #60 (total examples = 480)	Loss: 0.379344
Step #70 (total examples = 560)	Loss: 1.006738
Step #80 (total examples = 640)	Loss: 0.786668
Step #90 (total examples = 720)	Loss: 0.449074
Step #100 (total examples = 800)	Loss: 0.190675
Step #110 (total examples = 880)	Loss: 0.147055
Step #120 (total examples = 960)	Loss: 0.372300
Step #130 (total examples = 1040)	Loss: 0.120714
Step #140 (total examples = 1120)	Loss: 0.070425
Step #150 (total examples = 1200)	Loss: 0.164187
Step #160 (total examples = 1280)	Loss: 0.390715
Step #170 (total examples = 1360)	Loss: 0.495637
Step #180 (total examples = 1440)	Loss: 0.234767
Step #190 (total examples = 1520)	Loss: 0.114251
Step #200 (total examples = 1600)	Loss: 0.809105
Step #210 (total examples = 1680)	Loss: 0.054277
Step #220 (total examples = 1760)	Loss: 0.039124
Step #230 (total examples = 1840)	Loss: 0.497824
Step #240 (total examples = 1920)	Loss: 0.032974
Step #250 (total examples = 2000)	Loss: 0.136935
Step #260 (total examples = 2080)	Loss: 0.175030
Step #270 (total examples = 2160)	Loss: 0.154314
Step #280 (total examples = 2240)	Loss: 0.130301
Step #290 (total examples = 2320)	Loss: 0.510988
Step #300 (total examples = 2400)	Loss: 0.375484
Step #310 (total examples = 2480)	Loss: 0.075313
Step #320 (total examples = 2560)	Loss: 1.140759
Step #330 (total examples = 2640)	Loss: 0.978860
Step #340 (total examples = 2720)	Loss: 0.131771
Step #350 (total examples = 2800)	Loss: 0.049368
Step #360 (total examples = 2880)	Loss: 0.066672
Step #370 (total examples = 2960)	Loss: 0.010859
Step #380 (total examples = 3040)	Loss: 0.025361
Step #390 (total examples = 3120)	Loss: 0.035592
Step #400 (total examples = 3200)	Loss: 0.473801
Step #410 (total examples = 3280)	Loss: 0.283127
Step #420 (total examples = 3360)	Loss: 0.054005
Step #430 (total examples = 3440)	Loss: 0.036390
Step #440 (total examples = 3520)	Loss: 0.559785
Step #450 (total examples = 3600)	Loss: 0.135638
Step #460 (total examples = 3680)	Loss: 0.050691
Step #470 (total examples = 3760)	Loss: 0.133237
Step #480 (total examples = 3840)	Loss: 0.517879
Step #490 (total examples = 3920)	Loss: 0.128090
Step #500 (total examples = 4000)	Loss: 0.119502
Step #510 (total examples = 4080)	Loss: 0.084402
Step #520 (total examples = 4160)	Loss: 0.353101
Step #530 (total examples = 4240)	Loss: 0.021488
Step #540 (total examples = 4320)	Loss: 0.117918
Step #550 (total examples = 4400)	Loss: 0.032842
Step #560 (total examples = 4480)	Loss: 0.148233
Step #570 (total examples = 4560)	Loss: 0.150525
Step #580 (total examples = 4640)	Loss: 0.045970
Step #590 (total examples = 4720)	Loss: 0.308258
Step #600 (total examples = 4800)	Loss: 0.898518
Step #610 (total examples = 4880)	Loss: 0.107380
Step #620 (total examples = 4960)	Loss: 0.129031
Step #630 (total examples = 5040)	Loss: 0.003251
Step #640 (total examples = 5120)	Loss: 0.057245
Step #650 (total examples = 5200)	Loss: 0.008519
Step #660 (total examples = 5280)	Loss: 0.041083
Step #670 (total examples = 5360)	Loss: 0.245295
Step #680 (total examples = 5440)	Loss: 0.021210
Step #690 (total examples = 5520)	Loss: 0.008870
Step #700 (total examples = 5600)	Loss: 0.011807
Step #710 (total examples = 5680)	Loss: 0.299975
Step #720 (total examples = 5760)	Loss: 0.011701
Step #730 (total examples = 5840)	Loss: 1.248744
Step #740 (total examples = 5920)	Loss: 0.097754
Step #750 (total examples = 6000)	Loss: 0.517624
Step #760 (total examples = 6080)	Loss: 0.038566
Step #770 (total examples = 6160)	Loss: 0.098076
Step #780 (total examples = 6240)	Loss: 0.720161
Step #790 (total examples = 6320)	Loss: 0.134395
Step #800 (total examples = 6400)	Loss: 0.208439
Step #810 (total examples = 6480)	Loss: 0.212230
Step #820 (total examples = 6560)	Loss: 0.010938
Step #830 (total examples = 6640)	Loss: 0.026880
Step #840 (total examples = 6720)	Loss: 0.056406
Step #850 (total examples = 6800)	Loss: 0.023516
Step #860 (total examples = 6880)	Loss: 0.006316
Step #870 (total examples = 6960)	Loss: 0.051654
Step #880 (total examples = 7040)	Loss: 0.015654
Step #890 (total examples = 7120)	Loss: 0.002879
Step #900 (total examples = 7200)	Loss: 0.129211
Step #910 (total examples = 7280)	Loss: 0.082550
Step #920 (total examples = 7360)	Loss: 0.268184
Step #930 (total examples = 7440)	Loss: 0.035614
Step #940 (total examples = 7520)	Loss: 0.111682
Step #950 (total examples = 7600)	Loss: 0.410222
Step #960 (total examples = 7680)	Loss: 0.000962
Step #970 (total examples = 7760)	Loss: 0.046244
Step #980 (total examples = 7840)	Loss: 0.062514
Step #990 (total examples = 7920)	Loss: 0.054245
Step #1000 (total examples = 8000)	Loss: 0.340868
Step #1010 (total examples = 8080)	Loss: 0.161440
Step #1020 (total examples = 8160)	Loss: 0.089575
Step #1030 (total examples = 8240)	Loss: 0.009972
Step #1040 (total examples = 8320)	Loss: 0.073969
Step #1050 (total examples = 8400)	Loss: 0.079344
Step #1060 (total examples = 8480)	Loss: 0.016562
Step #1070 (total examples = 8560)	Loss: 0.046355
Step #1080 (total examples = 8640)	Loss: 0.138920
Step #1090 (total examples = 8720)	Loss: 0.006295
Step #1100 (total examples = 8800)	Loss: 0.169784
Step #1110 (total examples = 8880)	Loss: 0.313878
Step #1120 (total examples = 8960)	Loss: 0.000173
Step #1130 (total examples = 9040)	Loss: 0.092889
Step #1140 (total examples = 9120)	Loss: 0.337633
Step #1150 (total examples = 9200)	Loss: 0.018905
Step #1160 (total examples = 9280)	Loss: 0.145732
Step #1170 (total examples = 9360)	Loss: 0.030163
Step #1180 (total examples = 9440)	Loss: 0.134436
Step #1190 (total examples = 9520)	Loss: 0.011934
Step #1200 (total examples = 9600)	Loss: 0.017261
Step #1210 (total examples = 9680)	Loss: 0.005313
Step #1220 (total examples = 9760)	Loss: 0.005894
Step #1230 (total examples = 9840)	Loss: 0.840178
Step #1240 (total examples = 9920)	Loss: 0.318206
Step #1250 (total examples = 10000)	Loss: 0.041596
Step #1260 (total examples = 10080)	Loss: 0.104682
Step #1270 (total examples = 10160)	Loss: 0.072379
Step #1280 (total examples = 10240)	Loss: 0.046729
Step #1290 (total examples = 10320)	Loss: 0.030814
Step #1300 (total examples = 10400)	Loss: 0.001265
Step #1310 (total examples = 10480)	Loss: 0.009618
Step #1320 (total examples = 10560)	Loss: 0.035353
Step #1330 (total examples = 10640)	Loss: 0.069616
Step #1340 (total examples = 10720)	Loss: 0.044451
Step #1350 (total examples = 10800)	Loss: 0.018500
Step #1360 (total examples = 10880)	Loss: 0.038407
Step #1370 (total examples = 10960)	Loss: 0.707167
Step #1380 (total examples = 11040)	Loss: 0.103804
Step #1390 (total examples = 11120)	Loss: 0.096814
Step #1400 (total examples = 11200)	Loss: 0.014925
Step #1410 (total examples = 11280)	Loss: 1.006621
Step #1420 (total examples = 11360)	Loss: 0.010554
Step #1430 (total examples = 11440)	Loss: 0.063179
Step #1440 (total examples = 11520)	Loss: 0.127344
Step #1450 (total examples = 11600)	Loss: 0.001221
Step #1460 (total examples = 11680)	Loss: 0.021342
Step #1470 (total examples = 11760)	Loss: 0.001272
Step #1480 (total examples = 11840)	Loss: 0.014481
Step #1490 (total examples = 11920)	Loss: 0.050847
Step #1500 (total examples = 12000)	Loss: 0.016078
Step #1510 (total examples = 12080)	Loss: 0.003085
Step #1520 (total examples = 12160)	Loss: 0.017515
Step #1530 (total examples = 12240)	Loss: 0.058612
Step #1540 (total examples = 12320)	Loss: 0.785692
Step #1550 (total examples = 12400)	Loss: 0.016755
Step #1560 (total examples = 12480)	Loss: 0.000579
Step #1570 (total examples = 12560)	Loss: 0.443716
Step #1580 (total examples = 12640)	Loss: 0.062101
Step #1590 (total examples = 12720)	Loss: 0.001213
Step #1600 (total examples = 12800)	Loss: 0.034383
Step #1610 (total examples = 12880)	Loss: 0.045611
Step #1620 (total examples = 12960)	Loss: 0.440243
Step #1630 (total examples = 13040)	Loss: 0.032424
Step #1640 (total examples = 13120)	Loss: 0.007940
Step #1640 (total examples = 13120)	Loss: 0.517246
Step #1650 (total examples = 13200)	Loss: 0.176103
Step #1660 (total examples = 13280)	Loss: 0.124903
Step #1670 (total examples = 13360)	Loss: 0.005252
Step #1680 (total examples = 13440)	Loss: 0.145349
Step #1690 (total examples = 13520)	Loss: 0.009980
Step #1700 (total examples = 13600)	Loss: 0.088938
Step #1710 (total examples = 13680)	Loss: 0.045048
Step #1720 (total examples = 13760)	Loss: 0.005466
Step #1730 (total examples = 13840)	Loss: 0.033922
Step #1740 (total examples = 13920)	Loss: 0.381794
Step #1750 (total examples = 14000)	Loss: 0.103998
Step #1760 (total examples = 14080)	Loss: 0.013452
Step #1770 (total examples = 14160)	Loss: 0.001036
Step #1780 (total examples = 14240)	Loss: 0.105282
Step #1790 (total examples = 14320)	Loss: 0.004449
Step #1800 (total examples = 14400)	Loss: 0.005297
Step #1810 (total examples = 14480)	Loss: 0.002515
Step #1820 (total examples = 14560)	Loss: 0.002967
Step #1830 (total examples = 14640)	Loss: 0.005820
Step #1840 (total examples = 14720)	Loss: 0.095062
Step #1850 (total examples = 14800)	Loss: 0.004054
Step #1860 (total examples = 14880)	Loss: 0.012774
Step #1870 (total examples = 14960)	Loss: 0.000903
Step #1880 (total examples = 15040)	Loss: 0.002408
Step #1890 (total examples = 15120)	Loss: 0.338320
Step #1900 (total examples = 15200)	Loss: 0.050750
Step #1910 (total examples = 15280)	Loss: 0.055936
Step #1920 (total examples = 15360)	Loss: 0.020674
Step #1930 (total examples = 15440)	Loss: 0.015616
Step #1940 (total examples = 15520)	Loss: 0.003191
Step #1950 (total examples = 15600)	Loss: 0.003680
Step #1960 (total examples = 15680)	Loss: 0.033866
Step #1970 (total examples = 15760)	Loss: 0.011904
Step #1980 (total examples = 15840)	Loss: 0.081927
Step #1990 (total examples = 15920)	Loss: 0.006850
Step #2000 (total examples = 16000)	Loss: 0.002539
Step #2010 (total examples = 16080)	Loss: 0.896281
Step #2020 (total examples = 16160)	Loss: 0.004698
Step #2030 (total examples = 16240)	Loss: 0.189889
Step #2040 (total examples = 16320)	Loss: 0.023595
Step #2050 (total examples = 16400)	Loss: 0.000175
Step #2060 (total examples = 16480)	Loss: 0.027947
Step #2070 (total examples = 16560)	Loss: 0.127257
Step #2080 (total examples = 16640)	Loss: 0.005288
Step #2090 (total examples = 16720)	Loss: 0.000432
Step #2100 (total examples = 16800)	Loss: 0.002763
Step #2110 (total examples = 16880)	Loss: 0.015081
Step #2120 (total examples = 16960)	Loss: 0.385707
Step #2130 (total examples = 17040)	Loss: 0.009893
Step #2140 (total examples = 17120)	Loss: 0.003185
Step #2150 (total examples = 17200)	Loss: 0.017205
Step #2160 (total examples = 17280)	Loss: 0.010231
Step #2170 (total examples = 17360)	Loss: 0.000280
Step #2180 (total examples = 17440)	Loss: 0.000643
Step #2190 (total examples = 17520)	Loss: 0.012328
Step #2200 (total examples = 17600)	Loss: 0.066343
Step #2210 (total examples = 17680)	Loss: 0.499263
Step #2220 (total examples = 17760)	Loss: 0.000529
Step #2230 (total examples = 17840)	Loss: 0.272626
Step #2240 (total examples = 17920)	Loss: 0.005230
Step #2250 (total examples = 18000)	Loss: 0.129122
Step #2260 (total examples = 18080)	Loss: 0.040103
Step #2270 (total examples = 18160)	Loss: 0.007111
Step #2280 (total examples = 18240)	Loss: 0.009997
Step #2290 (total examples = 18320)	Loss: 0.002867
Step #2300 (total examples = 18400)	Loss: 0.068452
Step #2310 (total examples = 18480)	Loss: 0.321411
Step #2320 (total examples = 18560)	Loss: 0.090830
Step #2330 (total examples = 18640)	Loss: 0.033591
Step #2340 (total examples = 18720)	Loss: 0.000673
Step #2350 (total examples = 18800)	Loss: 0.021572
Step #2360 (total examples = 18880)	Loss: 0.007284
Step #2370 (total examples = 18960)	Loss: 0.163739
Step #2380 (total examples = 19040)	Loss: 0.001201
Step #2390 (total examples = 19120)	Loss: 0.048256
Step #2400 (total examples = 19200)	Loss: 0.391219
Step #2410 (total examples = 19280)	Loss: 0.035918
Step #2420 (total examples = 19360)	Loss: 0.035898
Step #2430 (total examples = 19440)	Loss: 0.006585
Step #2440 (total examples = 19520)	Loss: 0.003445
Step #2450 (total examples = 19600)	Loss: 0.036232
Step #2460 (total examples = 19680)	Loss: 0.013529
Step #2470 (total examples = 19760)	Loss: 0.035932
Step #2480 (total examples = 19840)	Loss: 0.007987
Step #2490 (total examples = 19920)	Loss: 0.176647
Step #2500 (total examples = 20000)	Loss: 0.108210
Step #2510 (total examples = 20080)	Loss: 0.002924
Step #2520 (total examples = 20160)	Loss: 0.000918
Step #2530 (total examples = 20240)	Loss: 0.392502
Step #2540 (total examples = 20320)	Loss: 0.158954
Step #2550 (total examples = 20400)	Loss: 0.064460
Step #2560 (total examples = 20480)	Loss: 0.142883
Step #2570 (total examples = 20560)	Loss: 0.035479
Step #2580 (total examples = 20640)	Loss: 0.004051
Step #2590 (total examples = 20720)	Loss: 0.269105
Step #2600 (total examples = 20800)	Loss: 0.000636
Step #2610 (total examples = 20880)	Loss: 0.000690
Step #2620 (total examples = 20960)	Loss: 0.011015
Step #2630 (total examples = 21040)	Loss: 0.033664
Step #2640 (total examples = 21120)	Loss: 0.079404
Step #2650 (total examples = 21200)	Loss: 0.048417
Step #2660 (total examples = 21280)	Loss: 0.032719
Step #2670 (total examples = 21360)	Loss: 0.304513
Step #2680 (total examples = 21440)	Loss: 0.298718
Step #2690 (total examples = 21520)	Loss: 0.146195
Step #2700 (total examples = 21600)	Loss: 0.005408
Step #2710 (total examples = 21680)	Loss: 0.028769
Step #2720 (total examples = 21760)	Loss: 0.004390
Step #2730 (total examples = 21840)	Loss: 0.002259
Step #2740 (total examples = 21920)	Loss: 0.001022
Step #2750 (total examples = 22000)	Loss: 0.003264
Step #2760 (total examples = 22080)	Loss: 0.000481
Step #2770 (total examples = 22160)	Loss: 0.001733
Step #2780 (total examples = 22240)	Loss: 0.032891
Step #2790 (total examples = 22320)	Loss: 0.001791
Step #2800 (total examples = 22400)	Loss: 0.016106
Step #2810 (total examples = 22480)	Loss: 0.085737
Step #2820 (total examples = 22560)	Loss: 0.018624
Step #2830 (total examples = 22640)	Loss: 0.300415
Step #2840 (total examples = 22720)	Loss: 0.002346
Step #2850 (total examples = 22800)	Loss: 0.012111
Step #2860 (total examples = 22880)	Loss: 0.115525
Step #2870 (total examples = 22960)	Loss: 0.332868
Step #2880 (total examples = 23040)	Loss: 0.053902
Step #2890 (total examples = 23120)	Loss: 0.028679
Step #2900 (total examples = 23200)	Loss: 0.027016
Step #2910 (total examples = 23280)	Loss: 0.011178
Step #2920 (total examples = 23360)	Loss: 0.317705
Step #2930 (total examples = 23440)	Loss: 0.011698
Step #2940 (total examples = 23520)	Loss: 0.023637
Step #2950 (total examples = 23600)	Loss: 0.004629
Step #2960 (total examples = 23680)	Loss: 0.056403
Step #2970 (total examples = 23760)	Loss: 0.007903
Step #2980 (total examples = 23840)	Loss: 0.000897
Step #2990 (total examples = 23920)	Loss: 0.002083
Step #3000 (total examples = 24000)	Loss: 0.114660
Step #3010 (total examples = 24080)	Loss: 0.066449
Step #3020 (total examples = 24160)	Loss: 0.132415
Step #3030 (total examples = 24240)	Loss: 0.000328
Step #3040 (total examples = 24320)	Loss: 0.001260
Step #3050 (total examples = 24400)	Loss: 0.004346
Step #3060 (total examples = 24480)	Loss: 0.004321
Step #3070 (total examples = 24560)	Loss: 0.527079
Step #3080 (total examples = 24640)	Loss: 0.039019
Step #3090 (total examples = 24720)	Loss: 0.006414
Step #3100 (total examples = 24800)	Loss: 0.239022
Step #3110 (total examples = 24880)	Loss: 0.032379
Step #3120 (total examples = 24960)	Loss: 0.000965
Step #3130 (total examples = 25040)	Loss: 0.064623
Step #3140 (total examples = 25120)	Loss: 0.084390
Step #3150 (total examples = 25200)	Loss: 0.652592
Step #3160 (total examples = 25280)	Loss: 0.000532
Step #3170 (total examples = 25360)	Loss: 0.014962
Step #3180 (total examples = 25440)	Loss: 0.542404
Step #3190 (total examples = 25520)	Loss: 0.029155
Step #3200 (total examples = 25600)	Loss: 0.016058
Step #3210 (total examples = 25680)	Loss: 0.001577
Step #3220 (total examples = 25760)	Loss: 0.000228
Step #3230 (total examples = 25840)	Loss: 0.425454
Step #3240 (total examples = 25920)	Loss: 0.013971
Step #1650 (total examples = 13200)	Loss: 0.867043
Step #1660 (total examples = 13280)	Loss: 0.274082
Step #1670 (total examples = 13360)	Loss: 0.313709
Step #1680 (total examples = 13440)	Loss: 0.067471
Step #1690 (total examples = 13520)	Loss: 0.478864
Step #1700 (total examples = 13600)	Loss: 0.057294
Step #1710 (total examples = 13680)	Loss: 0.309411
Step #1720 (total examples = 13760)	Loss: 0.001717
Step #1730 (total examples = 13840)	Loss: 0.413309
Step #1740 (total examples = 13920)	Loss: 0.010005
Step #1750 (total examples = 14000)	Loss: 0.363284
Step #1760 (total examples = 14080)	Loss: 0.000226
Step #1770 (total examples = 14160)	Loss: 0.006022
Step #1780 (total examples = 14240)	Loss: 0.060589
Step #1790 (total examples = 14320)	Loss: 0.000448
Step #1800 (total examples = 14400)	Loss: 0.133664
Step #1810 (total examples = 14480)	Loss: 0.000157
Step #1820 (total examples = 14560)	Loss: 0.068995
Step #1830 (total examples = 14640)	Loss: 0.409707
Step #1840 (total examples = 14720)	Loss: 0.033322
Step #1850 (total examples = 14800)	Loss: 0.002830
Step #1860 (total examples = 14880)	Loss: 0.078370
Step #1870 (total examples = 14960)	Loss: 0.061240
Step #1880 (total examples = 15040)	Loss: 0.150324
Step #1890 (total examples = 15120)	Loss: 0.035419
Step #1900 (total examples = 15200)	Loss: 0.318071
Step #1910 (total examples = 15280)	Loss: 0.003720
Step #1920 (total examples = 15360)	Loss: 0.426330
Step #1930 (total examples = 15440)	Loss: 0.114819
Step #1940 (total examples = 15520)	Loss: 0.457924
Step #1950 (total examples = 15600)	Loss: 0.701603
Step #1960 (total examples = 15680)	Loss: 0.035136
Step #1970 (total examples = 15760)	Loss: 0.006705
Step #1980 (total examples = 15840)	Loss: 0.001483
Step #1990 (total examples = 15920)	Loss: 0.002248
Step #2000 (total examples = 16000)	Loss: 0.026728
Step #2010 (total examples = 16080)	Loss: 0.230677
Step #2020 (total examples = 16160)	Loss: 0.130624
Step #2030 (total examples = 16240)	Loss: 0.000014
Step #2040 (total examples = 16320)	Loss: 0.027511
Step #2050 (total examples = 16400)	Loss: 0.044012
Step #2060 (total examples = 16480)	Loss: 0.004186
Step #2070 (total examples = 16560)	Loss: 0.550120
Step #2080 (total examples = 16640)	Loss: 0.156201
Step #2090 (total examples = 16720)	Loss: 0.002043
Step #2100 (total examples = 16800)	Loss: 0.422791
Step #2110 (total examples = 16880)	Loss: 0.011961
Step #2120 (total examples = 16960)	Loss: 0.006831
Step #2130 (total examples = 17040)	Loss: 0.040483
Step #2140 (total examples = 17120)	Loss: 0.002877
Step #2150 (total examples = 17200)	Loss: 0.041161
Step #2160 (total examples = 17280)	Loss: 0.002981
Step #2170 (total examples = 17360)	Loss: 0.802973
Step #2180 (total examples = 17440)	Loss: 0.000437
Step #2190 (total examples = 17520)	Loss: 0.006279
Step #2200 (total examples = 17600)	Loss: 0.000718
Step #2210 (total examples = 17680)	Loss: 0.000925
Step #2220 (total examples = 17760)	Loss: 0.083374
Step #2230 (total examples = 17840)	Loss: 0.000777
Step #2240 (total examples = 17920)	Loss: 0.003635
Step #2250 (total examples = 18000)	Loss: 0.182108
Step #2260 (total examples = 18080)	Loss: 0.112559
Step #2270 (total examples = 18160)	Loss: 0.068492
Step #2280 (total examples = 18240)	Loss: 0.030628
Step #2290 (total examples = 18320)	Loss: 0.043711
Step #2300 (total examples = 18400)	Loss: 0.003626
Step #2310 (total examples = 18480)	Loss: 0.012535
Step #2320 (total examples = 18560)	Loss: 0.177226
Step #2330 (total examples = 18640)	Loss: 0.138223
Step #2340 (total examples = 18720)	Loss: 0.027159
Step #2350 (total examples = 18800)	Loss: 0.123655
Step #2360 (total examples = 18880)	Loss: 0.144339
Step #2370 (total examples = 18960)	Loss: 0.005670
Step #2380 (total examples = 19040)	Loss: 0.657227
Step #2390 (total examples = 19120)	Loss: 0.022278
Step #2400 (total examples = 19200)	Loss: 0.049552
Step #2410 (total examples = 19280)	Loss: 0.014595
Step #2420 (total examples = 19360)	Loss: 0.175127
Step #2430 (total examples = 19440)	Loss: 0.264716
Step #2440 (total examples = 19520)	Loss: 0.106098
Step #2450 (total examples = 19600)	Loss: 0.036916
Step #2460 (total examples = 19680)	Loss: 0.000673
Step #2470 (total examples = 19760)	Loss: 0.259793
Step #2480 (total examples = 19840)	Loss: 0.015239
Step #2490 (total examples = 19920)	Loss: 1.160437
Step #2500 (total examples = 20000)	Loss: 0.016160
Step #2510 (total examples = 20080)	Loss: 0.018790
Step #2520 (total examples = 20160)	Loss: 0.115663
Step #2530 (total examples = 20240)	Loss: 0.008899
Step #2540 (total examples = 20320)	Loss: 0.012488
Step #2550 (total examples = 20400)	Loss: 0.004706
Step #2560 (total examples = 20480)	Loss: 0.007966
Step #2570 (total examples = 20560)	Loss: 0.003107
Step #2580 (total examples = 20640)	Loss: 0.115225
Step #2590 (total examples = 20720)	Loss: 0.295723
Step #2600 (total examples = 20800)	Loss: 0.058161
Step #2610 (total examples = 20880)	Loss: 0.013309
Step #2620 (total examples = 20960)	Loss: 0.427981
Step #2630 (total examples = 21040)	Loss: 0.009586
Step #2640 (total examples = 21120)	Loss: 0.134926
Step #2650 (total examples = 21200)	Loss: 0.326533
Step #2660 (total examples = 21280)	Loss: 0.013299
Step #2670 (total examples = 21360)	Loss: 0.001210
Step #2680 (total examples = 21440)	Loss: 0.047807
Step #2690 (total examples = 21520)	Loss: 0.088491
Step #2700 (total examples = 21600)	Loss: 0.021140
Step #2710 (total examples = 21680)	Loss: 0.047912
Step #2720 (total examples = 21760)	Loss: 0.000428
Step #2730 (total examples = 21840)	Loss: 0.013896
Step #2740 (total examples = 21920)	Loss: 0.129914
Step #2750 (total examples = 22000)	Loss: 0.000738
Step #2760 (total examples = 22080)	Loss: 0.025730
Step #2770 (total examples = 22160)	Loss: 0.011794
Step #2780 (total examples = 22240)	Loss: 0.008418
Step #2790 (total examples = 22320)	Loss: 0.032489
Step #2800 (total examples = 22400)	Loss: 0.010898
Step #2810 (total examples = 22480)	Loss: 0.383331
Step #2820 (total examples = 22560)	Loss: 0.006504
Step #2830 (total examples = 22640)	Loss: 0.000723
Step #2840 (total examples = 22720)	Loss: 0.036984
Step #2850 (total examples = 22800)	Loss: 0.031308
Step #2860 (total examples = 22880)	Loss: 0.048837
Step #2870 (total examples = 22960)	Loss: 0.004350
Step #2880 (total examples = 23040)	Loss: 0.229139
Step #2890 (total examples = 23120)	Loss: 0.116388
Step #2900 (total examples = 23200)	Loss: 0.000110
Step #2910 (total examples = 23280)	Loss: 0.000020
Step #2920 (total examples = 23360)	Loss: 0.027313
Step #2930 (total examples = 23440)	Loss: 0.045493
Step #2940 (total examples = 23520)	Loss: 0.009658
Step #2950 (total examples = 23600)	Loss: 0.981774
Step #2960 (total examples = 23680)	Loss: 0.004333
Step #2970 (total examples = 23760)	Loss: 0.134882
Step #2980 (total examples = 23840)	Loss: 0.020230
Step #2990 (total examples = 23920)	Loss: 0.041185
Step #3000 (total examples = 24000)	Loss: 0.029169
Step #3010 (total examples = 24080)	Loss: 0.000474
Step #3020 (total examples = 24160)	Loss: 0.284976
Step #3030 (total examples = 24240)	Loss: 0.006876
Step #3040 (total examples = 24320)	Loss: 1.028345
Step #3050 (total examples = 24400)	Loss: 0.035607
Step #3060 (total examples = 24480)	Loss: 0.255748
Step #3070 (total examples = 24560)	Loss: 0.015709
Step #3080 (total examples = 24640)	Loss: 0.025654
Step #3090 (total examples = 24720)	Loss: 0.009125
Step #3100 (total examples = 24800)	Loss: 0.000092
Step #3110 (total examples = 24880)	Loss: 0.003508
Step #3120 (total examples = 24960)	Loss: 0.055007
Step #3130 (total examples = 25040)	Loss: 0.010303
Step #3140 (total examples = 25120)	Loss: 0.001520
Step #3150 (total examples = 25200)	Loss: 0.004828
Step #3160 (total examples = 25280)	Loss: 0.212190
Step #3170 (total examples = 25360)	Loss: 0.079138
Step #3180 (total examples = 25440)	Loss: 0.562935
Step #3190 (total examples = 25520)	Loss: 0.026524
Step #3200 (total examples = 25600)	Loss: 0.130555
Step #3210 (total examples = 25680)	Loss: 0.007580
Step #3220 (total examples = 25760)	Loss: 0.309586
Step #3230 (total examples = 25840)	Loss: 0.004343
Step #3240 (total examples = 25920)	Loss: 0.002516
Step #3250 (total examples = 26000)	Loss: 0.021627
Step #3260 (total examples = 26080)	Loss: 0.000095
Step #3270 (total examples = 26160)	Loss: 0.074105
Step #3280 (total examples = 26240)	Loss: 0.001003
Step #3290 (total examples = 26320)	Loss: 0.000528
Step #3300 (total examples = 26400)	Loss: 0.168561
Step #3310 (total examples = 26480)	Loss: 0.009620
Step #3320 (total examples = 26560)	Loss: 0.042047
Step #3330 (total examples = 26640)	Loss: 0.148428
Step #3340 (total examples = 26720)	Loss: 0.041691
Step #3350 (total examples = 26800)	Loss: 0.000828
Step #3360 (total examples = 26880)	Loss: 0.188255
Step #3370 (total examples = 26960)	Loss: 0.019939
Step #3380 (total examples = 27040)	Loss: 0.000876
Step #3390 (total examples = 27120)	Loss: 0.002802
Step #3400 (total examples = 27200)	Loss: 0.068853
Step #3410 (total examples = 27280)	Loss: 0.008400
Step #3420 (total examples = 27360)	Loss: 0.135008
Step #3430 (total examples = 27440)	Loss: 0.133470
Step #3440 (total examples = 27520)	Loss: 0.596784
Step #3450 (total examples = 27600)	Loss: 0.003121
Step #3460 (total examples = 27680)	Loss: 0.007323
Step #3470 (total examples = 27760)	Loss: 0.295467
Step #3480 (total examples = 27840)	Loss: 0.011490
Step #3490 (total examples = 27920)	Loss: 0.005417
Step #3500 (total examples = 28000)	Loss: 0.000222
Step #3510 (total examples = 28080)	Loss: 0.015788
Step #3520 (total examples = 28160)	Loss: 0.000934
Step #3530 (total examples = 28240)	Loss: 0.320674
Step #3540 (total examples = 28320)	Loss: 0.266277
Step #3550 (total examples = 28400)	Loss: 0.002628
Step #3560 (total examples = 28480)	Loss: 0.001352
Step #3570 (total examples = 28560)	Loss: 0.008426
Step #3580 (total examples = 28640)	Loss: 0.002828
Step #3590 (total examples = 28720)	Loss: 0.013825
Step #3600 (total examples = 28800)	Loss: 0.006514
Step #3610 (total examples = 28880)	Loss: 0.354795
Step #3620 (total examples = 28960)	Loss: 0.000303
Step #3630 (total examples = 29040)	Loss: 0.007554
Step #3640 (total examples = 29120)	Loss: 0.047223
Step #3650 (total examples = 29200)	Loss: 0.136625
Step #3660 (total examples = 29280)	Loss: 0.001476
Step #3670 (total examples = 29360)	Loss: 0.000122
Step #3680 (total examples = 29440)	Loss: 0.093529
Step #3690 (total examples = 29520)	Loss: 0.011015
Step #3700 (total examples = 29600)	Loss: 0.001864
Step #3710 (total examples = 29680)	Loss: 0.014273
Step #3720 (total examples = 29760)	Loss: 0.306377
Step #3730 (total examples = 29840)	Loss: 0.008564
Step #3740 (total examples = 29920)	Loss: 0.006405
Step #3750 (total examples = 30000)	Loss: 0.040660
Step #3760 (total examples = 30080)	Loss: 0.867406
Step #3770 (total examples = 30160)	Loss: 0.000212
Step #3780 (total examples = 30240)	Loss: 0.004384
Step #3790 (total examples = 30320)	Loss: 0.000248
Step #3800 (total examples = 30400)	Loss: 0.208070
Step #3810 (total examples = 30480)	Loss: 0.002646
Step #3820 (total examples = 30560)	Loss: 0.006443
Step #3830 (total examples = 30640)	Loss: 0.003814
Step #3840 (total examples = 30720)	Loss: 0.002395
Step #3850 (total examples = 30800)	Loss: 0.002911
Step #3860 (total examples = 30880)	Loss: 0.000407
Step #3870 (total examples = 30960)	Loss: 0.207460
Step #3880 (total examples = 31040)	Loss: 0.000663
Step #3890 (total examples = 31120)	Loss: 0.190645
Step #3900 (total examples = 31200)	Loss: 0.005559
Step #3910 (total examples = 31280)	Loss: 0.117852
Step #3920 (total examples = 31360)	Loss: 0.269083
Step #3930 (total examples = 31440)	Loss: 0.080911
Step #3940 (total examples = 31520)	Loss: 0.096295
Step #3950 (total examples = 31600)	Loss: 0.003067
Step #3960 (total examples = 31680)	Loss: 0.094251
Step #3970 (total examples = 31760)	Loss: 0.002795
Step #3980 (total examples = 31840)	Loss: 0.016474
Step #3990 (total examples = 31920)	Loss: 0.003372

Step #3250 (total examples = 26000)	Loss: 0.668056
Step #3260 (total examples = 26080)	Loss: 0.004546
Step #3270 (total examples = 26160)	Loss: 0.000241
Step #3280 (total examples = 26240)	Loss: 0.021943
Step #3290 (total examples = 26320)	Loss: 0.001339
Step #3300 (total examples = 26400)	Loss: 0.002061
Step #3310 (total examples = 26480)	Loss: 0.002828
Step #3320 (total examples = 26560)	Loss: 0.004160
Step #3330 (total examples = 26640)	Loss: 0.007930
Step #3340 (total examples = 26720)	Loss: 0.039345
Step #3350 (total examples = 26800)	Loss: 0.032543
Step #3360 (total examples = 26880)	Loss: 0.000820
Step #3370 (total examples = 26960)	Loss: 0.000375
Step #3380 (total examples = 27040)	Loss: 0.061909
Step #3390 (total examples = 27120)	Loss: 0.007158
Step #3400 (total examples = 27200)	Loss: 0.608097
Step #3410 (total examples = 27280)	Loss: 0.004495
Step #3420 (total examples = 27360)	Loss: 0.166248
Step #3430 (total examples = 27440)	Loss: 0.007763
Step #3440 (total examples = 27520)	Loss: 0.031647
Step #3450 (total examples = 27600)	Loss: 0.062031
Step #3460 (total examples = 27680)	Loss: 0.052528
Step #3470 (total examples = 27760)	Loss: 0.125686
Step #3480 (total examples = 27840)	Loss: 0.004378
Step #3490 (total examples = 27920)	Loss: 0.000163
Step #3500 (total examples = 28000)	Loss: 0.010298
Step #3510 (total examples = 28080)	Loss: 0.007636
Step #3520 (total examples = 28160)	Loss: 0.002344
Step #3530 (total examples = 28240)	Loss: 0.041857
Step #3540 (total examples = 28320)	Loss: 0.215703
Step #3550 (total examples = 28400)	Loss: 0.069031
Step #3560 (total examples = 28480)	Loss: 0.020808
Step #3570 (total examples = 28560)	Loss: 0.047507
Step #3580 (total examples = 28640)	Loss: 0.000777
Step #3590 (total examples = 28720)	Loss: 0.504196
Step #3600 (total examples = 28800)	Loss: 0.029044
Step #3610 (total examples = 28880)	Loss: 0.000394
Step #3620 (total examples = 28960)	Loss: 0.000086
Step #3630 (total examples = 29040)	Loss: 0.021989
Step #3640 (total examples = 29120)	Loss: 0.007193
Step #3650 (total examples = 29200)	Loss: 0.989152
Step #3660 (total examples = 29280)	Loss: 0.001696
Step #3670 (total examples = 29360)	Loss: 0.000848
Step #3680 (total examples = 29440)	Loss: 0.034270
Step #3690 (total examples = 29520)	Loss: 0.034478
Step #3700 (total examples = 29600)	Loss: 0.076182
Step #3710 (total examples = 29680)	Loss: 0.000095
Step #3720 (total examples = 29760)	Loss: 0.000356
Step #3730 (total examples = 29840)	Loss: 0.005445
Step #3740 (total examples = 29920)	Loss: 0.000309
Step #3750 (total examples = 30000)	Loss: 0.014516
Step #3760 (total examples = 30080)	Loss: 0.007121
Step #3770 (total examples = 30160)	Loss: 0.363788
Step #3780 (total examples = 30240)	Loss: 0.000737
Step #3790 (total examples = 30320)	Loss: 0.278136
Step #3800 (total examples = 30400)	Loss: 0.127099
Step #3810 (total examples = 30480)	Loss: 0.178385
Step #3820 (total examples = 30560)	Loss: 0.515519
Step #3830 (total examples = 30640)	Loss: 0.000173
Step #3840 (total examples = 30720)	Loss: 0.295465
Step #3850 (total examples = 30800)	Loss: 0.257659
Step #3860 (total examples = 30880)	Loss: 0.000439
Step #3870 (total examples = 30960)	Loss: 0.017523
Step #3880 (total examples = 31040)	Loss: 0.000194
Step #3890 (total examples = 31120)	Loss: 0.113735
Step #3900 (total examples = 31200)	Loss: 0.000637
Step #3910 (total examples = 31280)	Loss: 0.000291
Step #3920 (total examples = 31360)	Loss: 0.263653
Step #3930 (total examples = 31440)	Loss: 0.019681
Step #3940 (total examples = 31520)	Loss: 0.101727
Step #3950 (total examples = 31600)	Loss: 0.001120
Step #3960 (total examples = 31680)	Loss: 0.003602
Step #3970 (total examples = 31760)	Loss: 0.302803
Step #3980 (total examples = 31840)	Loss: 0.019859
Step #3990 (total examples = 31920)	Loss: 0.001913
  1/313 [..............................] - ETA: 1:47 - loss: 0.0000e+00 - accuracy: 1.0000  5/313 [..............................] - ETA: 4s - loss: 2.2114 - accuracy: 0.9875        9/313 [..............................] - ETA: 4s - loss: 9.8325 - accuracy: 0.9826 13/313 [>.............................] - ETA: 4s - loss: 8.5578 - accuracy: 0.9808 17/313 [>.............................] - ETA: 4s - loss: 10.4205 - accuracy: 0.9816 21/313 [=>............................] - ETA: 4s - loss: 12.1657 - accuracy: 0.9792 25/313 [=>............................] - ETA: 4s - loss: 11.5168 - accuracy: 0.9800 27/313 [=>............................] - ETA: 4s - loss: 11.3022 - accuracy: 0.9803 29/313 [=>............................] - ETA: 5s - loss: 11.2427 - accuracy: 0.9806 31/313 [=>............................] - ETA: 5s - loss: 11.4509 - accuracy: 0.9778 33/313 [==>...........................] - ETA: 5s - loss: 12.0432 - accuracy: 0.9782 35/313 [==>...........................] - ETA: 5s - loss: 11.6457 - accuracy: 0.9777 37/313 [==>...........................] - ETA: 5s - loss: 11.1272 - accuracy: 0.9780 39/313 [==>...........................] - ETA: 5s - loss: 11.6956 - accuracy: 0.9776 41/313 [==>...........................] - ETA: 5s - loss: 13.0115 - accuracy: 0.9771 43/313 [===>..........................] - ETA: 6s - loss: 13.0912 - accuracy: 0.9753 45/313 [===>..........................] - ETA: 6s - loss: 13.3736 - accuracy: 0.9757 47/313 [===>..........................] - ETA: 6s - loss: 12.9212 - accuracy: 0.9761 49/313 [===>..........................] - ETA: 6s - loss: 14.6167 - accuracy: 0.9745 51/313 [===>..........................] - ETA: 6s - loss: 14.0435 - accuracy: 0.9755 53/313 [====>.........................] - ETA: 6s - loss: 13.8033 - accuracy: 0.9758 55/313 [====>.........................] - ETA: 6s - loss: 14.1565 - accuracy: 0.9750 57/313 [====>.........................] - ETA: 6s - loss: 13.6598 - accuracy: 0.9759 60/313 [====>.........................] - ETA: 6s - loss: 13.6876 - accuracy: 0.9760 63/313 [=====>........................] - ETA: 5s - loss: 13.1879 - accuracy: 0.9767 66/313 [=====>........................] - ETA: 5s - loss: 13.8858 - accuracy: 0.9754 69/313 [=====>........................] - ETA: 5s - loss: 15.6983 - accuracy: 0.9742 72/313 [=====>........................] - ETA: 5s - loss: 15.5938 - accuracy: 0.9744 75/313 [======>.......................] - ETA: 5s - loss: 15.3404 - accuracy: 0.9742 78/313 [======>.......................] - ETA: 5s - loss: 15.2595 - accuracy: 0.9740 82/313 [======>.......................] - ETA: 5s - loss: 14.7226 - accuracy: 0.9748 85/313 [=======>......................] - ETA: 5s - loss: 15.0447 - accuracy: 0.9746 88/313 [=======>......................] - ETA: 4s - loss: 14.5318 - accuracy: 0.9755 91/313 [=======>......................] - ETA: 4s - loss: 14.5845 - accuracy: 0.9756 95/313 [========>.....................] - ETA: 4s - loss: 14.2738 - accuracy: 0.9753 99/313 [========>.....................] - ETA: 4s - loss: 13.7346 - accuracy: 0.9757103/313 [========>.....................] - ETA: 4s - loss: 13.3482 - accuracy: 0.9760107/313 [=========>....................] - ETA: 4s - loss: 13.4494 - accuracy: 0.9758111/313 [=========>....................] - ETA: 4s - loss: 14.0128 - accuracy: 0.9758115/313 [==========>...................] - ETA: 4s - loss: 13.8759 - accuracy: 0.9761119/313 [==========>...................] - ETA: 3s - loss: 14.0827 - accuracy: 0.9756123/313 [==========>...................] - ETA: 3s - loss: 14.0392 - accuracy: 0.9756127/313 [===========>..................] - ETA: 3s - loss: 14.2563 - accuracy: 0.9759131/313 [===========>..................] - ETA: 3s - loss: 14.0265 - accuracy: 0.9761135/313 [===========>..................] - ETA: 3s - loss: 13.7511 - accuracy: 0.9766139/313 [============>.................] - ETA: 3s - loss: 13.3584 - accuracy: 0.9771143/313 [============>.................] - ETA: 3s - loss: 13.5323 - accuracy: 0.9768146/313 [============>.................] - ETA: 3s - loss: 13.4627 - accuracy: 0.9771149/313 [=============>................] - ETA: 3s - loss: 13.5413 - accuracy: 0.9769152/313 [=============>................] - ETA: 3s - loss: 13.7950 - accuracy: 0.9766155/313 [=============>................] - ETA: 3s - loss: 13.6144 - accuracy: 0.9766158/313 [==============>...............] - ETA: 3s - loss: 13.3843 - accuracy: 0.9769161/313 [==============>...............] - ETA: 2s - loss: 13.1349 - accuracy: 0.9773164/313 [==============>...............] - ETA: 2s - loss: 13.0290 - accuracy: 0.9775167/313 [===============>..............] - ETA: 2s - loss: 12.9157 - accuracy: 0.9777170/313 [===============>..............] - ETA: 2s - loss: 12.6878 - accuracy: 0.9781173/313 [===============>..............] - ETA: 2s - loss: 12.4678 - accuracy: 0.9785176/313 [===============>..............] - ETA: 2s - loss: 12.2553 - accuracy: 0.9789179/313 [================>.............] - ETA: 2s - loss: 12.0499 - accuracy: 0.9792182/313 [================>.............] - ETA: 2s - loss: 11.9303 - accuracy: 0.9794185/313 [================>.............] - ETA: 2s - loss: 11.8301 - accuracy: 0.9792188/313 [=================>............] - ETA: 2s - loss: 12.3990 - accuracy: 0.9784191/313 [=================>............] - ETA: 2s - loss: 12.2043 - accuracy: 0.9787194/313 [=================>............] - ETA: 2s - loss: 12.0156 - accuracy: 0.9791197/313 [=================>............] - ETA: 2s - loss: 11.8326 - accuracy: 0.9794200/313 [==================>...........] - ETA: 2s - loss: 11.6551 - accuracy: 0.9797203/313 [==================>...........] - ETA: 2s - loss: 11.4829 - accuracy: 0.9800206/313 [==================>...........] - ETA: 2s - loss: 11.6808 - accuracy: 0.9798209/313 [===================>..........] - ETA: 1s - loss: 11.8559 - accuracy: 0.9798212/313 [===================>..........] - ETA: 1s - loss: 11.8222 - accuracy: 0.9798215/313 [===================>..........] - ETA: 1s - loss: 11.6572 - accuracy: 0.9801218/313 [===================>..........] - ETA: 1s - loss: 11.4968 - accuracy: 0.9804221/313 [====================>.........] - ETA: 1s - loss: 11.3407 - accuracy: 0.9806224/313 [====================>.........] - ETA: 1s - loss: 11.1888 - accuracy: 0.9809227/313 [====================>.........] - ETA: 1s - loss: 11.0410 - accuracy: 0.9811231/313 [=====================>........] - ETA: 1s - loss: 10.8498 - accuracy: 0.9815235/313 [=====================>........] - ETA: 1s - loss: 10.6651 - accuracy: 0.9818239/313 [=====================>........] - ETA: 1s - loss: 10.4866 - accuracy: 0.9821242/313 [======================>.......] - ETA: 1s - loss: 10.3983 - accuracy: 0.9822245/313 [======================>.......] - ETA: 1s - loss: 10.2710 - accuracy: 0.9824248/313 [======================>.......] - ETA: 1s - loss: 10.1884 - accuracy: 0.9822251/313 [=======================>......] - ETA: 1s - loss: 10.0666 - accuracy: 0.9824254/313 [=======================>......] - ETA: 1s - loss: 10.1332 - accuracy: 0.9823257/313 [=======================>......] - ETA: 1s - loss: 10.0149 - accuracy: 0.9825261/313 [========================>.....] - ETA: 0s - loss: 9.8745 - accuracy: 0.9826 265/313 [========================>.....] - ETA: 0s - loss: 9.7254 - accuracy: 0.9829269/313 [========================>.....] - ETA: 0s - loss: 9.5932 - accuracy: 0.9830273/313 [=========================>....] - ETA: 0s - loss: 9.4526 - accuracy: 0.9833277/313 [=========================>....] - ETA: 0s - loss: 9.3161 - accuracy: 0.9835281/313 [=========================>....] - ETA: 0s - loss: 9.1835 - accuracy: 0.9838285/313 [==========================>...] - ETA: 0s - loss: 9.6755 - accuracy: 0.9833289/313 [==========================>...] - ETA: 0s - loss: 9.5416 - accuracy: 0.9836293/313 [===========================>..] - ETA: 0s - loss: 9.4114 - accuracy: 0.9838297/313 [===========================>..] - ETA: 0s - loss: 9.2846 - accuracy: 0.9840301/313 [===========================>..] - ETA: 0s - loss: 9.2440 - accuracy: 0.9840305/313 [============================>.] - ETA: 0s - loss: 9.4241 - accuracy: 0.9838309/313 [============================>.] - ETA: 0s - loss: 9.5400 - accuracy: 0.9838313/313 [==============================] - ETA: 0s - loss: 9.4772 - accuracy: 0.9839313/313 [==============================] - 6s 18ms/step - loss: 9.4772 - accuracy: 0.9839
Final model accuracy: 0.983900
Total training time: 382.235455
2021-12-03 20:24:19.750554: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/lang/Python/3.7.2-intel-2018.5.274/lib:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib64:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib:/opt/apps/software/math/GMP/6.1.2-GCCcore-6.3.0/lib:/opt/apps/software/tools/XZ/5.2.4-GCCcore-6.3.0/lib:/opt/apps/software/devel/SQLite/3.27.2-GCCcore-6.3.0/lib:/opt/apps/software/lang/Tcl/8.6.9-GCCcore-6.3.0/lib:/opt/apps/software/devel/ncurses/6.1-intel-2018.5.274/lib:/opt/apps/software/lib/libreadline/7.0-GCCcore-6.3.0/lib:/opt/apps/software/lib/zlib/1.2.11-GCCcore-6.3.0/lib:/opt/apps/software/tools/bzip2/1.0.6/lib:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/mkl/lib/intel64:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/lib/intel64:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/lib64:/opt/apps/software/lib/libfabric/1.9.1/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/tbb/lib/intel64/gcc4.4:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/tools/binutils/2.26-GCCcore-6.3.0/lib:/opt/apps/software/compiler/GCCcore/6.3.0/lib/gcc/x86_64-pc-linux-gnu/6.3.0:/opt/apps/software/compiler/GCCcore/6.3.0/lib64:/opt/apps/software/compiler/GCCcore/6.3.0/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/mic/lib
2021-12-03 20:24:19.750658: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-03 20:24:19.770803: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/lang/Python/3.7.2-intel-2018.5.274/lib:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib64:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib:/opt/apps/software/math/GMP/6.1.2-GCCcore-6.3.0/lib:/opt/apps/software/tools/XZ/5.2.4-GCCcore-6.3.0/lib:/opt/apps/software/devel/SQLite/3.27.2-GCCcore-6.3.0/lib:/opt/apps/software/lang/Tcl/8.6.9-GCCcore-6.3.0/lib:/opt/apps/software/devel/ncurses/6.1-intel-2018.5.274/lib:/opt/apps/software/lib/libreadline/7.0-GCCcore-6.3.0/lib:/opt/apps/software/lib/zlib/1.2.11-GCCcore-6.3.0/lib:/opt/apps/software/tools/bzip2/1.0.6/lib:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/mkl/lib/intel64:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/lib/intel64:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/lib64:/opt/apps/software/lib/libfabric/1.9.1/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/tbb/lib/intel64/gcc4.4:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/tools/binutils/2.26-GCCcore-6.3.0/lib:/opt/apps/software/compiler/GCCcore/6.3.0/lib/gcc/x86_64-pc-linux-gnu/6.3.0:/opt/apps/software/compiler/GCCcore/6.3.0/lib64:/opt/apps/software/compiler/GCCcore/6.3.0/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/mic/lib
2021-12-03 20:24:19.770955: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-03 20:24:23.395211: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2021-12-03 20:24:23.395387: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: gpu-0001
2021-12-03 20:24:23.395438: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: gpu-0001
2021-12-03 20:24:23.395541: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 465.19.1
2021-12-03 20:24:23.395631: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 465.19.1
2021-12-03 20:24:23.395677: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 465.19.1
2021-12-03 20:24:23.396651: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-03 20:24:23.412455: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/lang/Python/3.7.2-intel-2018.5.274/lib:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib64:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib:/opt/apps/software/math/GMP/6.1.2-GCCcore-6.3.0/lib:/opt/apps/software/tools/XZ/5.2.4-GCCcore-6.3.0/lib:/opt/apps/software/devel/SQLite/3.27.2-GCCcore-6.3.0/lib:/opt/apps/software/lang/Tcl/8.6.9-GCCcore-6.3.0/lib:/opt/apps/software/devel/ncurses/6.1-intel-2018.5.274/lib:/opt/apps/software/lib/libreadline/7.0-GCCcore-6.3.0/lib:/opt/apps/software/lib/zlib/1.2.11-GCCcore-6.3.0/lib:/opt/apps/software/tools/bzip2/1.0.6/lib:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/mkl/lib/intel64:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/lib/intel64:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/lib64:/opt/apps/software/lib/libfabric/1.9.1/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/tbb/lib/intel64/gcc4.4:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/tools/binutils/2.26-GCCcore-6.3.0/lib:/opt/apps/software/compiler/GCCcore/6.3.0/lib/gcc/x86_64-pc-linux-gnu/6.3.0:/opt/apps/software/compiler/GCCcore/6.3.0/lib64:/opt/apps/software/compiler/GCCcore/6.3.0/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/mic/lib
2021-12-03 20:24:23.412569: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-03 20:24:23.412632: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node-0001): /proc/driver/nvidia/version does not exist
===========
rank: 0
Batch size: 8
Total number of batches: 8000
Total training examples: 64000
Num of workers: 2
===========
Step #0 (total examples = 0)	Loss: 2.245382
Step #10 (total examples = 80)	Loss: 2.070405
Step #20 (total examples = 160)	Loss: 1.023697
Step #30 (total examples = 240)	Loss: 0.423784
Step #40 (total examples = 320)	Loss: 0.450500
Step #50 (total examples = 400)	Loss: 0.585007
Step #60 (total examples = 480)	Loss: 0.144091
Step #70 (total examples = 560)	Loss: 0.129058
Step #80 (total examples = 640)	Loss: 0.448115
Step #90 (total examples = 720)	Loss: 0.074627
Step #100 (total examples = 800)	Loss: 0.298664
Step #110 (total examples = 880)	Loss: 0.326256
Step #120 (total examples = 960)	Loss: 0.066893
Step #130 (total examples = 1040)	Loss: 0.088025
Step #140 (total examples = 1120)	Loss: 0.898169
Step #150 (total examples = 1200)	Loss: 0.271741
Step #160 (total examples = 1280)	Loss: 0.129444
Step #170 (total examples = 1360)	Loss: 0.030209
Step #180 (total examples = 1440)	Loss: 1.338000
Step #190 (total examples = 1520)	Loss: 0.254029
Step #200 (total examples = 1600)	Loss: 0.799794
Step #210 (total examples = 1680)	Loss: 0.303180
Step #220 (total examples = 1760)	Loss: 0.074423
Step #230 (total examples = 1840)	Loss: 0.144474
Step #240 (total examples = 1920)	Loss: 0.002268
Step #250 (total examples = 2000)	Loss: 0.278309
Step #260 (total examples = 2080)	Loss: 0.203199
Step #270 (total examples = 2160)	Loss: 0.498273
Step #280 (total examples = 2240)	Loss: 0.309812
Step #290 (total examples = 2320)	Loss: 0.054650
Step #300 (total examples = 2400)	Loss: 0.240708
Step #310 (total examples = 2480)	Loss: 0.099021
Step #320 (total examples = 2560)	Loss: 0.062007
Step #330 (total examples = 2640)	Loss: 1.336471
Step #340 (total examples = 2720)	Loss: 1.162757
Step #350 (total examples = 2800)	Loss: 0.028295
Step #360 (total examples = 2880)	Loss: 0.175690
Step #370 (total examples = 2960)	Loss: 0.459409
Step #380 (total examples = 3040)	Loss: 0.572598
Step #390 (total examples = 3120)	Loss: 0.035467
Step #400 (total examples = 3200)	Loss: 0.018375
Step #410 (total examples = 3280)	Loss: 0.227535
Step #420 (total examples = 3360)	Loss: 0.027834
Step #430 (total examples = 3440)	Loss: 0.004394
Step #440 (total examples = 3520)	Loss: 0.202904
Step #450 (total examples = 3600)	Loss: 0.826536
Step #460 (total examples = 3680)	Loss: 0.017600
Step #470 (total examples = 3760)	Loss: 0.598544
Step #480 (total examples = 3840)	Loss: 0.031534
Step #490 (total examples = 3920)	Loss: 0.877331
Step #500 (total examples = 4000)	Loss: 0.007323
Step #510 (total examples = 4080)	Loss: 0.054338
Step #520 (total examples = 4160)	Loss: 0.101024
Step #530 (total examples = 4240)	Loss: 0.135889
Step #540 (total examples = 4320)	Loss: 0.030988
Step #550 (total examples = 4400)	Loss: 0.097228
Step #560 (total examples = 4480)	Loss: 0.666798
Step #570 (total examples = 4560)	Loss: 0.007423
Step #580 (total examples = 4640)	Loss: 0.015732
Step #590 (total examples = 4720)	Loss: 0.104735
Step #600 (total examples = 4800)	Loss: 0.410288
Step #610 (total examples = 4880)	Loss: 0.045970
Step #620 (total examples = 4960)	Loss: 0.145057
Step #630 (total examples = 5040)	Loss: 0.012509
Step #640 (total examples = 5120)	Loss: 0.076630
Step #650 (total examples = 5200)	Loss: 0.053407
Step #660 (total examples = 5280)	Loss: 0.393294
Step #670 (total examples = 5360)	Loss: 0.020035
Step #680 (total examples = 5440)	Loss: 0.023211
Step #690 (total examples = 5520)	Loss: 0.005872
Step #700 (total examples = 5600)	Loss: 0.005488
Step #710 (total examples = 5680)	Loss: 0.010772
Step #720 (total examples = 5760)	Loss: 0.340427
Step #730 (total examples = 5840)	Loss: 0.013124
Step #740 (total examples = 5920)	Loss: 0.027963
Step #750 (total examples = 6000)	Loss: 0.209737
Step #760 (total examples = 6080)	Loss: 0.225534
Step #770 (total examples = 6160)	Loss: 0.007741
Step #780 (total examples = 6240)	Loss: 0.042540
Step #790 (total examples = 6320)	Loss: 0.003379
Step #800 (total examples = 6400)	Loss: 0.752092
Step #810 (total examples = 6480)	Loss: 0.004102
Step #820 (total examples = 6560)	Loss: 0.087534
Step #830 (total examples = 6640)	Loss: 0.004779
Step #840 (total examples = 6720)	Loss: 0.053476
Step #850 (total examples = 6800)	Loss: 0.445530
Step #860 (total examples = 6880)	Loss: 0.026376
Step #870 (total examples = 6960)	Loss: 0.001371
Step #880 (total examples = 7040)	Loss: 0.000788
Step #890 (total examples = 7120)	Loss: 0.084367
Step #900 (total examples = 7200)	Loss: 0.008331
Step #910 (total examples = 7280)	Loss: 0.302861
Step #920 (total examples = 7360)	Loss: 0.056811
Step #930 (total examples = 7440)	Loss: 0.089402
Step #940 (total examples = 7520)	Loss: 0.014216
Step #950 (total examples = 7600)	Loss: 0.013707
Step #960 (total examples = 7680)	Loss: 0.108902
Step #970 (total examples = 7760)	Loss: 0.171207
Step #980 (total examples = 7840)	Loss: 0.008323
Step #990 (total examples = 7920)	Loss: 0.857953
Step #1000 (total examples = 8000)	Loss: 0.007786
Step #1010 (total examples = 8080)	Loss: 0.013650
Step #1020 (total examples = 8160)	Loss: 0.003590
Step #1030 (total examples = 8240)	Loss: 0.149698
Step #1040 (total examples = 8320)	Loss: 0.014635
Step #1050 (total examples = 8400)	Loss: 0.011505
Step #1060 (total examples = 8480)	Loss: 0.103818
Step #1070 (total examples = 8560)	Loss: 0.017151
Step #1080 (total examples = 8640)	Loss: 0.051368
Step #1090 (total examples = 8720)	Loss: 0.015883
Step #1100 (total examples = 8800)	Loss: 0.073541
Step #1110 (total examples = 8880)	Loss: 0.157538
Step #1120 (total examples = 8960)	Loss: 0.001500
Step #1130 (total examples = 9040)	Loss: 0.019520
Step #1140 (total examples = 9120)	Loss: 0.030734
Step #1150 (total examples = 9200)	Loss: 0.005402
Step #1160 (total examples = 9280)	Loss: 0.030584
Step #1170 (total examples = 9360)	Loss: 0.025459
Step #1180 (total examples = 9440)	Loss: 0.011606
Step #1190 (total examples = 9520)	Loss: 0.241607
Step #1200 (total examples = 9600)	Loss: 0.026540
Step #1210 (total examples = 9680)	Loss: 0.261545
Step #1220 (total examples = 9760)	Loss: 0.075301
Step #1230 (total examples = 9840)	Loss: 0.023481
Step #1240 (total examples = 9920)	Loss: 0.102445
Step #1250 (total examples = 10000)	Loss: 0.035768
Step #1260 (total examples = 10080)	Loss: 0.031361
Step #1270 (total examples = 10160)	Loss: 0.017920
Step #1280 (total examples = 10240)	Loss: 0.021633
Step #1290 (total examples = 10320)	Loss: 0.102195
Step #1300 (total examples = 10400)	Loss: 0.468234
Step #1310 (total examples = 10480)	Loss: 0.000600
Step #1320 (total examples = 10560)	Loss: 0.040023
Step #1330 (total examples = 10640)	Loss: 0.021785
Step #1340 (total examples = 10720)	Loss: 0.004009
Step #1350 (total examples = 10800)	Loss: 0.001625
Step #1360 (total examples = 10880)	Loss: 0.051740
Step #1370 (total examples = 10960)	Loss: 0.358532
Step #1380 (total examples = 11040)	Loss: 0.101700
Step #1390 (total examples = 11120)	Loss: 0.021181
Step #1400 (total examples = 11200)	Loss: 0.044589
Step #1410 (total examples = 11280)	Loss: 0.092977
Step #1420 (total examples = 11360)	Loss: 0.020649
Step #1430 (total examples = 11440)	Loss: 0.014042
Step #1440 (total examples = 11520)	Loss: 0.025552
Step #1450 (total examples = 11600)	Loss: 0.280196
Step #1460 (total examples = 11680)	Loss: 0.000435
Step #1470 (total examples = 11760)	Loss: 0.018272
Step #1480 (total examples = 11840)	Loss: 0.068312
Step #1490 (total examples = 11920)	Loss: 0.175300
Step #1500 (total examples = 12000)	Loss: 0.012212
Step #1510 (total examples = 12080)	Loss: 0.008944
Step #1520 (total examples = 12160)	Loss: 0.555299
Step #1530 (total examples = 12240)	Loss: 0.003187
Step #1540 (total examples = 12320)	Loss: 0.169443
Step #1550 (total examples = 12400)	Loss: 0.090606
Step #1560 (total examples = 12480)	Loss: 0.012979
Step #1570 (total examples = 12560)	Loss: 0.006706
Step #1580 (total examples = 12640)	Loss: 0.584224
Step #1590 (total examples = 12720)	Loss: 0.014932
Step #1600 (total examples = 12800)	Loss: 0.006876
Step #1610 (total examples = 12880)	Loss: 0.040069
Step #1620 (total examples = 12960)	Loss: 0.000207
Step #1630 (total examples = 13040)	Loss: 0.003512===========
rank: 1
===========
Step #0 (total examples = 0)	Loss: 2.374414
Step #10 (total examples = 80)	Loss: 2.126624
Step #20 (total examples = 160)	Loss: 0.846700
Step #30 (total examples = 240)	Loss: 1.403826
Step #40 (total examples = 320)	Loss: 1.197212
Step #50 (total examples = 400)	Loss: 0.328406
Step #60 (total examples = 480)	Loss: 0.419877
Step #70 (total examples = 560)	Loss: 0.427598
Step #80 (total examples = 640)	Loss: 0.978011
Step #90 (total examples = 720)	Loss: 0.285459
Step #100 (total examples = 800)	Loss: 0.157672
Step #110 (total examples = 880)	Loss: 0.119918
Step #120 (total examples = 960)	Loss: 0.362345
Step #130 (total examples = 1040)	Loss: 0.089764
Step #140 (total examples = 1120)	Loss: 0.152944
Step #150 (total examples = 1200)	Loss: 0.035012
Step #160 (total examples = 1280)	Loss: 0.841586
Step #170 (total examples = 1360)	Loss: 0.321527
Step #180 (total examples = 1440)	Loss: 0.126039
Step #190 (total examples = 1520)	Loss: 0.283953
Step #200 (total examples = 1600)	Loss: 0.219347
Step #210 (total examples = 1680)	Loss: 0.056298
Step #220 (total examples = 1760)	Loss: 0.075457
Step #230 (total examples = 1840)	Loss: 0.648612
Step #240 (total examples = 1920)	Loss: 0.466138
Step #250 (total examples = 2000)	Loss: 0.148324
Step #260 (total examples = 2080)	Loss: 0.051361
Step #270 (total examples = 2160)	Loss: 0.233696
Step #280 (total examples = 2240)	Loss: 0.099142
Step #290 (total examples = 2320)	Loss: 0.351422
Step #300 (total examples = 2400)	Loss: 1.080490
Step #310 (total examples = 2480)	Loss: 0.100121
Step #320 (total examples = 2560)	Loss: 0.782731
Step #330 (total examples = 2640)	Loss: 0.422614
Step #340 (total examples = 2720)	Loss: 0.004817
Step #350 (total examples = 2800)	Loss: 0.291083
Step #360 (total examples = 2880)	Loss: 0.031570
Step #370 (total examples = 2960)	Loss: 0.054006
Step #380 (total examples = 3040)	Loss: 0.055060
Step #390 (total examples = 3120)	Loss: 0.152680
Step #400 (total examples = 3200)	Loss: 0.097858
Step #410 (total examples = 3280)	Loss: 0.592056
Step #420 (total examples = 3360)	Loss: 0.073196
Step #430 (total examples = 3440)	Loss: 0.029171
Step #440 (total examples = 3520)	Loss: 0.345233
Step #450 (total examples = 3600)	Loss: 0.013829
Step #460 (total examples = 3680)	Loss: 0.197145
Step #470 (total examples = 3760)	Loss: 0.061655
Step #480 (total examples = 3840)	Loss: 0.222643
Step #490 (total examples = 3920)	Loss: 0.188530
Step #500 (total examples = 4000)	Loss: 0.052466
Step #510 (total examples = 4080)	Loss: 0.034508
Step #520 (total examples = 4160)	Loss: 0.199151
Step #530 (total examples = 4240)	Loss: 0.049533
Step #540 (total examples = 4320)	Loss: 0.162879
Step #550 (total examples = 4400)	Loss: 0.007638
Step #560 (total examples = 4480)	Loss: 0.016470
Step #570 (total examples = 4560)	Loss: 0.045784
Step #580 (total examples = 4640)	Loss: 0.037746
Step #590 (total examples = 4720)	Loss: 0.011489
Step #600 (total examples = 4800)	Loss: 0.060481
Step #610 (total examples = 4880)	Loss: 0.834365
Step #620 (total examples = 4960)	Loss: 0.060845
Step #630 (total examples = 5040)	Loss: 0.017660
Step #640 (total examples = 5120)	Loss: 0.218538
Step #650 (total examples = 5200)	Loss: 0.093112
Step #660 (total examples = 5280)	Loss: 0.070971
Step #670 (total examples = 5360)	Loss: 0.095595
Step #680 (total examples = 5440)	Loss: 0.052265
Step #690 (total examples = 5520)	Loss: 0.008820
Step #700 (total examples = 5600)	Loss: 0.028287
Step #710 (total examples = 5680)	Loss: 0.120061
Step #720 (total examples = 5760)	Loss: 0.009501
Step #730 (total examples = 5840)	Loss: 0.373454
Step #740 (total examples = 5920)	Loss: 0.056018
Step #750 (total examples = 6000)	Loss: 0.590703
Step #760 (total examples = 6080)	Loss: 0.179692
Step #770 (total examples = 6160)	Loss: 0.168970
Step #780 (total examples = 6240)	Loss: 0.497765
Step #790 (total examples = 6320)	Loss: 0.068248
Step #800 (total examples = 6400)	Loss: 0.210863
Step #810 (total examples = 6480)	Loss: 0.152492
Step #820 (total examples = 6560)	Loss: 0.073982
Step #830 (total examples = 6640)	Loss: 0.039548
Step #840 (total examples = 6720)	Loss: 0.020141
Step #850 (total examples = 6800)	Loss: 0.050304
Step #860 (total examples = 6880)	Loss: 0.081665
Step #870 (total examples = 6960)	Loss: 0.021205
Step #880 (total examples = 7040)	Loss: 0.007505
Step #890 (total examples = 7120)	Loss: 0.008211
Step #900 (total examples = 7200)	Loss: 0.074737
Step #910 (total examples = 7280)	Loss: 0.030641
Step #920 (total examples = 7360)	Loss: 0.647212
Step #930 (total examples = 7440)	Loss: 0.019470
Step #940 (total examples = 7520)	Loss: 0.458969
Step #950 (total examples = 7600)	Loss: 0.265472
Step #960 (total examples = 7680)	Loss: 0.000204
Step #970 (total examples = 7760)	Loss: 0.061719
Step #980 (total examples = 7840)	Loss: 0.015952
Step #990 (total examples = 7920)	Loss: 0.008103
Step #1000 (total examples = 8000)	Loss: 0.157794
Step #1010 (total examples = 8080)	Loss: 0.146363
Step #1020 (total examples = 8160)	Loss: 0.144042
Step #1030 (total examples = 8240)	Loss: 0.019531
Step #1040 (total examples = 8320)	Loss: 0.111883
Step #1050 (total examples = 8400)	Loss: 0.003679
Step #1060 (total examples = 8480)	Loss: 0.029801
Step #1070 (total examples = 8560)	Loss: 0.108672
Step #1080 (total examples = 8640)	Loss: 0.018574
Step #1090 (total examples = 8720)	Loss: 0.001337
Step #1100 (total examples = 8800)	Loss: 0.057458
Step #1110 (total examples = 8880)	Loss: 0.037455
Step #1120 (total examples = 8960)	Loss: 0.003382
Step #1130 (total examples = 9040)	Loss: 0.075988
Step #1140 (total examples = 9120)	Loss: 0.112513
Step #1150 (total examples = 9200)	Loss: 0.179564
Step #1160 (total examples = 9280)	Loss: 0.017432
Step #1170 (total examples = 9360)	Loss: 0.034653
Step #1180 (total examples = 9440)	Loss: 0.181486
Step #1190 (total examples = 9520)	Loss: 0.006470
Step #1200 (total examples = 9600)	Loss: 0.087443
Step #1210 (total examples = 9680)	Loss: 0.090824
Step #1220 (total examples = 9760)	Loss: 0.005875
Step #1230 (total examples = 9840)	Loss: 0.190927
Step #1240 (total examples = 9920)	Loss: 0.201912
Step #1250 (total examples = 10000)	Loss: 0.001740
Step #1260 (total examples = 10080)	Loss: 0.021296
Step #1270 (total examples = 10160)	Loss: 0.074362
Step #1280 (total examples = 10240)	Loss: 0.033847
Step #1290 (total examples = 10320)	Loss: 0.171185
Step #1300 (total examples = 10400)	Loss: 0.089923
Step #1310 (total examples = 10480)	Loss: 0.010421
Step #1320 (total examples = 10560)	Loss: 0.702487
Step #1330 (total examples = 10640)	Loss: 0.002807
Step #1340 (total examples = 10720)	Loss: 0.143552
Step #1350 (total examples = 10800)	Loss: 0.312056
Step #1360 (total examples = 10880)	Loss: 0.033999
Step #1370 (total examples = 10960)	Loss: 0.041143
Step #1380 (total examples = 11040)	Loss: 0.403676
Step #1390 (total examples = 11120)	Loss: 0.235522
Step #1400 (total examples = 11200)	Loss: 0.005228
Step #1410 (total examples = 11280)	Loss: 0.027081
Step #1420 (total examples = 11360)	Loss: 0.016369
Step #1430 (total examples = 11440)	Loss: 0.074419
Step #1440 (total examples = 11520)	Loss: 0.426377
Step #1450 (total examples = 11600)	Loss: 0.009828
Step #1460 (total examples = 11680)	Loss: 0.027050
Step #1470 (total examples = 11760)	Loss: 0.001777
Step #1480 (total examples = 11840)	Loss: 0.072413
Step #1490 (total examples = 11920)	Loss: 0.185519
Step #1500 (total examples = 12000)	Loss: 0.338180
Step #1510 (total examples = 12080)	Loss: 0.045373
Step #1520 (total examples = 12160)	Loss: 0.492951
Step #1530 (total examples = 12240)	Loss: 0.116392
Step #1540 (total examples = 12320)	Loss: 0.923804
Step #1550 (total examples = 12400)	Loss: 0.023825
Step #1560 (total examples = 12480)	Loss: 0.000408
Step #1570 (total examples = 12560)	Loss: 0.263441
Step #1580 (total examples = 12640)	Loss: 0.001551
Step #1590 (total examples = 12720)	Loss: 0.006353
Step #1600 (total examples = 12800)	Loss: 0.154901
Step #1610 (total examples = 12880)	Loss: 0.087582
Step #1620 (total examples = 12960)	Loss: 0.262784
Step #1630 (total examples = 13040)	Loss: 0.001523
Step #1640 (total examples = 13120)	Loss: 0.182121
Step #1640 (total examples = 13120)	Loss: 0.527946
Step #1650 (total examples = 13200)	Loss: 0.058715
Step #1660 (total examples = 13280)	Loss: 0.004778
Step #1670 (total examples = 13360)	Loss: 0.000810
Step #1680 (total examples = 13440)	Loss: 0.002562
Step #1690 (total examples = 13520)	Loss: 0.009646
Step #1700 (total examples = 13600)	Loss: 0.005458
Step #1710 (total examples = 13680)	Loss: 0.122662
Step #1720 (total examples = 13760)	Loss: 0.013507
Step #1730 (total examples = 13840)	Loss: 0.005957
Step #1740 (total examples = 13920)	Loss: 0.930029
Step #1750 (total examples = 14000)	Loss: 0.012791
Step #1760 (total examples = 14080)	Loss: 0.039190
Step #1770 (total examples = 14160)	Loss: 0.002652
Step #1780 (total examples = 14240)	Loss: 0.063294
Step #1790 (total examples = 14320)	Loss: 0.052295
Step #1800 (total examples = 14400)	Loss: 0.027700
Step #1810 (total examples = 14480)	Loss: 0.018312
Step #1820 (total examples = 14560)	Loss: 0.004416
Step #1830 (total examples = 14640)	Loss: 0.110930
Step #1840 (total examples = 14720)	Loss: 0.008827
Step #1850 (total examples = 14800)	Loss: 0.004188
Step #1860 (total examples = 14880)	Loss: 0.012424
Step #1870 (total examples = 14960)	Loss: 0.028111
Step #1880 (total examples = 15040)	Loss: 0.002939
Step #1890 (total examples = 15120)	Loss: 0.991423
Step #1900 (total examples = 15200)	Loss: 0.013420
Step #1910 (total examples = 15280)	Loss: 0.041516
Step #1920 (total examples = 15360)	Loss: 0.172783
Step #1930 (total examples = 15440)	Loss: 0.001926
Step #1940 (total examples = 15520)	Loss: 0.054662
Step #1950 (total examples = 15600)	Loss: 0.011994
Step #1960 (total examples = 15680)	Loss: 0.156166
Step #1970 (total examples = 15760)	Loss: 0.080892
Step #1980 (total examples = 15840)	Loss: 0.145661
Step #1990 (total examples = 15920)	Loss: 0.002840
Step #2000 (total examples = 16000)	Loss: 0.240794
Step #2010 (total examples = 16080)	Loss: 0.859504
Step #2020 (total examples = 16160)	Loss: 0.102540
Step #2030 (total examples = 16240)	Loss: 0.071082
Step #2040 (total examples = 16320)	Loss: 0.000786
Step #2050 (total examples = 16400)	Loss: 0.092402
Step #2060 (total examples = 16480)	Loss: 0.038636
Step #2070 (total examples = 16560)	Loss: 0.021384
Step #2080 (total examples = 16640)	Loss: 0.010436
Step #2090 (total examples = 16720)	Loss: 0.109823
Step #2100 (total examples = 16800)	Loss: 0.001759
Step #2110 (total examples = 16880)	Loss: 0.003958
Step #2120 (total examples = 16960)	Loss: 0.030151
Step #2130 (total examples = 17040)	Loss: 0.002428
Step #2140 (total examples = 17120)	Loss: 0.010350
Step #2150 (total examples = 17200)	Loss: 0.000477
Step #2160 (total examples = 17280)	Loss: 0.000298
Step #2170 (total examples = 17360)	Loss: 0.001998
Step #2180 (total examples = 17440)	Loss: 0.004761
Step #2190 (total examples = 17520)	Loss: 0.024707
Step #2200 (total examples = 17600)	Loss: 0.001491
Step #2210 (total examples = 17680)	Loss: 0.210767
Step #2220 (total examples = 17760)	Loss: 0.001600
Step #2230 (total examples = 17840)	Loss: 0.127344
Step #2240 (total examples = 17920)	Loss: 0.001721
Step #2250 (total examples = 18000)	Loss: 0.019246
Step #2260 (total examples = 18080)	Loss: 0.059471
Step #2270 (total examples = 18160)	Loss: 0.028666
Step #2280 (total examples = 18240)	Loss: 0.007194
Step #2290 (total examples = 18320)	Loss: 0.002719
Step #2300 (total examples = 18400)	Loss: 0.089380
Step #2310 (total examples = 18480)	Loss: 0.579553
Step #2320 (total examples = 18560)	Loss: 0.009052
Step #2330 (total examples = 18640)	Loss: 0.370068
Step #2340 (total examples = 18720)	Loss: 0.005333
Step #2350 (total examples = 18800)	Loss: 0.082902
Step #2360 (total examples = 18880)	Loss: 0.027737
Step #2370 (total examples = 18960)	Loss: 0.026970
Step #2380 (total examples = 19040)	Loss: 0.024366
Step #2390 (total examples = 19120)	Loss: 0.169644
Step #2400 (total examples = 19200)	Loss: 0.338426
Step #2410 (total examples = 19280)	Loss: 0.028203
Step #2420 (total examples = 19360)	Loss: 0.220490
Step #2430 (total examples = 19440)	Loss: 0.002721
Step #2440 (total examples = 19520)	Loss: 0.010599
Step #2450 (total examples = 19600)	Loss: 0.006361
Step #2460 (total examples = 19680)	Loss: 0.120375
Step #2470 (total examples = 19760)	Loss: 0.006204
Step #2480 (total examples = 19840)	Loss: 0.056796
Step #2490 (total examples = 19920)	Loss: 0.199634
Step #2500 (total examples = 20000)	Loss: 0.005301
Step #2510 (total examples = 20080)	Loss: 0.003128
Step #2520 (total examples = 20160)	Loss: 0.001489
Step #2530 (total examples = 20240)	Loss: 0.569735
Step #2540 (total examples = 20320)	Loss: 0.036708
Step #2550 (total examples = 20400)	Loss: 0.053141
Step #2560 (total examples = 20480)	Loss: 0.137444
Step #2570 (total examples = 20560)	Loss: 0.075868
Step #2580 (total examples = 20640)	Loss: 0.002793
Step #2590 (total examples = 20720)	Loss: 0.100591
Step #2600 (total examples = 20800)	Loss: 0.037057
Step #2610 (total examples = 20880)	Loss: 0.011292
Step #2620 (total examples = 20960)	Loss: 0.034532
Step #2630 (total examples = 21040)	Loss: 0.279596
Step #2640 (total examples = 21120)	Loss: 0.006921
Step #2650 (total examples = 21200)	Loss: 0.000483
Step #2660 (total examples = 21280)	Loss: 0.011794
Step #2670 (total examples = 21360)	Loss: 0.016436
Step #2680 (total examples = 21440)	Loss: 0.117761
Step #2690 (total examples = 21520)	Loss: 0.051321
Step #2700 (total examples = 21600)	Loss: 0.001168
Step #2710 (total examples = 21680)	Loss: 0.049127
Step #2720 (total examples = 21760)	Loss: 0.006141
Step #2730 (total examples = 21840)	Loss: 0.010635
Step #2740 (total examples = 21920)	Loss: 0.026150
Step #2750 (total examples = 22000)	Loss: 0.010983
Step #2760 (total examples = 22080)	Loss: 0.012146
Step #2770 (total examples = 22160)	Loss: 0.032173
Step #2780 (total examples = 22240)	Loss: 0.009926
Step #2790 (total examples = 22320)	Loss: 0.002276
Step #2800 (total examples = 22400)	Loss: 0.038457
Step #2810 (total examples = 22480)	Loss: 0.058905
Step #2820 (total examples = 22560)	Loss: 0.018015
Step #2830 (total examples = 22640)	Loss: 0.593803
Step #2840 (total examples = 22720)	Loss: 0.001498
Step #2850 (total examples = 22800)	Loss: 0.095131
Step #2860 (total examples = 22880)	Loss: 0.153801
Step #2870 (total examples = 22960)	Loss: 0.061238
Step #2880 (total examples = 23040)	Loss: 0.029389
Step #2890 (total examples = 23120)	Loss: 0.005391
Step #2900 (total examples = 23200)	Loss: 0.096046
Step #2910 (total examples = 23280)	Loss: 0.026226
Step #2920 (total examples = 23360)	Loss: 0.268649
Step #2930 (total examples = 23440)	Loss: 0.002523
Step #2940 (total examples = 23520)	Loss: 0.016551
Step #2950 (total examples = 23600)	Loss: 0.210327
Step #2960 (total examples = 23680)	Loss: 0.160540
Step #2970 (total examples = 23760)	Loss: 0.001692
Step #2980 (total examples = 23840)	Loss: 0.003242
Step #2990 (total examples = 23920)	Loss: 0.017428
Step #3000 (total examples = 24000)	Loss: 0.222089
Step #3010 (total examples = 24080)	Loss: 0.004449
Step #3020 (total examples = 24160)	Loss: 0.029030
Step #3030 (total examples = 24240)	Loss: 0.080782
Step #3040 (total examples = 24320)	Loss: 0.005145
Step #3050 (total examples = 24400)	Loss: 0.062967
Step #3060 (total examples = 24480)	Loss: 0.001586
Step #3070 (total examples = 24560)	Loss: 0.244834
Step #3080 (total examples = 24640)	Loss: 0.006993
Step #3090 (total examples = 24720)	Loss: 0.008738
Step #3100 (total examples = 24800)	Loss: 0.130349
Step #3110 (total examples = 24880)	Loss: 0.021582
Step #3120 (total examples = 24960)	Loss: 0.076563
Step #3130 (total examples = 25040)	Loss: 0.012327
Step #3140 (total examples = 25120)	Loss: 0.004517
Step #3150 (total examples = 25200)	Loss: 0.305539
Step #3160 (total examples = 25280)	Loss: 0.000408
Step #3170 (total examples = 25360)	Loss: 0.079737
Step #3180 (total examples = 25440)	Loss: 0.000565
Step #3190 (total examples = 25520)	Loss: 0.003954
Step #3200 (total examples = 25600)	Loss: 0.082318
Step #3210 (total examples = 25680)	Loss: 0.095557
Step #3220 (total examples = 25760)	Loss: 0.000967
Step #3230 (total examples = 25840)	Loss: 0.317864
Step #3240 (total examples = 25920)	Loss: 0.028953
Step #1650 (total examples = 13200)	Loss: 0.046361
Step #1660 (total examples = 13280)	Loss: 0.123164
Step #1670 (total examples = 13360)	Loss: 0.116835
Step #1680 (total examples = 13440)	Loss: 0.104535
Step #1690 (total examples = 13520)	Loss: 0.321279
Step #1700 (total examples = 13600)	Loss: 0.263015
Step #1710 (total examples = 13680)	Loss: 0.166005
Step #1720 (total examples = 13760)	Loss: 0.003486
Step #1730 (total examples = 13840)	Loss: 0.247727
Step #1740 (total examples = 13920)	Loss: 0.001575
Step #1750 (total examples = 14000)	Loss: 0.001425
Step #1760 (total examples = 14080)	Loss: 0.006982
Step #1770 (total examples = 14160)	Loss: 0.049710
Step #1780 (total examples = 14240)	Loss: 0.041300
Step #1790 (total examples = 14320)	Loss: 0.009583
Step #1800 (total examples = 14400)	Loss: 0.130918
Step #1810 (total examples = 14480)	Loss: 0.001022
Step #1820 (total examples = 14560)	Loss: 0.000696
Step #1830 (total examples = 14640)	Loss: 0.338219
Step #1840 (total examples = 14720)	Loss: 0.003588
Step #1850 (total examples = 14800)	Loss: 0.063220
Step #1860 (total examples = 14880)	Loss: 0.040147
Step #1870 (total examples = 14960)	Loss: 0.011745
Step #1880 (total examples = 15040)	Loss: 0.158269
Step #1890 (total examples = 15120)	Loss: 0.017435
Step #1900 (total examples = 15200)	Loss: 0.489392
Step #1910 (total examples = 15280)	Loss: 0.004907
Step #1920 (total examples = 15360)	Loss: 0.239678
Step #1930 (total examples = 15440)	Loss: 0.020454
Step #1940 (total examples = 15520)	Loss: 0.975052
Step #1950 (total examples = 15600)	Loss: 0.358771
Step #1960 (total examples = 15680)	Loss: 0.004364
Step #1970 (total examples = 15760)	Loss: 0.041286
Step #1980 (total examples = 15840)	Loss: 0.017582
Step #1990 (total examples = 15920)	Loss: 0.004047
Step #2000 (total examples = 16000)	Loss: 0.173457
Step #2010 (total examples = 16080)	Loss: 0.852374
Step #2020 (total examples = 16160)	Loss: 0.065719
Step #2030 (total examples = 16240)	Loss: 0.000268
Step #2040 (total examples = 16320)	Loss: 0.010531
Step #2050 (total examples = 16400)	Loss: 0.023051
Step #2060 (total examples = 16480)	Loss: 0.014241
Step #2070 (total examples = 16560)	Loss: 0.006579
Step #2080 (total examples = 16640)	Loss: 0.009282
Step #2090 (total examples = 16720)	Loss: 0.042489
Step #2100 (total examples = 16800)	Loss: 0.153214
Step #2110 (total examples = 16880)	Loss: 0.019499
Step #2120 (total examples = 16960)	Loss: 0.003051
Step #2130 (total examples = 17040)	Loss: 0.068818
Step #2140 (total examples = 17120)	Loss: 0.045855
Step #2150 (total examples = 17200)	Loss: 0.028618
Step #2160 (total examples = 17280)	Loss: 0.011245
Step #2170 (total examples = 17360)	Loss: 0.080408
Step #2180 (total examples = 17440)	Loss: 0.003864
Step #2190 (total examples = 17520)	Loss: 0.029867
Step #2200 (total examples = 17600)	Loss: 0.014230
Step #2210 (total examples = 17680)	Loss: 0.000200
Step #2220 (total examples = 17760)	Loss: 0.121398
Step #2230 (total examples = 17840)	Loss: 0.003457
Step #2240 (total examples = 17920)	Loss: 0.001709
Step #2250 (total examples = 18000)	Loss: 0.008042
Step #2260 (total examples = 18080)	Loss: 0.612091
Step #2270 (total examples = 18160)	Loss: 0.048229
Step #2280 (total examples = 18240)	Loss: 0.134154
Step #2290 (total examples = 18320)	Loss: 0.053837
Step #2300 (total examples = 18400)	Loss: 0.217489
Step #2310 (total examples = 18480)	Loss: 0.001147
Step #2320 (total examples = 18560)	Loss: 0.933042
Step #2330 (total examples = 18640)	Loss: 0.119612
Step #2340 (total examples = 18720)	Loss: 0.005510
Step #2350 (total examples = 18800)	Loss: 0.021332
Step #2360 (total examples = 18880)	Loss: 0.168122
Step #2370 (total examples = 18960)	Loss: 0.003022
Step #2380 (total examples = 19040)	Loss: 0.415990
Step #2390 (total examples = 19120)	Loss: 0.012777
Step #2400 (total examples = 19200)	Loss: 0.020023
Step #2410 (total examples = 19280)	Loss: 0.005161
Step #2420 (total examples = 19360)	Loss: 0.180006
Step #2430 (total examples = 19440)	Loss: 0.493675
Step #2440 (total examples = 19520)	Loss: 0.022978
Step #2450 (total examples = 19600)	Loss: 0.144242
Step #2460 (total examples = 19680)	Loss: 0.006238
Step #2470 (total examples = 19760)	Loss: 0.969655
Step #2480 (total examples = 19840)	Loss: 0.088756
Step #2490 (total examples = 19920)	Loss: 0.216973
Step #2500 (total examples = 20000)	Loss: 1.049162
Step #2510 (total examples = 20080)	Loss: 0.012982
Step #2520 (total examples = 20160)	Loss: 0.018228
Step #2530 (total examples = 20240)	Loss: 0.006335
Step #2540 (total examples = 20320)	Loss: 0.031662
Step #2550 (total examples = 20400)	Loss: 0.006025
Step #2560 (total examples = 20480)	Loss: 0.001800
Step #2570 (total examples = 20560)	Loss: 0.007975
Step #2580 (total examples = 20640)	Loss: 0.014182
Step #2590 (total examples = 20720)	Loss: 0.176097
Step #2600 (total examples = 20800)	Loss: 0.005307
Step #2610 (total examples = 20880)	Loss: 0.118813
Step #2620 (total examples = 20960)	Loss: 0.043213
Step #2630 (total examples = 21040)	Loss: 0.001722
Step #2640 (total examples = 21120)	Loss: 0.059427
Step #2650 (total examples = 21200)	Loss: 0.053286
Step #2660 (total examples = 21280)	Loss: 0.000791
Step #2670 (total examples = 21360)	Loss: 0.009733
Step #2680 (total examples = 21440)	Loss: 0.048369
Step #2690 (total examples = 21520)	Loss: 0.054989
Step #2700 (total examples = 21600)	Loss: 0.231481
Step #2710 (total examples = 21680)	Loss: 0.075616
Step #2720 (total examples = 21760)	Loss: 0.067495
Step #2730 (total examples = 21840)	Loss: 0.004057
Step #2740 (total examples = 21920)	Loss: 0.116126
Step #2750 (total examples = 22000)	Loss: 0.015984
Step #2760 (total examples = 22080)	Loss: 0.003407
Step #2770 (total examples = 22160)	Loss: 0.005409
Step #2780 (total examples = 22240)	Loss: 0.002766
Step #2790 (total examples = 22320)	Loss: 0.070355
Step #2800 (total examples = 22400)	Loss: 0.003607
Step #2810 (total examples = 22480)	Loss: 0.166936
Step #2820 (total examples = 22560)	Loss: 0.005549
Step #2830 (total examples = 22640)	Loss: 0.033686
Step #2840 (total examples = 22720)	Loss: 0.305307
Step #2850 (total examples = 22800)	Loss: 0.007572
Step #2860 (total examples = 22880)	Loss: 0.004876
Step #2870 (total examples = 22960)	Loss: 0.004743
Step #2880 (total examples = 23040)	Loss: 0.195395
Step #2890 (total examples = 23120)	Loss: 0.378891
Step #2900 (total examples = 23200)	Loss: 0.000395
Step #2910 (total examples = 23280)	Loss: 0.028600
Step #2920 (total examples = 23360)	Loss: 0.109619
Step #2930 (total examples = 23440)	Loss: 0.058522
Step #2940 (total examples = 23520)	Loss: 0.015518
Step #2950 (total examples = 23600)	Loss: 0.394324
Step #2960 (total examples = 23680)	Loss: 0.018291
Step #2970 (total examples = 23760)	Loss: 0.028693
Step #2980 (total examples = 23840)	Loss: 0.017177
Step #2990 (total examples = 23920)	Loss: 0.007789
Step #3000 (total examples = 24000)	Loss: 0.010118
Step #3010 (total examples = 24080)	Loss: 0.028556
Step #3020 (total examples = 24160)	Loss: 0.186610
Step #3030 (total examples = 24240)	Loss: 0.034726
Step #3040 (total examples = 24320)	Loss: 0.435622
Step #3050 (total examples = 24400)	Loss: 0.003872
Step #3060 (total examples = 24480)	Loss: 0.067220
Step #3070 (total examples = 24560)	Loss: 0.028559
Step #3080 (total examples = 24640)	Loss: 0.013039
Step #3090 (total examples = 24720)	Loss: 0.185572
Step #3100 (total examples = 24800)	Loss: 0.004578
Step #3110 (total examples = 24880)	Loss: 0.002077
Step #3120 (total examples = 24960)	Loss: 0.078218
Step #3130 (total examples = 25040)	Loss: 0.004147
Step #3140 (total examples = 25120)	Loss: 0.213085
Step #3150 (total examples = 25200)	Loss: 0.365282
Step #3160 (total examples = 25280)	Loss: 0.325169
Step #3170 (total examples = 25360)	Loss: 0.065627
Step #3180 (total examples = 25440)	Loss: 0.054084
Step #3190 (total examples = 25520)	Loss: 0.014489
Step #3200 (total examples = 25600)	Loss: 0.003269
Step #3210 (total examples = 25680)	Loss: 0.093893
Step #3220 (total examples = 25760)	Loss: 0.192487
Step #3230 (total examples = 25840)	Loss: 0.000347
Step #3240 (total examples = 25920)	Loss: 0.002850
Step #3250 (total examples = 26000)	Loss: 0.014132
Step #3260 (total examples = 26080)	Loss: 0.002274
Step #3270 (total examples = 26160)	Loss: 0.001354
Step #3280 (total examples = 26240)	Loss: 0.007305
Step #3290 (total examples = 26320)	Loss: 0.000250
Step #3300 (total examples = 26400)	Loss: 0.059809
Step #3310 (total examples = 26480)	Loss: 0.091847
Step #3320 (total examples = 26560)	Loss: 0.019070
Step #3330 (total examples = 26640)	Loss: 0.030766
Step #3340 (total examples = 26720)	Loss: 0.119210
Step #3350 (total examples = 26800)	Loss: 0.007968
Step #3360 (total examples = 26880)	Loss: 0.175117
Step #3370 (total examples = 26960)	Loss: 0.012292
Step #3380 (total examples = 27040)	Loss: 0.006270
Step #3390 (total examples = 27120)	Loss: 0.036163
Step #3400 (total examples = 27200)	Loss: 0.003654
Step #3410 (total examples = 27280)	Loss: 0.004169
Step #3420 (total examples = 27360)	Loss: 0.035045
Step #3430 (total examples = 27440)	Loss: 0.021341
Step #3440 (total examples = 27520)	Loss: 0.875845
Step #3450 (total examples = 27600)	Loss: 0.004830
Step #3460 (total examples = 27680)	Loss: 0.066706
Step #3470 (total examples = 27760)	Loss: 0.028858
Step #3480 (total examples = 27840)	Loss: 0.092326
Step #3490 (total examples = 27920)	Loss: 0.023365
Step #3500 (total examples = 28000)	Loss: 0.000068
Step #3510 (total examples = 28080)	Loss: 0.378020
Step #3520 (total examples = 28160)	Loss: 0.011648
Step #3530 (total examples = 28240)	Loss: 0.514825
Step #3540 (total examples = 28320)	Loss: 0.270459
Step #3550 (total examples = 28400)	Loss: 0.002915
Step #3560 (total examples = 28480)	Loss: 0.003332
Step #3570 (total examples = 28560)	Loss: 0.013476
Step #3580 (total examples = 28640)	Loss: 0.058891
Step #3590 (total examples = 28720)	Loss: 0.002582
Step #3600 (total examples = 28800)	Loss: 0.013603
Step #3610 (total examples = 28880)	Loss: 0.145532
Step #3620 (total examples = 28960)	Loss: 0.086088
Step #3630 (total examples = 29040)	Loss: 0.001824
Step #3640 (total examples = 29120)	Loss: 0.192972
Step #3650 (total examples = 29200)	Loss: 0.042699
Step #3660 (total examples = 29280)	Loss: 0.001774
Step #3670 (total examples = 29360)	Loss: 0.000229
Step #3680 (total examples = 29440)	Loss: 0.002578
Step #3690 (total examples = 29520)	Loss: 0.016072
Step #3700 (total examples = 29600)	Loss: 0.012387
Step #3710 (total examples = 29680)	Loss: 0.226093
Step #3720 (total examples = 29760)	Loss: 0.147000
Step #3730 (total examples = 29840)	Loss: 0.607237
Step #3740 (total examples = 29920)	Loss: 0.001525
Step #3750 (total examples = 30000)	Loss: 0.037755
Step #3760 (total examples = 30080)	Loss: 0.177645
Step #3770 (total examples = 30160)	Loss: 0.002884
Step #3780 (total examples = 30240)	Loss: 0.005729
Step #3790 (total examples = 30320)	Loss: 0.008241
Step #3800 (total examples = 30400)	Loss: 0.129558
Step #3810 (total examples = 30480)	Loss: 0.000783
Step #3820 (total examples = 30560)	Loss: 0.000770
Step #3830 (total examples = 30640)	Loss: 0.000668
Step #3840 (total examples = 30720)	Loss: 0.013271
Step #3850 (total examples = 30800)	Loss: 0.000462
Step #3860 (total examples = 30880)	Loss: 0.001862
Step #3870 (total examples = 30960)	Loss: 0.007931
Step #3880 (total examples = 31040)	Loss: 0.005895
Step #3890 (total examples = 31120)	Loss: 0.512697
Step #3900 (total examples = 31200)	Loss: 0.156869
Step #3910 (total examples = 31280)	Loss: 0.002106
Step #3920 (total examples = 31360)	Loss: 0.611294
Step #3930 (total examples = 31440)	Loss: 0.139870
Step #3940 (total examples = 31520)	Loss: 0.070900
Step #3950 (total examples = 31600)	Loss: 0.027251
Step #3960 (total examples = 31680)	Loss: 0.867396
Step #3970 (total examples = 31760)	Loss: 0.002251
Step #3980 (total examples = 31840)	Loss: 0.000325
Step #3990 (total examples = 31920)	Loss: 0.000471

Step #3250 (total examples = 26000)	Loss: 0.403394
Step #3260 (total examples = 26080)	Loss: 0.006011
Step #3270 (total examples = 26160)	Loss: 0.020694
Step #3280 (total examples = 26240)	Loss: 0.053768
Step #3290 (total examples = 26320)	Loss: 0.000570
Step #3300 (total examples = 26400)	Loss: 0.000690
Step #3310 (total examples = 26480)	Loss: 0.049068
Step #3320 (total examples = 26560)	Loss: 0.002820
Step #3330 (total examples = 26640)	Loss: 0.326839
Step #3340 (total examples = 26720)	Loss: 0.006385
Step #3350 (total examples = 26800)	Loss: 0.011657
Step #3360 (total examples = 26880)	Loss: 0.000322
Step #3370 (total examples = 26960)	Loss: 0.000981
Step #3380 (total examples = 27040)	Loss: 0.135788
Step #3390 (total examples = 27120)	Loss: 0.001825
Step #3400 (total examples = 27200)	Loss: 0.021692
Step #3410 (total examples = 27280)	Loss: 0.006729
Step #3420 (total examples = 27360)	Loss: 0.058562
Step #3430 (total examples = 27440)	Loss: 0.002649
Step #3440 (total examples = 27520)	Loss: 0.231647
Step #3450 (total examples = 27600)	Loss: 0.533689
Step #3460 (total examples = 27680)	Loss: 0.013594
Step #3470 (total examples = 27760)	Loss: 0.342834
Step #3480 (total examples = 27840)	Loss: 0.074636
Step #3490 (total examples = 27920)	Loss: 0.000124
Step #3500 (total examples = 28000)	Loss: 0.025329
Step #3510 (total examples = 28080)	Loss: 0.001513
Step #3520 (total examples = 28160)	Loss: 0.012900
Step #3530 (total examples = 28240)	Loss: 0.001152
Step #3540 (total examples = 28320)	Loss: 0.003267
Step #3550 (total examples = 28400)	Loss: 0.032429
Step #3560 (total examples = 28480)	Loss: 0.003386
Step #3570 (total examples = 28560)	Loss: 0.014334
Step #3580 (total examples = 28640)	Loss: 0.008463
Step #3590 (total examples = 28720)	Loss: 0.142051
Step #3600 (total examples = 28800)	Loss: 0.000468
Step #3610 (total examples = 28880)	Loss: 0.108064
Step #3620 (total examples = 28960)	Loss: 0.000133
Step #3630 (total examples = 29040)	Loss: 0.000155
Step #3640 (total examples = 29120)	Loss: 0.001190
Step #3650 (total examples = 29200)	Loss: 0.244059
Step #3660 (total examples = 29280)	Loss: 0.002070
Step #3670 (total examples = 29360)	Loss: 0.000666
Step #3680 (total examples = 29440)	Loss: 0.015688
Step #3690 (total examples = 29520)	Loss: 0.002570
Step #3700 (total examples = 29600)	Loss: 0.010722
Step #3710 (total examples = 29680)	Loss: 0.002030
Step #3720 (total examples = 29760)	Loss: 0.001316
Step #3730 (total examples = 29840)	Loss: 0.049221
Step #3740 (total examples = 29920)	Loss: 0.001179
Step #3750 (total examples = 30000)	Loss: 0.001866
Step #3760 (total examples = 30080)	Loss: 0.065479
Step #3770 (total examples = 30160)	Loss: 0.036442
Step #3780 (total examples = 30240)	Loss: 0.002467
Step #3790 (total examples = 30320)	Loss: 0.422605
Step #3800 (total examples = 30400)	Loss: 0.011636
Step #3810 (total examples = 30480)	Loss: 0.207204
Step #3820 (total examples = 30560)	Loss: 0.002787
Step #3830 (total examples = 30640)	Loss: 0.000756
Step #3840 (total examples = 30720)	Loss: 0.041567
Step #3850 (total examples = 30800)	Loss: 0.341925
Step #3860 (total examples = 30880)	Loss: 0.012751
Step #3870 (total examples = 30960)	Loss: 0.004408
Step #3880 (total examples = 31040)	Loss: 0.033718
Step #3890 (total examples = 31120)	Loss: 0.133283
Step #3900 (total examples = 31200)	Loss: 0.000143
Step #3910 (total examples = 31280)	Loss: 0.014112
Step #3920 (total examples = 31360)	Loss: 0.002262
Step #3930 (total examples = 31440)	Loss: 0.306785
Step #3940 (total examples = 31520)	Loss: 0.113715
Step #3950 (total examples = 31600)	Loss: 0.001787
Step #3960 (total examples = 31680)	Loss: 0.018520
Step #3970 (total examples = 31760)	Loss: 0.759160
Step #3980 (total examples = 31840)	Loss: 0.008896
Step #3990 (total examples = 31920)	Loss: 0.006607
  1/313 [..............................] - ETA: 1:56 - loss: 0.0000e+00 - accuracy: 1.0000  4/313 [..............................] - ETA: 5s - loss: 0.7946 - accuracy: 0.9922        7/313 [..............................] - ETA: 5s - loss: 0.4541 - accuracy: 0.9955 10/313 [..............................] - ETA: 5s - loss: 9.3500 - accuracy: 0.9875 13/313 [>.............................] - ETA: 5s - loss: 9.1312 - accuracy: 0.9856 16/313 [>.............................] - ETA: 5s - loss: 9.2567 - accuracy: 0.9863 19/313 [>.............................] - ETA: 5s - loss: 11.6303 - accuracy: 0.9852 22/313 [=>............................] - ETA: 5s - loss: 11.3650 - accuracy: 0.9844 24/313 [=>............................] - ETA: 5s - loss: 12.6569 - accuracy: 0.9831 26/313 [=>............................] - ETA: 5s - loss: 11.6832 - accuracy: 0.9844 28/313 [=>............................] - ETA: 5s - loss: 10.8487 - accuracy: 0.9855 30/313 [=>............................] - ETA: 6s - loss: 11.0221 - accuracy: 0.9833 32/313 [==>...........................] - ETA: 6s - loss: 13.3323 - accuracy: 0.9824 34/313 [==>...........................] - ETA: 6s - loss: 12.9061 - accuracy: 0.9825 36/313 [==>...........................] - ETA: 6s - loss: 12.6927 - accuracy: 0.9826 38/313 [==>...........................] - ETA: 6s - loss: 12.8865 - accuracy: 0.9803 40/313 [==>...........................] - ETA: 6s - loss: 15.0588 - accuracy: 0.9773 42/313 [===>..........................] - ETA: 6s - loss: 15.0980 - accuracy: 0.9754 44/313 [===>..........................] - ETA: 6s - loss: 15.2473 - accuracy: 0.9759 46/313 [===>..........................] - ETA: 6s - loss: 14.6742 - accuracy: 0.9762 48/313 [===>..........................] - ETA: 6s - loss: 15.5172 - accuracy: 0.9746 50/313 [===>..........................] - ETA: 6s - loss: 15.1592 - accuracy: 0.9750 52/313 [===>..........................] - ETA: 6s - loss: 14.5761 - accuracy: 0.9760 55/313 [====>.........................] - ETA: 6s - loss: 15.6282 - accuracy: 0.9739 59/313 [====>.........................] - ETA: 6s - loss: 14.8720 - accuracy: 0.9751 63/313 [=====>........................] - ETA: 6s - loss: 14.2879 - accuracy: 0.9762 67/313 [=====>........................] - ETA: 5s - loss: 18.1430 - accuracy: 0.9725 71/313 [=====>........................] - ETA: 5s - loss: 17.6780 - accuracy: 0.9727 75/313 [======>.......................] - ETA: 5s - loss: 17.5103 - accuracy: 0.9729 79/313 [======>.......................] - ETA: 5s - loss: 17.9033 - accuracy: 0.9727 83/313 [======>.......................] - ETA: 5s - loss: 17.3941 - accuracy: 0.9729 86/313 [=======>......................] - ETA: 5s - loss: 16.7931 - accuracy: 0.9735 89/313 [=======>......................] - ETA: 4s - loss: 16.2270 - accuracy: 0.9744 92/313 [=======>......................] - ETA: 4s - loss: 16.4799 - accuracy: 0.9738 95/313 [========>.....................] - ETA: 4s - loss: 16.1985 - accuracy: 0.9740 98/313 [========>.....................] - ETA: 4s - loss: 15.9086 - accuracy: 0.9739101/313 [========>.....................] - ETA: 4s - loss: 15.5591 - accuracy: 0.9743104/313 [========>.....................] - ETA: 4s - loss: 15.3867 - accuracy: 0.9742107/313 [=========>....................] - ETA: 4s - loss: 15.2819 - accuracy: 0.9746110/313 [=========>....................] - ETA: 4s - loss: 15.1255 - accuracy: 0.9750114/313 [=========>....................] - ETA: 4s - loss: 16.2232 - accuracy: 0.9748118/313 [==========>...................] - ETA: 4s - loss: 16.3544 - accuracy: 0.9746122/313 [==========>...................] - ETA: 3s - loss: 16.9000 - accuracy: 0.9746126/313 [===========>..................] - ETA: 3s - loss: 17.3823 - accuracy: 0.9745129/313 [===========>..................] - ETA: 3s - loss: 17.2481 - accuracy: 0.9748133/313 [===========>..................] - ETA: 3s - loss: 17.2292 - accuracy: 0.9744137/313 [============>.................] - ETA: 3s - loss: 16.8689 - accuracy: 0.9747141/313 [============>.................] - ETA: 3s - loss: 16.8210 - accuracy: 0.9747145/313 [============>.................] - ETA: 3s - loss: 17.1003 - accuracy: 0.9744149/313 [=============>................] - ETA: 3s - loss: 16.9660 - accuracy: 0.9744153/313 [=============>................] - ETA: 3s - loss: 16.7742 - accuracy: 0.9741157/313 [==============>...............] - ETA: 3s - loss: 16.3468 - accuracy: 0.9747161/313 [==============>...............] - ETA: 2s - loss: 15.9407 - accuracy: 0.9753165/313 [==============>...............] - ETA: 2s - loss: 15.6808 - accuracy: 0.9756169/313 [===============>..............] - ETA: 2s - loss: 15.4461 - accuracy: 0.9760173/313 [===============>..............] - ETA: 2s - loss: 15.0890 - accuracy: 0.9765177/313 [===============>..............] - ETA: 2s - loss: 14.7480 - accuracy: 0.9770181/313 [================>.............] - ETA: 2s - loss: 14.4221 - accuracy: 0.9776185/313 [================>.............] - ETA: 2s - loss: 14.3860 - accuracy: 0.9774189/313 [=================>............] - ETA: 2s - loss: 14.6971 - accuracy: 0.9770193/313 [=================>............] - ETA: 2s - loss: 14.6065 - accuracy: 0.9770197/313 [=================>............] - ETA: 2s - loss: 14.3099 - accuracy: 0.9775201/313 [==================>...........] - ETA: 2s - loss: 14.0251 - accuracy: 0.9779205/313 [==================>...........] - ETA: 2s - loss: 14.1505 - accuracy: 0.9782209/313 [===================>..........] - ETA: 1s - loss: 14.5772 - accuracy: 0.9780213/313 [===================>..........] - ETA: 1s - loss: 14.4002 - accuracy: 0.9783217/313 [===================>..........] - ETA: 1s - loss: 14.1348 - accuracy: 0.9787221/313 [====================>.........] - ETA: 1s - loss: 13.8790 - accuracy: 0.9791225/313 [====================>.........] - ETA: 1s - loss: 13.6322 - accuracy: 0.9794229/313 [====================>.........] - ETA: 1s - loss: 13.3941 - accuracy: 0.9798233/313 [=====================>........] - ETA: 1s - loss: 13.2481 - accuracy: 0.9800237/313 [=====================>........] - ETA: 1s - loss: 13.0245 - accuracy: 0.9804241/313 [======================>.......] - ETA: 1s - loss: 12.8083 - accuracy: 0.9807245/313 [======================>.......] - ETA: 1s - loss: 12.7187 - accuracy: 0.9807249/313 [======================>.......] - ETA: 1s - loss: 12.5144 - accuracy: 0.9810253/313 [=======================>......] - ETA: 1s - loss: 12.3166 - accuracy: 0.9813257/313 [=======================>......] - ETA: 1s - loss: 12.1249 - accuracy: 0.9816261/313 [========================>.....] - ETA: 0s - loss: 11.9449 - accuracy: 0.9817265/313 [========================>.....] - ETA: 0s - loss: 11.7646 - accuracy: 0.9820269/313 [========================>.....] - ETA: 0s - loss: 11.6927 - accuracy: 0.9821273/313 [=========================>....] - ETA: 0s - loss: 11.5213 - accuracy: 0.9824277/313 [=========================>....] - ETA: 0s - loss: 11.3550 - accuracy: 0.9826281/313 [=========================>....] - ETA: 0s - loss: 11.1933 - accuracy: 0.9829285/313 [==========================>...] - ETA: 0s - loss: 11.7854 - accuracy: 0.9826289/313 [==========================>...] - ETA: 0s - loss: 11.6223 - accuracy: 0.9828293/313 [===========================>..] - ETA: 0s - loss: 11.4636 - accuracy: 0.9830297/313 [===========================>..] - ETA: 0s - loss: 11.3092 - accuracy: 0.9833301/313 [===========================>..] - ETA: 0s - loss: 11.2206 - accuracy: 0.9833305/313 [============================>.] - ETA: 0s - loss: 11.2600 - accuracy: 0.9830309/313 [============================>.] - ETA: 0s - loss: 11.2411 - accuracy: 0.9831313/313 [==============================] - ETA: 0s - loss: 11.1744 - accuracy: 0.9831313/313 [==============================] - 6s 18ms/step - loss: 11.1744 - accuracy: 0.9831
Final model accuracy: 0.983100
Total training time: 382.228628
2021-12-03 20:30:54.613460: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/lang/Python/3.7.2-intel-2018.5.274/lib:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib64:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib:/opt/apps/software/math/GMP/6.1.2-GCCcore-6.3.0/lib:/opt/apps/software/tools/XZ/5.2.4-GCCcore-6.3.0/lib:/opt/apps/software/devel/SQLite/3.27.2-GCCcore-6.3.0/lib:/opt/apps/software/lang/Tcl/8.6.9-GCCcore-6.3.0/lib:/opt/apps/software/devel/ncurses/6.1-intel-2018.5.274/lib:/opt/apps/software/lib/libreadline/7.0-GCCcore-6.3.0/lib:/opt/apps/software/lib/zlib/1.2.11-GCCcore-6.3.0/lib:/opt/apps/software/tools/bzip2/1.0.6/lib:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/mkl/lib/intel64:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/lib/intel64:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/lib64:/opt/apps/software/lib/libfabric/1.9.1/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/tbb/lib/intel64/gcc4.4:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/tools/binutils/2.26-GCCcore-6.3.0/lib:/opt/apps/software/compiler/GCCcore/6.3.0/lib/gcc/x86_64-pc-linux-gnu/6.3.0:/opt/apps/software/compiler/GCCcore/6.3.0/lib64:/opt/apps/software/compiler/GCCcore/6.3.0/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/mic/lib
2021-12-03 20:30:54.613616: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-03 20:30:54.637173: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/lang/Python/3.7.2-intel-2018.5.274/lib:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib64:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib:/opt/apps/software/math/GMP/6.1.2-GCCcore-6.3.0/lib:/opt/apps/software/tools/XZ/5.2.4-GCCcore-6.3.0/lib:/opt/apps/software/devel/SQLite/3.27.2-GCCcore-6.3.0/lib:/opt/apps/software/lang/Tcl/8.6.9-GCCcore-6.3.0/lib:/opt/apps/software/devel/ncurses/6.1-intel-2018.5.274/lib:/opt/apps/software/lib/libreadline/7.0-GCCcore-6.3.0/lib:/opt/apps/software/lib/zlib/1.2.11-GCCcore-6.3.0/lib:/opt/apps/software/tools/bzip2/1.0.6/lib:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/mkl/lib/intel64:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/lib/intel64:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/lib64:/opt/apps/software/lib/libfabric/1.9.1/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/tbb/lib/intel64/gcc4.4:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/tools/binutils/2.26-GCCcore-6.3.0/lib:/opt/apps/software/compiler/GCCcore/6.3.0/lib/gcc/x86_64-pc-linux-gnu/6.3.0:/opt/apps/software/compiler/GCCcore/6.3.0/lib64:/opt/apps/software/compiler/GCCcore/6.3.0/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/mic/lib
2021-12-03 20:30:54.637277: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-03 20:30:58.810108: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2021-12-03 20:30:58.810275: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: gpu-0001
2021-12-03 20:30:58.810324: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: gpu-0001
2021-12-03 20:30:58.810459: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 465.19.1
2021-12-03 20:30:58.810584: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 465.19.1
2021-12-03 20:30:58.810659: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 465.19.1
2021-12-03 20:30:58.811552: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-03 20:30:58.832803: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/lang/Python/3.7.2-intel-2018.5.274/lib:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib64:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib:/opt/apps/software/math/GMP/6.1.2-GCCcore-6.3.0/lib:/opt/apps/software/tools/XZ/5.2.4-GCCcore-6.3.0/lib:/opt/apps/software/devel/SQLite/3.27.2-GCCcore-6.3.0/lib:/opt/apps/software/lang/Tcl/8.6.9-GCCcore-6.3.0/lib:/opt/apps/software/devel/ncurses/6.1-intel-2018.5.274/lib:/opt/apps/software/lib/libreadline/7.0-GCCcore-6.3.0/lib:/opt/apps/software/lib/zlib/1.2.11-GCCcore-6.3.0/lib:/opt/apps/software/tools/bzip2/1.0.6/lib:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/mkl/lib/intel64:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/lib/intel64:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/lib64:/opt/apps/software/lib/libfabric/1.9.1/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/tbb/lib/intel64/gcc4.4:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/tools/binutils/2.26-GCCcore-6.3.0/lib:/opt/apps/software/compiler/GCCcore/6.3.0/lib/gcc/x86_64-pc-linux-gnu/6.3.0:/opt/apps/software/compiler/GCCcore/6.3.0/lib64:/opt/apps/software/compiler/GCCcore/6.3.0/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/mic/lib
2021-12-03 20:30:58.832899: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-03 20:30:58.832959: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node-0001): /proc/driver/nvidia/version does not exist
===========
rank: 0
Batch size: 8
Total number of batches: 8000
Total training examples: 64000
Num of workers: 2
===========
Step #0 (total examples = 0)	Loss: 2.299055
Step #10 (total examples = 80)	Loss: 2.139295
Step #20 (total examples = 160)	Loss: 1.428015
Step #30 (total examples = 240)	Loss: 0.207138
Step #40 (total examples = 320)	Loss: 0.341441
Step #50 (total examples = 400)	Loss: 0.345925
Step #60 (total examples = 480)	Loss: 0.533961
Step #70 (total examples = 560)	Loss: 0.164615
Step #80 (total examples = 640)	Loss: 0.714970
Step #90 (total examples = 720)	Loss: 0.116148
Step #100 (total examples = 800)	Loss: 0.301764
Step #110 (total examples = 880)	Loss: 0.358289
Step #120 (total examples = 960)	Loss: 0.171703
Step #130 (total examples = 1040)	Loss: 0.058166
Step #140 (total examples = 1120)	Loss: 1.016877
Step #150 (total examples = 1200)	Loss: 0.187587
Step #160 (total examples = 1280)	Loss: 0.179616
Step #170 (total examples = 1360)	Loss: 0.045997
Step #180 (total examples = 1440)	Loss: 0.945198
Step #190 (total examples = 1520)	Loss: 0.253718
Step #200 (total examples = 1600)	Loss: 0.689290
Step #210 (total examples = 1680)	Loss: 0.538301
Step #220 (total examples = 1760)	Loss: 0.280830
Step #230 (total examples = 1840)	Loss: 0.354591
Step #240 (total examples = 1920)	Loss: 0.013106
Step #250 (total examples = 2000)	Loss: 0.153710
Step #260 (total examples = 2080)	Loss: 0.476966
Step #270 (total examples = 2160)	Loss: 0.362365
Step #280 (total examples = 2240)	Loss: 0.636550
Step #290 (total examples = 2320)	Loss: 0.027322
Step #300 (total examples = 2400)	Loss: 0.103484
Step #310 (total examples = 2480)	Loss: 0.034870
Step #320 (total examples = 2560)	Loss: 0.117055
Step #330 (total examples = 2640)	Loss: 1.131417
Step #340 (total examples = 2720)	Loss: 0.240801
Step #350 (total examples = 2800)	Loss: 0.046990
Step #360 (total examples = 2880)	Loss: 0.380817
Step #370 (total examples = 2960)	Loss: 0.401190
Step #380 (total examples = 3040)	Loss: 0.465771
Step #390 (total examples = 3120)	Loss: 0.012876
Step #400 (total examples = 3200)	Loss: 0.055765
Step #410 (total examples = 3280)	Loss: 0.089752
Step #420 (total examples = 3360)	Loss: 0.168990
Step #430 (total examples = 3440)	Loss: 0.095104
Step #440 (total examples = 3520)	Loss: 0.123615
Step #450 (total examples = 3600)	Loss: 0.119589
Step #460 (total examples = 3680)	Loss: 0.018354
Step #470 (total examples = 3760)	Loss: 0.372812
Step #480 (total examples = 3840)	Loss: 0.184354
Step #490 (total examples = 3920)	Loss: 1.135974
Step #500 (total examples = 4000)	Loss: 0.011455
Step #510 (total examples = 4080)	Loss: 0.053458
Step #520 (total examples = 4160)	Loss: 0.003160
Step #530 (total examples = 4240)	Loss: 0.024279
Step #540 (total examples = 4320)	Loss: 0.010799
Step #550 (total examples = 4400)	Loss: 0.141723
Step #560 (total examples = 4480)	Loss: 0.489007
Step #570 (total examples = 4560)	Loss: 0.037848
Step #580 (total examples = 4640)	Loss: 0.014974
Step #590 (total examples = 4720)	Loss: 0.011817
Step #600 (total examples = 4800)	Loss: 0.317506
Step #610 (total examples = 4880)	Loss: 0.154191
Step #620 (total examples = 4960)	Loss: 0.127665
Step #630 (total examples = 5040)	Loss: 0.066000
Step #640 (total examples = 5120)	Loss: 0.513437
Step #650 (total examples = 5200)	Loss: 0.215204
Step #660 (total examples = 5280)	Loss: 0.172436
Step #670 (total examples = 5360)	Loss: 0.013810
Step #680 (total examples = 5440)	Loss: 0.062347
Step #690 (total examples = 5520)	Loss: 0.006420
Step #700 (total examples = 5600)	Loss: 0.040257
Step #710 (total examples = 5680)	Loss: 0.052041
Step #720 (total examples = 5760)	Loss: 0.643682
Step #730 (total examples = 5840)	Loss: 0.012274
Step #740 (total examples = 5920)	Loss: 0.062205
Step #750 (total examples = 6000)	Loss: 0.011241
Step #760 (total examples = 6080)	Loss: 0.069835
Step #770 (total examples = 6160)	Loss: 0.599387
Step #780 (total examples = 6240)	Loss: 0.006259
Step #790 (total examples = 6320)	Loss: 0.021139
Step #800 (total examples = 6400)	Loss: 0.262883
Step #810 (total examples = 6480)	Loss: 0.008570
Step #820 (total examples = 6560)	Loss: 0.046930
Step #830 (total examples = 6640)	Loss: 0.433221
Step #840 (total examples = 6720)	Loss: 0.837144
Step #850 (total examples = 6800)	Loss: 0.025882
Step #860 (total examples = 6880)	Loss: 0.574782
Step #870 (total examples = 6960)	Loss: 0.020437
Step #880 (total examples = 7040)	Loss: 0.002054
Step #890 (total examples = 7120)	Loss: 0.099533
Step #900 (total examples = 7200)	Loss: 0.215672
Step #910 (total examples = 7280)	Loss: 0.227696
Step #920 (total examples = 7360)	Loss: 0.091111
Step #930 (total examples = 7440)	Loss: 0.043092
Step #940 (total examples = 7520)	Loss: 0.098440
Step #950 (total examples = 7600)	Loss: 0.011224
Step #960 (total examples = 7680)	Loss: 0.293689
Step #970 (total examples = 7760)	Loss: 0.189250
Step #980 (total examples = 7840)	Loss: 0.002241
Step #990 (total examples = 7920)	Loss: 0.544914
Step #1000 (total examples = 8000)	Loss: 0.001064
Step #1010 (total examples = 8080)	Loss: 0.026284
Step #1020 (total examples = 8160)	Loss: 0.000988
Step #1030 (total examples = 8240)	Loss: 0.039164
Step #1040 (total examples = 8320)	Loss: 0.007403
Step #1050 (total examples = 8400)	Loss: 0.029020
Step #1060 (total examples = 8480)	Loss: 0.139498
Step #1070 (total examples = 8560)	Loss: 0.264157
Step #1080 (total examples = 8640)	Loss: 0.020437
Step #1090 (total examples = 8720)	Loss: 0.098441
Step #1100 (total examples = 8800)	Loss: 0.023354
Step #1110 (total examples = 8880)	Loss: 0.008700
Step #1120 (total examples = 8960)	Loss: 0.002028
Step #1130 (total examples = 9040)	Loss: 0.023016
Step #1140 (total examples = 9120)	Loss: 0.001393
Step #1150 (total examples = 9200)	Loss: 0.003940
Step #1160 (total examples = 9280)	Loss: 0.021322
Step #1170 (total examples = 9360)	Loss: 0.042864
Step #1180 (total examples = 9440)	Loss: 0.044748
Step #1190 (total examples = 9520)	Loss: 0.075405
Step #1200 (total examples = 9600)	Loss: 0.039450
Step #1210 (total examples = 9680)	Loss: 0.424790
Step #1220 (total examples = 9760)	Loss: 0.012039
Step #1230 (total examples = 9840)	Loss: 0.032407
Step #1240 (total examples = 9920)	Loss: 0.056400
Step #1250 (total examples = 10000)	Loss: 0.061970
Step #1260 (total examples = 10080)	Loss: 0.055839
Step #1270 (total examples = 10160)	Loss: 0.042585
Step #1280 (total examples = 10240)	Loss: 0.006910
Step #1290 (total examples = 10320)	Loss: 0.017723
Step #1300 (total examples = 10400)	Loss: 0.136278
Step #1310 (total examples = 10480)	Loss: 0.002408
Step #1320 (total examples = 10560)	Loss: 0.051417
Step #1330 (total examples = 10640)	Loss: 0.020516
Step #1340 (total examples = 10720)	Loss: 0.004555
Step #1350 (total examples = 10800)	Loss: 0.008099
Step #1360 (total examples = 10880)	Loss: 0.048257
Step #1370 (total examples = 10960)	Loss: 1.056694
Step #1380 (total examples = 11040)	Loss: 0.174237
Step #1390 (total examples = 11120)	Loss: 0.007869
Step #1400 (total examples = 11200)	Loss: 0.025526
Step #1410 (total examples = 11280)	Loss: 0.009200
Step #1420 (total examples = 11360)	Loss: 0.103273
Step #1430 (total examples = 11440)	Loss: 0.007470
Step #1440 (total examples = 11520)	Loss: 0.066391
Step #1450 (total examples = 11600)	Loss: 0.175466
Step #1460 (total examples = 11680)	Loss: 0.000495
Step #1470 (total examples = 11760)	Loss: 0.016565
Step #1480 (total examples = 11840)	Loss: 0.031592
Step #1490 (total examples = 11920)	Loss: 0.045520
Step #1500 (total examples = 12000)	Loss: 0.002700
Step #1510 (total examples = 12080)	Loss: 0.290947
Step #1520 (total examples = 12160)	Loss: 0.031891
Step #1530 (total examples = 12240)	Loss: 0.009223
Step #1540 (total examples = 12320)	Loss: 0.020722
Step #1550 (total examples = 12400)	Loss: 0.130214
Step #1560 (total examples = 12480)	Loss: 0.018684
Step #1570 (total examples = 12560)	Loss: 0.012868
Step #1580 (total examples = 12640)	Loss: 0.379783
Step #1590 (total examples = 12720)	Loss: 0.004057
Step #1600 (total examples = 12800)	Loss: 0.008926
Step #1610 (total examples = 12880)	Loss: 0.034886
Step #1620 (total examples = 12960)	Loss: 0.001311
Step #1630 (total examples = 13040)	Loss: 0.042611===========
rank: 1
===========
Step #0 (total examples = 0)	Loss: 2.292186
Step #10 (total examples = 80)	Loss: 2.154344
Step #20 (total examples = 160)	Loss: 0.774739
Step #30 (total examples = 240)	Loss: 1.438120
Step #40 (total examples = 320)	Loss: 0.646098
Step #50 (total examples = 400)	Loss: 0.200989
Step #60 (total examples = 480)	Loss: 0.353609
Step #70 (total examples = 560)	Loss: 0.967577
Step #80 (total examples = 640)	Loss: 0.332482
Step #90 (total examples = 720)	Loss: 0.517057
Step #100 (total examples = 800)	Loss: 0.070840
Step #110 (total examples = 880)	Loss: 0.048636
Step #120 (total examples = 960)	Loss: 0.166742
Step #130 (total examples = 1040)	Loss: 0.089189
Step #140 (total examples = 1120)	Loss: 0.152791
Step #150 (total examples = 1200)	Loss: 0.141498
Step #160 (total examples = 1280)	Loss: 0.569128
Step #170 (total examples = 1360)	Loss: 0.213249
Step #180 (total examples = 1440)	Loss: 0.161179
Step #190 (total examples = 1520)	Loss: 0.137569
Step #200 (total examples = 1600)	Loss: 0.279288
Step #210 (total examples = 1680)	Loss: 0.044975
Step #220 (total examples = 1760)	Loss: 0.171494
Step #230 (total examples = 1840)	Loss: 0.271631
Step #240 (total examples = 1920)	Loss: 0.117904
Step #250 (total examples = 2000)	Loss: 0.054182
Step #260 (total examples = 2080)	Loss: 0.134241
Step #270 (total examples = 2160)	Loss: 0.353276
Step #280 (total examples = 2240)	Loss: 0.080727
Step #290 (total examples = 2320)	Loss: 0.317863
Step #300 (total examples = 2400)	Loss: 0.736198
Step #310 (total examples = 2480)	Loss: 0.086336
Step #320 (total examples = 2560)	Loss: 0.942773
Step #330 (total examples = 2640)	Loss: 0.330870
Step #340 (total examples = 2720)	Loss: 0.068703
Step #350 (total examples = 2800)	Loss: 0.029745
Step #360 (total examples = 2880)	Loss: 0.035300
Step #370 (total examples = 2960)	Loss: 0.009415
Step #380 (total examples = 3040)	Loss: 0.111208
Step #390 (total examples = 3120)	Loss: 0.001975
Step #400 (total examples = 3200)	Loss: 0.088631
Step #410 (total examples = 3280)	Loss: 0.491865
Step #420 (total examples = 3360)	Loss: 0.097431
Step #430 (total examples = 3440)	Loss: 0.084499
Step #440 (total examples = 3520)	Loss: 0.137168
Step #450 (total examples = 3600)	Loss: 0.059227
Step #460 (total examples = 3680)	Loss: 0.020462
Step #470 (total examples = 3760)	Loss: 0.213975
Step #480 (total examples = 3840)	Loss: 0.033422
Step #490 (total examples = 3920)	Loss: 0.031745
Step #500 (total examples = 4000)	Loss: 0.303254
Step #510 (total examples = 4080)	Loss: 0.093521
Step #520 (total examples = 4160)	Loss: 0.328505
Step #530 (total examples = 4240)	Loss: 0.032451
Step #540 (total examples = 4320)	Loss: 0.037880
Step #550 (total examples = 4400)	Loss: 0.058556
Step #560 (total examples = 4480)	Loss: 0.006501
Step #570 (total examples = 4560)	Loss: 0.194514
Step #580 (total examples = 4640)	Loss: 0.094819
Step #590 (total examples = 4720)	Loss: 0.005008
Step #600 (total examples = 4800)	Loss: 0.444153
Step #610 (total examples = 4880)	Loss: 0.496714
Step #620 (total examples = 4960)	Loss: 0.021406
Step #630 (total examples = 5040)	Loss: 0.033929
Step #640 (total examples = 5120)	Loss: 0.142249
Step #650 (total examples = 5200)	Loss: 0.234738
Step #660 (total examples = 5280)	Loss: 0.025191
Step #670 (total examples = 5360)	Loss: 0.031466
Step #680 (total examples = 5440)	Loss: 0.183791
Step #690 (total examples = 5520)	Loss: 0.262221
Step #700 (total examples = 5600)	Loss: 0.066901
Step #710 (total examples = 5680)	Loss: 0.209144
Step #720 (total examples = 5760)	Loss: 0.041268
Step #730 (total examples = 5840)	Loss: 0.278136
Step #740 (total examples = 5920)	Loss: 0.128013
Step #750 (total examples = 6000)	Loss: 0.423719
Step #760 (total examples = 6080)	Loss: 0.371271
Step #770 (total examples = 6160)	Loss: 0.144052
Step #780 (total examples = 6240)	Loss: 0.213268
Step #790 (total examples = 6320)	Loss: 0.004927
Step #800 (total examples = 6400)	Loss: 0.596440
Step #810 (total examples = 6480)	Loss: 0.023127
Step #820 (total examples = 6560)	Loss: 0.074957
Step #830 (total examples = 6640)	Loss: 0.136074
Step #840 (total examples = 6720)	Loss: 0.118525
Step #850 (total examples = 6800)	Loss: 0.033356
Step #860 (total examples = 6880)	Loss: 0.057338
Step #870 (total examples = 6960)	Loss: 0.056341
Step #880 (total examples = 7040)	Loss: 0.039632
Step #890 (total examples = 7120)	Loss: 0.004332
Step #900 (total examples = 7200)	Loss: 0.008352
Step #910 (total examples = 7280)	Loss: 0.034322
Step #920 (total examples = 7360)	Loss: 0.541025
Step #930 (total examples = 7440)	Loss: 0.007838
Step #940 (total examples = 7520)	Loss: 0.134694
Step #950 (total examples = 7600)	Loss: 0.724014
Step #960 (total examples = 7680)	Loss: 0.001259
Step #970 (total examples = 7760)	Loss: 0.009577
Step #980 (total examples = 7840)	Loss: 0.064396
Step #990 (total examples = 7920)	Loss: 0.109625
Step #1000 (total examples = 8000)	Loss: 0.429331
Step #1010 (total examples = 8080)	Loss: 0.728601
Step #1020 (total examples = 8160)	Loss: 0.421315
Step #1030 (total examples = 8240)	Loss: 0.044291
Step #1040 (total examples = 8320)	Loss: 0.149187
Step #1050 (total examples = 8400)	Loss: 0.054704
Step #1060 (total examples = 8480)	Loss: 0.031348
Step #1070 (total examples = 8560)	Loss: 0.510737
Step #1080 (total examples = 8640)	Loss: 0.483047
Step #1090 (total examples = 8720)	Loss: 0.003998
Step #1100 (total examples = 8800)	Loss: 0.269519
Step #1110 (total examples = 8880)	Loss: 0.145116
Step #1120 (total examples = 8960)	Loss: 0.002185
Step #1130 (total examples = 9040)	Loss: 0.121624
Step #1140 (total examples = 9120)	Loss: 0.343724
Step #1150 (total examples = 9200)	Loss: 0.002522
Step #1160 (total examples = 9280)	Loss: 0.019309
Step #1170 (total examples = 9360)	Loss: 0.007421
Step #1180 (total examples = 9440)	Loss: 0.043866
Step #1190 (total examples = 9520)	Loss: 0.009023
Step #1200 (total examples = 9600)	Loss: 0.009222
Step #1210 (total examples = 9680)	Loss: 0.072405
Step #1220 (total examples = 9760)	Loss: 0.117417
Step #1230 (total examples = 9840)	Loss: 0.276299
Step #1240 (total examples = 9920)	Loss: 0.313675
Step #1250 (total examples = 10000)	Loss: 0.017006
Step #1260 (total examples = 10080)	Loss: 0.085920
Step #1270 (total examples = 10160)	Loss: 0.320084
Step #1280 (total examples = 10240)	Loss: 0.000347
Step #1290 (total examples = 10320)	Loss: 0.005045
Step #1300 (total examples = 10400)	Loss: 0.011024
Step #1310 (total examples = 10480)	Loss: 0.077569
Step #1320 (total examples = 10560)	Loss: 0.216396
Step #1330 (total examples = 10640)	Loss: 0.007919
Step #1340 (total examples = 10720)	Loss: 0.012503
Step #1350 (total examples = 10800)	Loss: 0.018006
Step #1360 (total examples = 10880)	Loss: 0.035446
Step #1370 (total examples = 10960)	Loss: 0.015980
Step #1380 (total examples = 11040)	Loss: 0.210980
Step #1390 (total examples = 11120)	Loss: 0.662962
Step #1400 (total examples = 11200)	Loss: 0.033823
Step #1410 (total examples = 11280)	Loss: 0.080198
Step #1420 (total examples = 11360)	Loss: 0.171147
Step #1430 (total examples = 11440)	Loss: 0.146635
Step #1440 (total examples = 11520)	Loss: 0.002018
Step #1450 (total examples = 11600)	Loss: 0.000434
Step #1460 (total examples = 11680)	Loss: 0.008271
Step #1470 (total examples = 11760)	Loss: 0.050458
Step #1480 (total examples = 11840)	Loss: 0.001503
Step #1490 (total examples = 11920)	Loss: 0.905434
Step #1500 (total examples = 12000)	Loss: 0.009177
Step #1510 (total examples = 12080)	Loss: 0.015026
Step #1520 (total examples = 12160)	Loss: 0.277332
Step #1530 (total examples = 12240)	Loss: 0.062685
Step #1540 (total examples = 12320)	Loss: 1.125848
Step #1550 (total examples = 12400)	Loss: 0.215892
Step #1560 (total examples = 12480)	Loss: 0.005903
Step #1570 (total examples = 12560)	Loss: 0.067459
Step #1580 (total examples = 12640)	Loss: 0.032810
Step #1590 (total examples = 12720)	Loss: 0.001008
Step #1600 (total examples = 12800)	Loss: 0.422590
Step #1610 (total examples = 12880)	Loss: 0.029617
Step #1620 (total examples = 12960)	Loss: 0.389152
Step #1630 (total examples = 13040)	Loss: 0.036698
Step #1640 (total examples = 13120)	Loss: 0.039471
Step #1640 (total examples = 13120)	Loss: 0.536236
Step #1650 (total examples = 13200)	Loss: 0.413244
Step #1660 (total examples = 13280)	Loss: 0.020502
Step #1670 (total examples = 13360)	Loss: 0.056712
Step #1680 (total examples = 13440)	Loss: 0.078232
Step #1690 (total examples = 13520)	Loss: 0.025661
Step #1700 (total examples = 13600)	Loss: 0.078871
Step #1710 (total examples = 13680)	Loss: 0.003456
Step #1720 (total examples = 13760)	Loss: 0.052091
Step #1730 (total examples = 13840)	Loss: 0.009363
Step #1740 (total examples = 13920)	Loss: 0.807411
Step #1750 (total examples = 14000)	Loss: 0.047192
Step #1760 (total examples = 14080)	Loss: 0.045506
Step #1770 (total examples = 14160)	Loss: 0.001966
Step #1780 (total examples = 14240)	Loss: 0.018089
Step #1790 (total examples = 14320)	Loss: 0.058825
Step #1800 (total examples = 14400)	Loss: 0.107776
Step #1810 (total examples = 14480)	Loss: 0.002126
Step #1820 (total examples = 14560)	Loss: 0.001667
Step #1830 (total examples = 14640)	Loss: 0.291088
Step #1840 (total examples = 14720)	Loss: 0.006204
Step #1850 (total examples = 14800)	Loss: 0.009110
Step #1860 (total examples = 14880)	Loss: 0.008667
Step #1870 (total examples = 14960)	Loss: 0.032212
Step #1880 (total examples = 15040)	Loss: 0.024028
Step #1890 (total examples = 15120)	Loss: 1.002726
Step #1900 (total examples = 15200)	Loss: 0.013163
Step #1910 (total examples = 15280)	Loss: 0.136011
Step #1920 (total examples = 15360)	Loss: 0.045062
Step #1930 (total examples = 15440)	Loss: 0.012060
Step #1940 (total examples = 15520)	Loss: 0.028334
Step #1950 (total examples = 15600)	Loss: 0.027732
Step #1960 (total examples = 15680)	Loss: 0.053914
Step #1970 (total examples = 15760)	Loss: 0.062677
Step #1980 (total examples = 15840)	Loss: 0.279679
Step #1990 (total examples = 15920)	Loss: 0.082007
Step #2000 (total examples = 16000)	Loss: 0.005487
Step #2010 (total examples = 16080)	Loss: 1.148129
Step #2020 (total examples = 16160)	Loss: 0.014440
Step #2030 (total examples = 16240)	Loss: 0.007762
Step #2040 (total examples = 16320)	Loss: 0.138600
Step #2050 (total examples = 16400)	Loss: 0.060440
Step #2060 (total examples = 16480)	Loss: 0.006522
Step #2070 (total examples = 16560)	Loss: 0.218822
Step #2080 (total examples = 16640)	Loss: 0.005599
Step #2090 (total examples = 16720)	Loss: 0.001400
Step #2100 (total examples = 16800)	Loss: 0.003388
Step #2110 (total examples = 16880)	Loss: 0.002605
Step #2120 (total examples = 16960)	Loss: 0.123568
Step #2130 (total examples = 17040)	Loss: 0.000377
Step #2140 (total examples = 17120)	Loss: 0.123312
Step #2150 (total examples = 17200)	Loss: 0.004457
Step #2160 (total examples = 17280)	Loss: 0.001781
Step #2170 (total examples = 17360)	Loss: 0.001638
Step #2180 (total examples = 17440)	Loss: 0.072021
Step #2190 (total examples = 17520)	Loss: 0.000624
Step #2200 (total examples = 17600)	Loss: 0.027679
Step #2210 (total examples = 17680)	Loss: 0.200617
Step #2220 (total examples = 17760)	Loss: 0.000101
Step #2230 (total examples = 17840)	Loss: 0.146394
Step #2240 (total examples = 17920)	Loss: 0.000053
Step #2250 (total examples = 18000)	Loss: 0.340541
Step #2260 (total examples = 18080)	Loss: 0.012301
Step #2270 (total examples = 18160)	Loss: 0.007584
Step #2280 (total examples = 18240)	Loss: 0.013814
Step #2290 (total examples = 18320)	Loss: 0.068409
Step #2300 (total examples = 18400)	Loss: 0.009793
Step #2310 (total examples = 18480)	Loss: 0.039624
Step #2320 (total examples = 18560)	Loss: 0.024543
Step #2330 (total examples = 18640)	Loss: 0.331876
Step #2340 (total examples = 18720)	Loss: 0.037911
Step #2350 (total examples = 18800)	Loss: 0.114978
Step #2360 (total examples = 18880)	Loss: 0.013518
Step #2370 (total examples = 18960)	Loss: 0.100467
Step #2380 (total examples = 19040)	Loss: 0.020068
Step #2390 (total examples = 19120)	Loss: 0.282500
Step #2400 (total examples = 19200)	Loss: 0.498303
Step #2410 (total examples = 19280)	Loss: 0.017373
Step #2420 (total examples = 19360)	Loss: 0.138610
Step #2430 (total examples = 19440)	Loss: 0.002679
Step #2440 (total examples = 19520)	Loss: 0.000915
Step #2450 (total examples = 19600)	Loss: 0.052125
Step #2460 (total examples = 19680)	Loss: 0.000382
Step #2470 (total examples = 19760)	Loss: 0.000858
Step #2480 (total examples = 19840)	Loss: 0.033499
Step #2490 (total examples = 19920)	Loss: 0.306883
Step #2500 (total examples = 20000)	Loss: 0.010800
Step #2510 (total examples = 20080)	Loss: 0.000907
Step #2520 (total examples = 20160)	Loss: 0.001916
Step #2530 (total examples = 20240)	Loss: 0.880414
Step #2540 (total examples = 20320)	Loss: 0.388911
Step #2550 (total examples = 20400)	Loss: 0.016071
Step #2560 (total examples = 20480)	Loss: 0.153580
Step #2570 (total examples = 20560)	Loss: 0.043561
Step #2580 (total examples = 20640)	Loss: 0.004700
Step #2590 (total examples = 20720)	Loss: 0.044573
Step #2600 (total examples = 20800)	Loss: 0.033347
Step #2610 (total examples = 20880)	Loss: 0.005462
Step #2620 (total examples = 20960)	Loss: 0.055302
Step #2630 (total examples = 21040)	Loss: 0.020730
Step #2640 (total examples = 21120)	Loss: 0.012248
Step #2650 (total examples = 21200)	Loss: 0.012540
Step #2660 (total examples = 21280)	Loss: 0.000842
Step #2670 (total examples = 21360)	Loss: 0.353752
Step #2680 (total examples = 21440)	Loss: 0.406782
Step #2690 (total examples = 21520)	Loss: 0.004872
Step #2700 (total examples = 21600)	Loss: 0.008873
Step #2710 (total examples = 21680)	Loss: 0.381270
Step #2720 (total examples = 21760)	Loss: 0.001119
Step #2730 (total examples = 21840)	Loss: 0.001331
Step #2740 (total examples = 21920)	Loss: 0.010889
Step #2750 (total examples = 22000)	Loss: 0.099513
Step #2760 (total examples = 22080)	Loss: 0.011828
Step #2770 (total examples = 22160)	Loss: 0.009037
Step #2780 (total examples = 22240)	Loss: 0.000243
Step #2790 (total examples = 22320)	Loss: 0.001875
Step #2800 (total examples = 22400)	Loss: 0.003829
Step #2810 (total examples = 22480)	Loss: 0.461071
Step #2820 (total examples = 22560)	Loss: 0.023421
Step #2830 (total examples = 22640)	Loss: 0.043943
Step #2840 (total examples = 22720)	Loss: 0.002394
Step #2850 (total examples = 22800)	Loss: 0.011980
Step #2860 (total examples = 22880)	Loss: 0.041858
Step #2870 (total examples = 22960)	Loss: 0.041788
Step #2880 (total examples = 23040)	Loss: 0.061032
Step #2890 (total examples = 23120)	Loss: 0.007148
Step #2900 (total examples = 23200)	Loss: 0.005797
Step #2910 (total examples = 23280)	Loss: 0.015018
Step #2920 (total examples = 23360)	Loss: 0.206456
Step #2930 (total examples = 23440)	Loss: 0.161696
Step #2940 (total examples = 23520)	Loss: 0.008453
Step #2950 (total examples = 23600)	Loss: 0.126190
Step #2960 (total examples = 23680)	Loss: 0.203308
Step #2970 (total examples = 23760)	Loss: 0.004102
Step #2980 (total examples = 23840)	Loss: 0.017996
Step #2990 (total examples = 23920)	Loss: 0.113749
Step #3000 (total examples = 24000)	Loss: 0.231209
Step #3010 (total examples = 24080)	Loss: 0.008277
Step #3020 (total examples = 24160)	Loss: 0.196826
Step #3030 (total examples = 24240)	Loss: 0.002106
Step #3040 (total examples = 24320)	Loss: 0.001331
Step #3050 (total examples = 24400)	Loss: 0.007271
Step #3060 (total examples = 24480)	Loss: 0.000696
Step #3070 (total examples = 24560)	Loss: 0.395574
Step #3080 (total examples = 24640)	Loss: 0.010096
Step #3090 (total examples = 24720)	Loss: 0.000320
Step #3100 (total examples = 24800)	Loss: 0.093996
Step #3110 (total examples = 24880)	Loss: 0.040832
Step #3120 (total examples = 24960)	Loss: 0.014825
Step #3130 (total examples = 25040)	Loss: 0.015248
Step #3140 (total examples = 25120)	Loss: 0.000538
Step #3150 (total examples = 25200)	Loss: 0.001187
Step #3160 (total examples = 25280)	Loss: 0.000201
Step #3170 (total examples = 25360)	Loss: 0.011573
Step #3180 (total examples = 25440)	Loss: 0.000978
Step #3190 (total examples = 25520)	Loss: 0.216624
Step #3200 (total examples = 25600)	Loss: 0.003226
Step #3210 (total examples = 25680)	Loss: 0.444992
Step #3220 (total examples = 25760)	Loss: 0.000291
Step #3230 (total examples = 25840)	Loss: 0.814688
Step #3240 (total examples = 25920)	Loss: 0.008425
Step #1650 (total examples = 13200)	Loss: 0.193707
Step #1660 (total examples = 13280)	Loss: 0.037920
Step #1670 (total examples = 13360)	Loss: 0.079733
Step #1680 (total examples = 13440)	Loss: 0.017105
Step #1690 (total examples = 13520)	Loss: 0.078077
Step #1700 (total examples = 13600)	Loss: 0.069569
Step #1710 (total examples = 13680)	Loss: 0.061647
Step #1720 (total examples = 13760)	Loss: 0.000443
Step #1730 (total examples = 13840)	Loss: 0.027344
Step #1740 (total examples = 13920)	Loss: 0.000220
Step #1750 (total examples = 14000)	Loss: 0.111216
Step #1760 (total examples = 14080)	Loss: 0.056142
Step #1770 (total examples = 14160)	Loss: 0.010701
Step #1780 (total examples = 14240)	Loss: 0.115301
Step #1790 (total examples = 14320)	Loss: 0.003136
Step #1800 (total examples = 14400)	Loss: 0.180218
Step #1810 (total examples = 14480)	Loss: 0.002173
Step #1820 (total examples = 14560)	Loss: 0.003418
Step #1830 (total examples = 14640)	Loss: 0.007361
Step #1840 (total examples = 14720)	Loss: 0.024455
Step #1850 (total examples = 14800)	Loss: 0.010415
Step #1860 (total examples = 14880)	Loss: 0.230319
Step #1870 (total examples = 14960)	Loss: 0.050265
Step #1880 (total examples = 15040)	Loss: 0.089549
Step #1890 (total examples = 15120)	Loss: 0.002543
Step #1900 (total examples = 15200)	Loss: 0.437532
Step #1910 (total examples = 15280)	Loss: 0.006696
Step #1920 (total examples = 15360)	Loss: 0.443556
Step #1930 (total examples = 15440)	Loss: 0.368464
Step #1940 (total examples = 15520)	Loss: 0.660377
Step #1950 (total examples = 15600)	Loss: 1.031140
Step #1960 (total examples = 15680)	Loss: 0.021869
Step #1970 (total examples = 15760)	Loss: 0.004337
Step #1980 (total examples = 15840)	Loss: 0.019023
Step #1990 (total examples = 15920)	Loss: 0.002685
Step #2000 (total examples = 16000)	Loss: 0.005591
Step #2010 (total examples = 16080)	Loss: 0.526930
Step #2020 (total examples = 16160)	Loss: 0.020547
Step #2030 (total examples = 16240)	Loss: 0.000977
Step #2040 (total examples = 16320)	Loss: 0.000535
Step #2050 (total examples = 16400)	Loss: 0.326174
Step #2060 (total examples = 16480)	Loss: 0.049298
Step #2070 (total examples = 16560)	Loss: 0.245749
Step #2080 (total examples = 16640)	Loss: 0.002112
Step #2090 (total examples = 16720)	Loss: 0.021509
Step #2100 (total examples = 16800)	Loss: 1.413558
Step #2110 (total examples = 16880)	Loss: 0.013868
Step #2120 (total examples = 16960)	Loss: 0.007625
Step #2130 (total examples = 17040)	Loss: 0.184578
Step #2140 (total examples = 17120)	Loss: 0.039008
Step #2150 (total examples = 17200)	Loss: 0.009215
Step #2160 (total examples = 17280)	Loss: 0.000820
Step #2170 (total examples = 17360)	Loss: 0.854681
Step #2180 (total examples = 17440)	Loss: 0.004893
Step #2190 (total examples = 17520)	Loss: 0.023634
Step #2200 (total examples = 17600)	Loss: 0.012961
Step #2210 (total examples = 17680)	Loss: 0.000673
Step #2220 (total examples = 17760)	Loss: 0.036304
Step #2230 (total examples = 17840)	Loss: 0.000796
Step #2240 (total examples = 17920)	Loss: 0.004757
Step #2250 (total examples = 18000)	Loss: 0.009239
Step #2260 (total examples = 18080)	Loss: 0.171716
Step #2270 (total examples = 18160)	Loss: 0.000226
Step #2280 (total examples = 18240)	Loss: 0.071730
Step #2290 (total examples = 18320)	Loss: 0.122907
Step #2300 (total examples = 18400)	Loss: 0.007477
Step #2310 (total examples = 18480)	Loss: 0.000307
Step #2320 (total examples = 18560)	Loss: 1.000944
Step #2330 (total examples = 18640)	Loss: 0.329275
Step #2340 (total examples = 18720)	Loss: 0.019197
Step #2350 (total examples = 18800)	Loss: 0.044228
Step #2360 (total examples = 18880)	Loss: 0.051180
Step #2370 (total examples = 18960)	Loss: 0.031300
Step #2380 (total examples = 19040)	Loss: 0.190471
Step #2390 (total examples = 19120)	Loss: 0.005965
Step #2400 (total examples = 19200)	Loss: 0.136496
Step #2410 (total examples = 19280)	Loss: 0.000828
Step #2420 (total examples = 19360)	Loss: 0.196344
Step #2430 (total examples = 19440)	Loss: 0.103938
Step #2440 (total examples = 19520)	Loss: 0.083638
Step #2450 (total examples = 19600)	Loss: 0.634875
Step #2460 (total examples = 19680)	Loss: 0.006761
Step #2470 (total examples = 19760)	Loss: 1.730783
Step #2480 (total examples = 19840)	Loss: 0.060123
Step #2490 (total examples = 19920)	Loss: 0.236889
Step #2500 (total examples = 20000)	Loss: 0.251605
Step #2510 (total examples = 20080)	Loss: 0.010900
Step #2520 (total examples = 20160)	Loss: 0.003319
Step #2530 (total examples = 20240)	Loss: 0.001097
Step #2540 (total examples = 20320)	Loss: 0.011905
Step #2550 (total examples = 20400)	Loss: 0.001649
Step #2560 (total examples = 20480)	Loss: 0.017276
Step #2570 (total examples = 20560)	Loss: 0.005866
Step #2580 (total examples = 20640)	Loss: 0.021078
Step #2590 (total examples = 20720)	Loss: 0.008359
Step #2600 (total examples = 20800)	Loss: 0.011903
Step #2610 (total examples = 20880)	Loss: 0.167327
Step #2620 (total examples = 20960)	Loss: 0.092619
Step #2630 (total examples = 21040)	Loss: 0.001128
Step #2640 (total examples = 21120)	Loss: 0.043114
Step #2650 (total examples = 21200)	Loss: 0.266989
Step #2660 (total examples = 21280)	Loss: 0.000912
Step #2670 (total examples = 21360)	Loss: 0.000386
Step #2680 (total examples = 21440)	Loss: 0.031476
Step #2690 (total examples = 21520)	Loss: 0.088201
Step #2700 (total examples = 21600)	Loss: 0.039862
Step #2710 (total examples = 21680)	Loss: 0.116827
Step #2720 (total examples = 21760)	Loss: 0.001079
Step #2730 (total examples = 21840)	Loss: 0.001393
Step #2740 (total examples = 21920)	Loss: 0.070531
Step #2750 (total examples = 22000)	Loss: 0.006030
Step #2760 (total examples = 22080)	Loss: 0.109885
Step #2770 (total examples = 22160)	Loss: 0.124423
Step #2780 (total examples = 22240)	Loss: 0.002188
Step #2790 (total examples = 22320)	Loss: 0.093533
Step #2800 (total examples = 22400)	Loss: 0.010313
Step #2810 (total examples = 22480)	Loss: 0.027569
Step #2820 (total examples = 22560)	Loss: 0.000978
Step #2830 (total examples = 22640)	Loss: 0.002544
Step #2840 (total examples = 22720)	Loss: 0.053012
Step #2850 (total examples = 22800)	Loss: 0.010699
Step #2860 (total examples = 22880)	Loss: 0.134420
Step #2870 (total examples = 22960)	Loss: 0.051642
Step #2880 (total examples = 23040)	Loss: 0.040340
Step #2890 (total examples = 23120)	Loss: 0.076268
Step #2900 (total examples = 23200)	Loss: 0.004376
Step #2910 (total examples = 23280)	Loss: 0.005202
Step #2920 (total examples = 23360)	Loss: 0.118114
Step #2930 (total examples = 23440)	Loss: 0.136301
Step #2940 (total examples = 23520)	Loss: 0.000971
Step #2950 (total examples = 23600)	Loss: 0.524898
Step #2960 (total examples = 23680)	Loss: 0.006128
Step #2970 (total examples = 23760)	Loss: 0.040193
Step #2980 (total examples = 23840)	Loss: 0.007918
Step #2990 (total examples = 23920)	Loss: 0.009614
Step #3000 (total examples = 24000)	Loss: 0.002442
Step #3010 (total examples = 24080)	Loss: 0.024957
Step #3020 (total examples = 24160)	Loss: 0.037381
Step #3030 (total examples = 24240)	Loss: 0.037192
Step #3040 (total examples = 24320)	Loss: 0.873092
Step #3050 (total examples = 24400)	Loss: 0.004325
Step #3060 (total examples = 24480)	Loss: 0.001831
Step #3070 (total examples = 24560)	Loss: 0.000080
Step #3080 (total examples = 24640)	Loss: 0.020273
Step #3090 (total examples = 24720)	Loss: 0.039159
Step #3100 (total examples = 24800)	Loss: 0.000430
Step #3110 (total examples = 24880)	Loss: 0.009294
Step #3120 (total examples = 24960)	Loss: 0.175935
Step #3130 (total examples = 25040)	Loss: 0.001075
Step #3140 (total examples = 25120)	Loss: 0.347788
Step #3150 (total examples = 25200)	Loss: 0.003338
Step #3160 (total examples = 25280)	Loss: 0.173126
Step #3170 (total examples = 25360)	Loss: 0.074038
Step #3180 (total examples = 25440)	Loss: 0.874967
Step #3190 (total examples = 25520)	Loss: 0.001039
Step #3200 (total examples = 25600)	Loss: 0.005499
Step #3210 (total examples = 25680)	Loss: 0.206182
Step #3220 (total examples = 25760)	Loss: 0.145289
Step #3230 (total examples = 25840)	Loss: 0.002046
Step #3240 (total examples = 25920)	Loss: 0.003042
Step #3250 (total examples = 26000)	Loss: 0.012020
Step #3260 (total examples = 26080)	Loss: 0.022106
Step #3270 (total examples = 26160)	Loss: 0.022676
Step #3280 (total examples = 26240)	Loss: 0.000030
Step #3290 (total examples = 26320)	Loss: 0.002052
Step #3300 (total examples = 26400)	Loss: 0.495745
Step #3310 (total examples = 26480)	Loss: 0.004158
Step #3320 (total examples = 26560)	Loss: 0.042921
Step #3330 (total examples = 26640)	Loss: 0.513343
Step #3340 (total examples = 26720)	Loss: 0.028173
Step #3350 (total examples = 26800)	Loss: 0.000633
Step #3360 (total examples = 26880)	Loss: 0.005509
Step #3370 (total examples = 26960)	Loss: 0.010671
Step #3380 (total examples = 27040)	Loss: 0.268414
Step #3390 (total examples = 27120)	Loss: 0.352923
Step #3400 (total examples = 27200)	Loss: 0.013445
Step #3410 (total examples = 27280)	Loss: 0.022347
Step #3420 (total examples = 27360)	Loss: 0.133504
Step #3430 (total examples = 27440)	Loss: 0.047191
Step #3440 (total examples = 27520)	Loss: 0.143659
Step #3450 (total examples = 27600)	Loss: 0.001235
Step #3460 (total examples = 27680)	Loss: 0.146991
Step #3470 (total examples = 27760)	Loss: 0.073795
Step #3480 (total examples = 27840)	Loss: 0.022127
Step #3490 (total examples = 27920)	Loss: 0.070019
Step #3500 (total examples = 28000)	Loss: 0.018752
Step #3510 (total examples = 28080)	Loss: 0.025888
Step #3520 (total examples = 28160)	Loss: 0.027799
Step #3530 (total examples = 28240)	Loss: 0.030044
Step #3540 (total examples = 28320)	Loss: 0.607578
Step #3550 (total examples = 28400)	Loss: 0.001883
Step #3560 (total examples = 28480)	Loss: 0.003030
Step #3570 (total examples = 28560)	Loss: 0.016479
Step #3580 (total examples = 28640)	Loss: 0.049578
Step #3590 (total examples = 28720)	Loss: 0.006673
Step #3600 (total examples = 28800)	Loss: 0.066856
Step #3610 (total examples = 28880)	Loss: 0.251036
Step #3620 (total examples = 28960)	Loss: 0.000003
Step #3630 (total examples = 29040)	Loss: 0.000032
Step #3640 (total examples = 29120)	Loss: 0.251585
Step #3650 (total examples = 29200)	Loss: 0.364789
Step #3660 (total examples = 29280)	Loss: 0.026213
Step #3670 (total examples = 29360)	Loss: 0.005565
Step #3680 (total examples = 29440)	Loss: 0.004320
Step #3690 (total examples = 29520)	Loss: 0.045587
Step #3700 (total examples = 29600)	Loss: 0.078223
Step #3710 (total examples = 29680)	Loss: 0.003744
Step #3720 (total examples = 29760)	Loss: 0.100374
Step #3730 (total examples = 29840)	Loss: 0.000314
Step #3740 (total examples = 29920)	Loss: 0.408794
Step #3750 (total examples = 30000)	Loss: 0.090076
Step #3760 (total examples = 30080)	Loss: 0.191518
Step #3770 (total examples = 30160)	Loss: 0.000905
Step #3780 (total examples = 30240)	Loss: 0.012846
Step #3790 (total examples = 30320)	Loss: 0.000157
Step #3800 (total examples = 30400)	Loss: 0.051369
Step #3810 (total examples = 30480)	Loss: 0.001135
Step #3820 (total examples = 30560)	Loss: 0.001962
Step #3830 (total examples = 30640)	Loss: 0.016754
Step #3840 (total examples = 30720)	Loss: 0.004142
Step #3850 (total examples = 30800)	Loss: 0.015407
Step #3860 (total examples = 30880)	Loss: 0.000156
Step #3870 (total examples = 30960)	Loss: 0.181597
Step #3880 (total examples = 31040)	Loss: 0.001628
Step #3890 (total examples = 31120)	Loss: 0.312089
Step #3900 (total examples = 31200)	Loss: 0.313309
Step #3910 (total examples = 31280)	Loss: 0.111078
Step #3920 (total examples = 31360)	Loss: 0.065569
Step #3930 (total examples = 31440)	Loss: 0.097386
Step #3940 (total examples = 31520)	Loss: 0.126112
Step #3950 (total examples = 31600)	Loss: 0.013460
Step #3960 (total examples = 31680)	Loss: 0.128793
Step #3970 (total examples = 31760)	Loss: 0.002036
Step #3980 (total examples = 31840)	Loss: 0.003855
Step #3990 (total examples = 31920)	Loss: 0.002675

Step #3250 (total examples = 26000)	Loss: 0.184753
Step #3260 (total examples = 26080)	Loss: 0.000102
Step #3270 (total examples = 26160)	Loss: 0.130926
Step #3280 (total examples = 26240)	Loss: 0.417051
Step #3290 (total examples = 26320)	Loss: 0.008335
Step #3300 (total examples = 26400)	Loss: 0.004475
Step #3310 (total examples = 26480)	Loss: 0.023460
Step #3320 (total examples = 26560)	Loss: 0.001642
Step #3330 (total examples = 26640)	Loss: 0.045822
Step #3340 (total examples = 26720)	Loss: 0.012216
Step #3350 (total examples = 26800)	Loss: 0.005768
Step #3360 (total examples = 26880)	Loss: 0.002808
Step #3370 (total examples = 26960)	Loss: 0.003501
Step #3380 (total examples = 27040)	Loss: 0.011631
Step #3390 (total examples = 27120)	Loss: 0.016834
Step #3400 (total examples = 27200)	Loss: 0.692778
Step #3410 (total examples = 27280)	Loss: 0.001555
Step #3420 (total examples = 27360)	Loss: 0.335504
Step #3430 (total examples = 27440)	Loss: 0.001090
Step #3440 (total examples = 27520)	Loss: 0.386449
Step #3450 (total examples = 27600)	Loss: 0.619970
Step #3460 (total examples = 27680)	Loss: 0.034640
Step #3470 (total examples = 27760)	Loss: 0.494726
Step #3480 (total examples = 27840)	Loss: 0.106918
Step #3490 (total examples = 27920)	Loss: 0.000388
Step #3500 (total examples = 28000)	Loss: 0.001569
Step #3510 (total examples = 28080)	Loss: 0.019894
Step #3520 (total examples = 28160)	Loss: 0.373077
Step #3530 (total examples = 28240)	Loss: 0.190339
Step #3540 (total examples = 28320)	Loss: 0.004303
Step #3550 (total examples = 28400)	Loss: 0.016589
Step #3560 (total examples = 28480)	Loss: 0.001671
Step #3570 (total examples = 28560)	Loss: 0.021502
Step #3580 (total examples = 28640)	Loss: 0.002241
Step #3590 (total examples = 28720)	Loss: 0.459092
Step #3600 (total examples = 28800)	Loss: 0.163376
Step #3610 (total examples = 28880)	Loss: 0.000339
Step #3620 (total examples = 28960)	Loss: 0.001779
Step #3630 (total examples = 29040)	Loss: 0.023243
Step #3640 (total examples = 29120)	Loss: 0.000562
Step #3650 (total examples = 29200)	Loss: 1.494592
Step #3660 (total examples = 29280)	Loss: 0.141885
Step #3670 (total examples = 29360)	Loss: 0.000940
Step #3680 (total examples = 29440)	Loss: 0.002655
Step #3690 (total examples = 29520)	Loss: 0.037385
Step #3700 (total examples = 29600)	Loss: 0.264591
Step #3710 (total examples = 29680)	Loss: 0.116918
Step #3720 (total examples = 29760)	Loss: 0.012731
Step #3730 (total examples = 29840)	Loss: 0.000570
Step #3740 (total examples = 29920)	Loss: 0.000298
Step #3750 (total examples = 30000)	Loss: 0.021403
Step #3760 (total examples = 30080)	Loss: 0.003549
Step #3770 (total examples = 30160)	Loss: 0.057527
Step #3780 (total examples = 30240)	Loss: 0.007346
Step #3790 (total examples = 30320)	Loss: 0.037372
Step #3800 (total examples = 30400)	Loss: 0.191116
Step #3810 (total examples = 30480)	Loss: 0.031167
Step #3820 (total examples = 30560)	Loss: 0.011926
Step #3830 (total examples = 30640)	Loss: 0.001962
Step #3840 (total examples = 30720)	Loss: 0.333772
Step #3850 (total examples = 30800)	Loss: 0.192245
Step #3860 (total examples = 30880)	Loss: 0.157742
Step #3870 (total examples = 30960)	Loss: 0.002804
Step #3880 (total examples = 31040)	Loss: 0.004012
Step #3890 (total examples = 31120)	Loss: 0.525179
Step #3900 (total examples = 31200)	Loss: 0.001593
Step #3910 (total examples = 31280)	Loss: 0.009331
Step #3920 (total examples = 31360)	Loss: 0.010846
Step #3930 (total examples = 31440)	Loss: 0.417167
Step #3940 (total examples = 31520)	Loss: 0.083594
Step #3950 (total examples = 31600)	Loss: 0.000170
Step #3960 (total examples = 31680)	Loss: 0.000977
Step #3970 (total examples = 31760)	Loss: 0.463668
Step #3980 (total examples = 31840)	Loss: 0.005782
Step #3990 (total examples = 31920)	Loss: 0.001861
  1/313 [..............................] - ETA: 1:47 - loss: 33.3297 - accuracy: 0.9688  5/313 [..............................] - ETA: 4s - loss: 8.5724 - accuracy: 0.9812     9/313 [..............................] - ETA: 4s - loss: 13.0532 - accuracy: 0.9792 13/313 [>.............................] - ETA: 4s - loss: 13.0267 - accuracy: 0.9808 17/313 [>.............................] - ETA: 4s - loss: 13.6355 - accuracy: 0.9816 21/313 [=>............................] - ETA: 4s - loss: 12.2264 - accuracy: 0.9807 25/313 [=>............................] - ETA: 4s - loss: 13.1198 - accuracy: 0.9787 28/313 [=>............................] - ETA: 4s - loss: 11.8286 - accuracy: 0.9799 30/313 [=>............................] - ETA: 4s - loss: 11.7236 - accuracy: 0.9792 32/313 [==>...........................] - ETA: 5s - loss: 11.9674 - accuracy: 0.9785 34/313 [==>...........................] - ETA: 5s - loss: 11.6443 - accuracy: 0.9779 36/313 [==>...........................] - ETA: 5s - loss: 12.0360 - accuracy: 0.9766 38/313 [==>...........................] - ETA: 5s - loss: 11.9445 - accuracy: 0.9762 40/313 [==>...........................] - ETA: 5s - loss: 14.8778 - accuracy: 0.9742 42/313 [===>..........................] - ETA: 5s - loss: 16.0497 - accuracy: 0.9717 44/313 [===>..........................] - ETA: 5s - loss: 17.0947 - accuracy: 0.9709 46/313 [===>..........................] - ETA: 5s - loss: 16.4626 - accuracy: 0.9715 48/313 [===>..........................] - ETA: 5s - loss: 16.7683 - accuracy: 0.9707 50/313 [===>..........................] - ETA: 5s - loss: 16.1667 - accuracy: 0.9712 52/313 [===>..........................] - ETA: 5s - loss: 16.3293 - accuracy: 0.9712 54/313 [====>.........................] - ETA: 6s - loss: 16.0131 - accuracy: 0.9711 56/313 [====>.........................] - ETA: 6s - loss: 15.9194 - accuracy: 0.9715 58/313 [====>.........................] - ETA: 6s - loss: 16.0164 - accuracy: 0.9720 60/313 [====>.........................] - ETA: 6s - loss: 15.9705 - accuracy: 0.9724 63/313 [=====>........................] - ETA: 5s - loss: 15.2277 - accuracy: 0.9732 67/313 [=====>........................] - ETA: 5s - loss: 19.5482 - accuracy: 0.9692 71/313 [=====>........................] - ETA: 5s - loss: 19.3834 - accuracy: 0.9688 75/313 [======>.......................] - ETA: 5s - loss: 20.4898 - accuracy: 0.9683 79/313 [======>.......................] - ETA: 5s - loss: 19.9439 - accuracy: 0.9688 83/313 [======>.......................] - ETA: 5s - loss: 19.7837 - accuracy: 0.9691 87/313 [=======>......................] - ETA: 4s - loss: 19.7677 - accuracy: 0.9688 91/313 [=======>......................] - ETA: 4s - loss: 19.7940 - accuracy: 0.9691 95/313 [========>.....................] - ETA: 4s - loss: 19.5409 - accuracy: 0.9691 99/313 [========>.....................] - ETA: 4s - loss: 19.1154 - accuracy: 0.9697102/313 [========>.....................] - ETA: 4s - loss: 18.7028 - accuracy: 0.9703105/313 [=========>....................] - ETA: 4s - loss: 18.4278 - accuracy: 0.9705108/313 [=========>....................] - ETA: 4s - loss: 18.5642 - accuracy: 0.9705111/313 [=========>....................] - ETA: 4s - loss: 19.1073 - accuracy: 0.9704114/313 [=========>....................] - ETA: 4s - loss: 19.4193 - accuracy: 0.9704117/313 [==========>...................] - ETA: 3s - loss: 18.9214 - accuracy: 0.9712121/313 [==========>...................] - ETA: 3s - loss: 20.3862 - accuracy: 0.9698125/313 [==========>...................] - ETA: 3s - loss: 20.4449 - accuracy: 0.9695129/313 [===========>..................] - ETA: 3s - loss: 20.6418 - accuracy: 0.9695133/313 [===========>..................] - ETA: 3s - loss: 20.4889 - accuracy: 0.9697137/313 [============>.................] - ETA: 3s - loss: 20.3872 - accuracy: 0.9697141/313 [============>.................] - ETA: 3s - loss: 19.9921 - accuracy: 0.9701145/313 [============>.................] - ETA: 3s - loss: 19.7416 - accuracy: 0.9698149/313 [=============>................] - ETA: 3s - loss: 19.7604 - accuracy: 0.9700153/313 [=============>................] - ETA: 3s - loss: 19.8735 - accuracy: 0.9696157/313 [==============>...............] - ETA: 2s - loss: 19.3672 - accuracy: 0.9703161/313 [==============>...............] - ETA: 2s - loss: 18.8860 - accuracy: 0.9711165/313 [==============>...............] - ETA: 2s - loss: 18.5562 - accuracy: 0.9714169/313 [===============>..............] - ETA: 2s - loss: 18.2971 - accuracy: 0.9719173/313 [===============>..............] - ETA: 2s - loss: 17.8740 - accuracy: 0.9725177/313 [===============>..............] - ETA: 2s - loss: 17.5576 - accuracy: 0.9728181/313 [================>.............] - ETA: 2s - loss: 17.3042 - accuracy: 0.9731185/313 [================>.............] - ETA: 2s - loss: 17.2043 - accuracy: 0.9733188/313 [=================>............] - ETA: 2s - loss: 17.8641 - accuracy: 0.9726191/313 [=================>............] - ETA: 2s - loss: 17.6568 - accuracy: 0.9722194/313 [=================>............] - ETA: 2s - loss: 17.3837 - accuracy: 0.9726197/313 [=================>............] - ETA: 2s - loss: 17.1190 - accuracy: 0.9730200/313 [==================>...........] - ETA: 2s - loss: 16.8622 - accuracy: 0.9734203/313 [==================>...........] - ETA: 2s - loss: 16.6130 - accuracy: 0.9738206/313 [==================>...........] - ETA: 1s - loss: 16.4796 - accuracy: 0.9739209/313 [===================>..........] - ETA: 1s - loss: 16.7004 - accuracy: 0.9738212/313 [===================>..........] - ETA: 1s - loss: 16.5539 - accuracy: 0.9738215/313 [===================>..........] - ETA: 1s - loss: 16.3229 - accuracy: 0.9741218/313 [===================>..........] - ETA: 1s - loss: 16.0993 - accuracy: 0.9743221/313 [====================>.........] - ETA: 1s - loss: 15.8807 - accuracy: 0.9747224/313 [====================>.........] - ETA: 1s - loss: 15.6680 - accuracy: 0.9750227/313 [====================>.........] - ETA: 1s - loss: 15.5879 - accuracy: 0.9752230/313 [=====================>........] - ETA: 1s - loss: 15.3846 - accuracy: 0.9755233/313 [=====================>........] - ETA: 1s - loss: 15.2796 - accuracy: 0.9756236/313 [=====================>........] - ETA: 1s - loss: 15.0854 - accuracy: 0.9759239/313 [=====================>........] - ETA: 1s - loss: 14.8960 - accuracy: 0.9762242/313 [======================>.......] - ETA: 1s - loss: 14.7286 - accuracy: 0.9764245/313 [======================>.......] - ETA: 1s - loss: 14.5483 - accuracy: 0.9767248/313 [======================>.......] - ETA: 1s - loss: 14.4685 - accuracy: 0.9766251/313 [=======================>......] - ETA: 1s - loss: 14.2955 - accuracy: 0.9768254/313 [=======================>......] - ETA: 1s - loss: 14.3255 - accuracy: 0.9767257/313 [=======================>......] - ETA: 1s - loss: 14.1583 - accuracy: 0.9770260/313 [=======================>......] - ETA: 0s - loss: 13.9949 - accuracy: 0.9773263/313 [========================>.....] - ETA: 0s - loss: 13.8353 - accuracy: 0.9775266/313 [========================>.....] - ETA: 0s - loss: 13.7064 - accuracy: 0.9777269/313 [========================>.....] - ETA: 0s - loss: 13.5893 - accuracy: 0.9778272/313 [=========================>....] - ETA: 0s - loss: 13.4395 - accuracy: 0.9781276/313 [=========================>....] - ETA: 0s - loss: 13.2447 - accuracy: 0.9784280/313 [=========================>....] - ETA: 0s - loss: 13.0555 - accuracy: 0.9787283/313 [==========================>...] - ETA: 0s - loss: 13.3685 - accuracy: 0.9785286/313 [==========================>...] - ETA: 0s - loss: 13.2283 - accuracy: 0.9787289/313 [==========================>...] - ETA: 0s - loss: 13.0910 - accuracy: 0.9789292/313 [==========================>...] - ETA: 0s - loss: 12.9565 - accuracy: 0.9791295/313 [===========================>..] - ETA: 0s - loss: 12.8247 - accuracy: 0.9793298/313 [===========================>..] - ETA: 0s - loss: 12.7000 - accuracy: 0.9794302/313 [===========================>..] - ETA: 0s - loss: 12.5318 - accuracy: 0.9797306/313 [============================>.] - ETA: 0s - loss: 13.3175 - accuracy: 0.9794310/313 [============================>.] - ETA: 0s - loss: 13.3672 - accuracy: 0.9792313/313 [==============================] - 6s 18ms/step - loss: 13.4186 - accuracy: 0.9792
Final model accuracy: 0.979200
Total training time: 382.227779
2021-12-03 20:37:29.102746: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/lang/Python/3.7.2-intel-2018.5.274/lib:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib64:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib:/opt/apps/software/math/GMP/6.1.2-GCCcore-6.3.0/lib:/opt/apps/software/tools/XZ/5.2.4-GCCcore-6.3.0/lib:/opt/apps/software/devel/SQLite/3.27.2-GCCcore-6.3.0/lib:/opt/apps/software/lang/Tcl/8.6.9-GCCcore-6.3.0/lib:/opt/apps/software/devel/ncurses/6.1-intel-2018.5.274/lib:/opt/apps/software/lib/libreadline/7.0-GCCcore-6.3.0/lib:/opt/apps/software/lib/zlib/1.2.11-GCCcore-6.3.0/lib:/opt/apps/software/tools/bzip2/1.0.6/lib:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/mkl/lib/intel64:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/lib/intel64:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/lib64:/opt/apps/software/lib/libfabric/1.9.1/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/tbb/lib/intel64/gcc4.4:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/tools/binutils/2.26-GCCcore-6.3.0/lib:/opt/apps/software/compiler/GCCcore/6.3.0/lib/gcc/x86_64-pc-linux-gnu/6.3.0:/opt/apps/software/compiler/GCCcore/6.3.0/lib64:/opt/apps/software/compiler/GCCcore/6.3.0/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/mic/lib
2021-12-03 20:37:29.102836: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-03 20:37:29.128718: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/lang/Python/3.7.2-intel-2018.5.274/lib:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib64:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib:/opt/apps/software/math/GMP/6.1.2-GCCcore-6.3.0/lib:/opt/apps/software/tools/XZ/5.2.4-GCCcore-6.3.0/lib:/opt/apps/software/devel/SQLite/3.27.2-GCCcore-6.3.0/lib:/opt/apps/software/lang/Tcl/8.6.9-GCCcore-6.3.0/lib:/opt/apps/software/devel/ncurses/6.1-intel-2018.5.274/lib:/opt/apps/software/lib/libreadline/7.0-GCCcore-6.3.0/lib:/opt/apps/software/lib/zlib/1.2.11-GCCcore-6.3.0/lib:/opt/apps/software/tools/bzip2/1.0.6/lib:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/mkl/lib/intel64:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/lib/intel64:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/lib64:/opt/apps/software/lib/libfabric/1.9.1/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/tbb/lib/intel64/gcc4.4:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/tools/binutils/2.26-GCCcore-6.3.0/lib:/opt/apps/software/compiler/GCCcore/6.3.0/lib/gcc/x86_64-pc-linux-gnu/6.3.0:/opt/apps/software/compiler/GCCcore/6.3.0/lib64:/opt/apps/software/compiler/GCCcore/6.3.0/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/mic/lib
2021-12-03 20:37:29.128870: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-03 20:37:32.911053: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2021-12-03 20:37:32.911222: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: gpu-0001
2021-12-03 20:37:32.911271: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: gpu-0001
2021-12-03 20:37:32.911373: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 465.19.1
2021-12-03 20:37:32.911468: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 465.19.1
2021-12-03 20:37:32.911545: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 465.19.1
2021-12-03 20:37:32.912482: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-12-03 20:37:32.936138: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/lang/Python/3.7.2-intel-2018.5.274/lib:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib64:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib:/opt/apps/software/math/GMP/6.1.2-GCCcore-6.3.0/lib:/opt/apps/software/tools/XZ/5.2.4-GCCcore-6.3.0/lib:/opt/apps/software/devel/SQLite/3.27.2-GCCcore-6.3.0/lib:/opt/apps/software/lang/Tcl/8.6.9-GCCcore-6.3.0/lib:/opt/apps/software/devel/ncurses/6.1-intel-2018.5.274/lib:/opt/apps/software/lib/libreadline/7.0-GCCcore-6.3.0/lib:/opt/apps/software/lib/zlib/1.2.11-GCCcore-6.3.0/lib:/opt/apps/software/tools/bzip2/1.0.6/lib:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/mkl/lib/intel64:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/lib/intel64:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/lib64:/opt/apps/software/lib/libfabric/1.9.1/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/tbb/lib/intel64/gcc4.4:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/tools/binutils/2.26-GCCcore-6.3.0/lib:/opt/apps/software/compiler/GCCcore/6.3.0/lib/gcc/x86_64-pc-linux-gnu/6.3.0:/opt/apps/software/compiler/GCCcore/6.3.0/lib64:/opt/apps/software/compiler/GCCcore/6.3.0/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/mic/lib
2021-12-03 20:37:32.936242: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-03 20:37:32.936303: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node-0001): /proc/driver/nvidia/version does not exist
===========
rank: 0
Batch size: 8
Total number of batches: 8000
Total training examples: 64000
Num of workers: 2
===========
Step #0 (total examples = 0)	Loss: 2.249752
Step #10 (total examples = 80)	Loss: 2.238681
Step #20 (total examples = 160)	Loss: 1.849917
Step #30 (total examples = 240)	Loss: 0.221275
Step #40 (total examples = 320)	Loss: 0.258780
Step #50 (total examples = 400)	Loss: 0.840941
Step #60 (total examples = 480)	Loss: 0.389403
Step #70 (total examples = 560)	Loss: 0.087694
Step #80 (total examples = 640)	Loss: 1.419973
Step #90 (total examples = 720)	Loss: 0.198014
Step #100 (total examples = 800)	Loss: 0.311201
Step #110 (total examples = 880)	Loss: 0.103239
Step #120 (total examples = 960)	Loss: 0.120657
Step #130 (total examples = 1040)	Loss: 0.137265
Step #140 (total examples = 1120)	Loss: 0.944863
Step #150 (total examples = 1200)	Loss: 0.062804
Step #160 (total examples = 1280)	Loss: 0.076673
Step #170 (total examples = 1360)	Loss: 0.046193
Step #180 (total examples = 1440)	Loss: 1.046943
Step #190 (total examples = 1520)	Loss: 0.449137
Step #200 (total examples = 1600)	Loss: 0.874702
Step #210 (total examples = 1680)	Loss: 0.560689
Step #220 (total examples = 1760)	Loss: 0.115056
Step #230 (total examples = 1840)	Loss: 0.293835
Step #240 (total examples = 1920)	Loss: 0.032995
Step #250 (total examples = 2000)	Loss: 0.222239
Step #260 (total examples = 2080)	Loss: 0.015227
Step #270 (total examples = 2160)	Loss: 0.125428
Step #280 (total examples = 2240)	Loss: 0.418129
Step #290 (total examples = 2320)	Loss: 0.038825
Step #300 (total examples = 2400)	Loss: 0.393654
Step #310 (total examples = 2480)	Loss: 0.112468
Step #320 (total examples = 2560)	Loss: 0.097072
Step #330 (total examples = 2640)	Loss: 1.112945
Step #340 (total examples = 2720)	Loss: 0.335380
Step #350 (total examples = 2800)	Loss: 0.181756
Step #360 (total examples = 2880)	Loss: 0.099008
Step #370 (total examples = 2960)	Loss: 0.329078
Step #380 (total examples = 3040)	Loss: 0.844906
Step #390 (total examples = 3120)	Loss: 0.010407
Step #400 (total examples = 3200)	Loss: 0.005159
Step #410 (total examples = 3280)	Loss: 0.181649
Step #420 (total examples = 3360)	Loss: 0.685850
Step #430 (total examples = 3440)	Loss: 0.034769
Step #440 (total examples = 3520)	Loss: 0.303878
Step #450 (total examples = 3600)	Loss: 0.080638
Step #460 (total examples = 3680)	Loss: 0.229799
Step #470 (total examples = 3760)	Loss: 0.123011
Step #480 (total examples = 3840)	Loss: 0.054138
Step #490 (total examples = 3920)	Loss: 1.427756
Step #500 (total examples = 4000)	Loss: 0.001669
Step #510 (total examples = 4080)	Loss: 0.005470
Step #520 (total examples = 4160)	Loss: 0.028952
Step #530 (total examples = 4240)	Loss: 0.035087
Step #540 (total examples = 4320)	Loss: 0.011913
Step #550 (total examples = 4400)	Loss: 0.007068
Step #560 (total examples = 4480)	Loss: 0.222571
Step #570 (total examples = 4560)	Loss: 0.008906
Step #580 (total examples = 4640)	Loss: 0.003811
Step #590 (total examples = 4720)	Loss: 0.096473
Step #600 (total examples = 4800)	Loss: 0.687042
Step #610 (total examples = 4880)	Loss: 0.019063
Step #620 (total examples = 4960)	Loss: 0.057737
Step #630 (total examples = 5040)	Loss: 0.005467
Step #640 (total examples = 5120)	Loss: 0.069993
Step #650 (total examples = 5200)	Loss: 0.054556
Step #660 (total examples = 5280)	Loss: 0.146681
Step #670 (total examples = 5360)	Loss: 0.065924
Step #680 (total examples = 5440)	Loss: 0.009519
Step #690 (total examples = 5520)	Loss: 0.022674
Step #700 (total examples = 5600)	Loss: 0.145085
Step #710 (total examples = 5680)	Loss: 0.004697
Step #720 (total examples = 5760)	Loss: 0.065511
Step #730 (total examples = 5840)	Loss: 0.018850
Step #740 (total examples = 5920)	Loss: 0.061793
Step #750 (total examples = 6000)	Loss: 0.048645
Step #760 (total examples = 6080)	Loss: 0.284847
Step #770 (total examples = 6160)	Loss: 0.006038
Step #780 (total examples = 6240)	Loss: 0.011193
Step #790 (total examples = 6320)	Loss: 0.001852
Step #800 (total examples = 6400)	Loss: 0.486073
Step #810 (total examples = 6480)	Loss: 0.057227
Step #820 (total examples = 6560)	Loss: 0.094856
Step #830 (total examples = 6640)	Loss: 0.025977
Step #840 (total examples = 6720)	Loss: 0.042683
Step #850 (total examples = 6800)	Loss: 0.012554
Step #860 (total examples = 6880)	Loss: 0.190581
Step #870 (total examples = 6960)	Loss: 0.009209
Step #880 (total examples = 7040)	Loss: 0.013764
Step #890 (total examples = 7120)	Loss: 0.131287
Step #900 (total examples = 7200)	Loss: 0.015041
Step #910 (total examples = 7280)	Loss: 0.156340
Step #920 (total examples = 7360)	Loss: 0.063566
Step #930 (total examples = 7440)	Loss: 0.002819
Step #940 (total examples = 7520)	Loss: 0.020339
Step #950 (total examples = 7600)	Loss: 0.004853
Step #960 (total examples = 7680)	Loss: 0.238440
Step #970 (total examples = 7760)	Loss: 0.311056
Step #980 (total examples = 7840)	Loss: 0.014866
Step #990 (total examples = 7920)	Loss: 0.594763
Step #1000 (total examples = 8000)	Loss: 0.078397
Step #1010 (total examples = 8080)	Loss: 0.011751
Step #1020 (total examples = 8160)	Loss: 0.034245
Step #1030 (total examples = 8240)	Loss: 0.059241
Step #1040 (total examples = 8320)	Loss: 0.037369
Step #1050 (total examples = 8400)	Loss: 0.017917
Step #1060 (total examples = 8480)	Loss: 0.084642
Step #1070 (total examples = 8560)	Loss: 0.313838
Step #1080 (total examples = 8640)	Loss: 0.333569
Step #1090 (total examples = 8720)	Loss: 0.047764
Step #1100 (total examples = 8800)	Loss: 0.001662
Step #1110 (total examples = 8880)	Loss: 0.020641
Step #1120 (total examples = 8960)	Loss: 0.004522
Step #1130 (total examples = 9040)	Loss: 0.074625
Step #1140 (total examples = 9120)	Loss: 0.079527
Step #1150 (total examples = 9200)	Loss: 0.000336
Step #1160 (total examples = 9280)	Loss: 0.006818
Step #1170 (total examples = 9360)	Loss: 0.040406
Step #1180 (total examples = 9440)	Loss: 0.023660
Step #1190 (total examples = 9520)	Loss: 0.036316
Step #1200 (total examples = 9600)	Loss: 0.071267
Step #1210 (total examples = 9680)	Loss: 0.146301
Step #1220 (total examples = 9760)	Loss: 0.017683
Step #1230 (total examples = 9840)	Loss: 0.065684
Step #1240 (total examples = 9920)	Loss: 0.002921
Step #1250 (total examples = 10000)	Loss: 0.049739
Step #1260 (total examples = 10080)	Loss: 0.132833
Step #1270 (total examples = 10160)	Loss: 0.017353
Step #1280 (total examples = 10240)	Loss: 0.000759
Step #1290 (total examples = 10320)	Loss: 0.023758
Step #1300 (total examples = 10400)	Loss: 0.149463
Step #1310 (total examples = 10480)	Loss: 0.002285
Step #1320 (total examples = 10560)	Loss: 0.122407
Step #1330 (total examples = 10640)	Loss: 0.498811
Step #1340 (total examples = 10720)	Loss: 0.005263
Step #1350 (total examples = 10800)	Loss: 0.211433
Step #1360 (total examples = 10880)	Loss: 0.248481
Step #1370 (total examples = 10960)	Loss: 1.113853
Step #1380 (total examples = 11040)	Loss: 0.150921
Step #1390 (total examples = 11120)	Loss: 0.005651
Step #1400 (total examples = 11200)	Loss: 0.024108
Step #1410 (total examples = 11280)	Loss: 0.010856
Step #1420 (total examples = 11360)	Loss: 0.013283
Step #1430 (total examples = 11440)	Loss: 0.016922
Step #1440 (total examples = 11520)	Loss: 0.306438
Step #1450 (total examples = 11600)	Loss: 0.961641
Step #1460 (total examples = 11680)	Loss: 0.051490
Step #1470 (total examples = 11760)	Loss: 0.115147
Step #1480 (total examples = 11840)	Loss: 0.262303
Step #1490 (total examples = 11920)	Loss: 0.121053
Step #1500 (total examples = 12000)	Loss: 0.005902
Step #1510 (total examples = 12080)	Loss: 0.005048
Step #1520 (total examples = 12160)	Loss: 0.072524
Step #1530 (total examples = 12240)	Loss: 0.034792
Step #1540 (total examples = 12320)	Loss: 0.284563
Step #1550 (total examples = 12400)	Loss: 0.238836
Step #1560 (total examples = 12480)	Loss: 0.051099
Step #1570 (total examples = 12560)	Loss: 0.000372
Step #1580 (total examples = 12640)	Loss: 0.040341
Step #1590 (total examples = 12720)	Loss: 0.007730
Step #1600 (total examples = 12800)	Loss: 0.001328
Step #1610 (total examples = 12880)	Loss: 0.050058
Step #1620 (total examples = 12960)	Loss: 0.000691
Step #1630 (total examples = 13040)	Loss: 0.004999===========
rank: 1
===========
Step #0 (total examples = 0)	Loss: 2.293703
Step #10 (total examples = 80)	Loss: 2.157740
Step #20 (total examples = 160)	Loss: 0.581264
Step #30 (total examples = 240)	Loss: 0.881704
Step #40 (total examples = 320)	Loss: 0.986224
Step #50 (total examples = 400)	Loss: 0.327179
Step #60 (total examples = 480)	Loss: 0.217354
Step #70 (total examples = 560)	Loss: 0.348360
Step #80 (total examples = 640)	Loss: 0.566894
Step #90 (total examples = 720)	Loss: 0.247108
Step #100 (total examples = 800)	Loss: 0.217524
Step #110 (total examples = 880)	Loss: 0.249726
Step #120 (total examples = 960)	Loss: 0.274296
Step #130 (total examples = 1040)	Loss: 0.089881
Step #140 (total examples = 1120)	Loss: 0.163791
Step #150 (total examples = 1200)	Loss: 0.145550
Step #160 (total examples = 1280)	Loss: 0.508201
Step #170 (total examples = 1360)	Loss: 0.187571
Step #180 (total examples = 1440)	Loss: 0.105390
Step #190 (total examples = 1520)	Loss: 0.043284
Step #200 (total examples = 1600)	Loss: 0.162838
Step #210 (total examples = 1680)	Loss: 0.086509
Step #220 (total examples = 1760)	Loss: 0.496443
Step #230 (total examples = 1840)	Loss: 0.163423
Step #240 (total examples = 1920)	Loss: 0.150985
Step #250 (total examples = 2000)	Loss: 0.020033
Step #260 (total examples = 2080)	Loss: 0.059717
Step #270 (total examples = 2160)	Loss: 0.264086
Step #280 (total examples = 2240)	Loss: 0.052932
Step #290 (total examples = 2320)	Loss: 0.100356
Step #300 (total examples = 2400)	Loss: 0.798822
Step #310 (total examples = 2480)	Loss: 0.637904
Step #320 (total examples = 2560)	Loss: 1.456828
Step #330 (total examples = 2640)	Loss: 0.374882
Step #340 (total examples = 2720)	Loss: 0.091358
Step #350 (total examples = 2800)	Loss: 0.016038
Step #360 (total examples = 2880)	Loss: 0.199690
Step #370 (total examples = 2960)	Loss: 0.006766
Step #380 (total examples = 3040)	Loss: 0.072691
Step #390 (total examples = 3120)	Loss: 0.183851
Step #400 (total examples = 3200)	Loss: 0.047745
Step #410 (total examples = 3280)	Loss: 0.429444
Step #420 (total examples = 3360)	Loss: 0.017722
Step #430 (total examples = 3440)	Loss: 0.059484
Step #440 (total examples = 3520)	Loss: 0.199218
Step #450 (total examples = 3600)	Loss: 0.009819
Step #460 (total examples = 3680)	Loss: 0.017706
Step #470 (total examples = 3760)	Loss: 0.080189
Step #480 (total examples = 3840)	Loss: 0.166089
Step #490 (total examples = 3920)	Loss: 0.159905
Step #500 (total examples = 4000)	Loss: 0.022783
Step #510 (total examples = 4080)	Loss: 0.066432
Step #520 (total examples = 4160)	Loss: 0.176034
Step #530 (total examples = 4240)	Loss: 0.009277
Step #540 (total examples = 4320)	Loss: 0.227349
Step #550 (total examples = 4400)	Loss: 0.048618
Step #560 (total examples = 4480)	Loss: 0.006223
Step #570 (total examples = 4560)	Loss: 0.034357
Step #580 (total examples = 4640)	Loss: 0.033193
Step #590 (total examples = 4720)	Loss: 0.009354
Step #600 (total examples = 4800)	Loss: 0.254658
Step #610 (total examples = 4880)	Loss: 0.277718
Step #620 (total examples = 4960)	Loss: 0.085340
Step #630 (total examples = 5040)	Loss: 0.078663
Step #640 (total examples = 5120)	Loss: 0.252505
Step #650 (total examples = 5200)	Loss: 0.188916
Step #660 (total examples = 5280)	Loss: 0.105376
Step #670 (total examples = 5360)	Loss: 0.080668
Step #680 (total examples = 5440)	Loss: 0.023880
Step #690 (total examples = 5520)	Loss: 0.040856
Step #700 (total examples = 5600)	Loss: 0.007561
Step #710 (total examples = 5680)	Loss: 0.199014
Step #720 (total examples = 5760)	Loss: 0.007009
Step #730 (total examples = 5840)	Loss: 0.573118
Step #740 (total examples = 5920)	Loss: 0.101337
Step #750 (total examples = 6000)	Loss: 0.428365
Step #760 (total examples = 6080)	Loss: 0.062250
Step #770 (total examples = 6160)	Loss: 0.021434
Step #780 (total examples = 6240)	Loss: 0.189074
Step #790 (total examples = 6320)	Loss: 0.016107
Step #800 (total examples = 6400)	Loss: 0.121685
Step #810 (total examples = 6480)	Loss: 0.098947
Step #820 (total examples = 6560)	Loss: 0.015277
Step #830 (total examples = 6640)	Loss: 0.114038
Step #840 (total examples = 6720)	Loss: 0.134885
Step #850 (total examples = 6800)	Loss: 0.006026
Step #860 (total examples = 6880)	Loss: 0.013680
Step #870 (total examples = 6960)	Loss: 0.005518
Step #880 (total examples = 7040)	Loss: 0.039261
Step #890 (total examples = 7120)	Loss: 0.011416
Step #900 (total examples = 7200)	Loss: 0.276649
Step #910 (total examples = 7280)	Loss: 0.058630
Step #920 (total examples = 7360)	Loss: 0.147718
Step #930 (total examples = 7440)	Loss: 0.109368
Step #940 (total examples = 7520)	Loss: 0.150257
Step #950 (total examples = 7600)	Loss: 0.968641
Step #960 (total examples = 7680)	Loss: 0.000696
Step #970 (total examples = 7760)	Loss: 0.041572
Step #980 (total examples = 7840)	Loss: 0.335685
Step #990 (total examples = 7920)	Loss: 0.051804
Step #1000 (total examples = 8000)	Loss: 0.204265
Step #1010 (total examples = 8080)	Loss: 0.136759
Step #1020 (total examples = 8160)	Loss: 0.336404
Step #1030 (total examples = 8240)	Loss: 0.089442
Step #1040 (total examples = 8320)	Loss: 0.042497
Step #1050 (total examples = 8400)	Loss: 0.033807
Step #1060 (total examples = 8480)	Loss: 0.053884
Step #1070 (total examples = 8560)	Loss: 0.046249
Step #1080 (total examples = 8640)	Loss: 0.069492
Step #1090 (total examples = 8720)	Loss: 0.012678
Step #1100 (total examples = 8800)	Loss: 0.049921
Step #1110 (total examples = 8880)	Loss: 0.102571
Step #1120 (total examples = 8960)	Loss: 0.001473
Step #1130 (total examples = 9040)	Loss: 0.051587
Step #1140 (total examples = 9120)	Loss: 0.033997
Step #1150 (total examples = 9200)	Loss: 0.035439
Step #1160 (total examples = 9280)	Loss: 0.023902
Step #1170 (total examples = 9360)	Loss: 0.010926
Step #1180 (total examples = 9440)	Loss: 0.007544
Step #1190 (total examples = 9520)	Loss: 0.004502
Step #1200 (total examples = 9600)	Loss: 0.004711
Step #1210 (total examples = 9680)	Loss: 0.005288
Step #1220 (total examples = 9760)	Loss: 0.002539
Step #1230 (total examples = 9840)	Loss: 0.195196
Step #1240 (total examples = 9920)	Loss: 0.053831
Step #1250 (total examples = 10000)	Loss: 0.003036
Step #1260 (total examples = 10080)	Loss: 0.009543
Step #1270 (total examples = 10160)	Loss: 0.360253
Step #1280 (total examples = 10240)	Loss: 0.001110
Step #1290 (total examples = 10320)	Loss: 0.007130
Step #1300 (total examples = 10400)	Loss: 0.007075
Step #1310 (total examples = 10480)	Loss: 0.001554
Step #1320 (total examples = 10560)	Loss: 0.439029
Step #1330 (total examples = 10640)	Loss: 0.016781
Step #1340 (total examples = 10720)	Loss: 0.029560
Step #1350 (total examples = 10800)	Loss: 0.100394
Step #1360 (total examples = 10880)	Loss: 0.016112
Step #1370 (total examples = 10960)	Loss: 1.058348
Step #1380 (total examples = 11040)	Loss: 0.576197
Step #1390 (total examples = 11120)	Loss: 0.251707
Step #1400 (total examples = 11200)	Loss: 0.008652
Step #1410 (total examples = 11280)	Loss: 0.033691
Step #1420 (total examples = 11360)	Loss: 0.004440
Step #1430 (total examples = 11440)	Loss: 0.247267
Step #1440 (total examples = 11520)	Loss: 0.388320
Step #1450 (total examples = 11600)	Loss: 0.001401
Step #1460 (total examples = 11680)	Loss: 0.008526
Step #1470 (total examples = 11760)	Loss: 0.004539
Step #1480 (total examples = 11840)	Loss: 0.005340
Step #1490 (total examples = 11920)	Loss: 0.330843
Step #1500 (total examples = 12000)	Loss: 0.006606
Step #1510 (total examples = 12080)	Loss: 0.002322
Step #1520 (total examples = 12160)	Loss: 0.119832
Step #1530 (total examples = 12240)	Loss: 0.043010
Step #1540 (total examples = 12320)	Loss: 0.816938
Step #1550 (total examples = 12400)	Loss: 0.162174
Step #1560 (total examples = 12480)	Loss: 0.000170
Step #1570 (total examples = 12560)	Loss: 0.199140
Step #1580 (total examples = 12640)	Loss: 0.002077
Step #1590 (total examples = 12720)	Loss: 0.002150
Step #1600 (total examples = 12800)	Loss: 0.180024
Step #1610 (total examples = 12880)	Loss: 0.060558
Step #1620 (total examples = 12960)	Loss: 0.691741
Step #1630 (total examples = 13040)	Loss: 0.001383
Step #1640 (total examples = 13120)	Loss: 0.012707
Step #1640 (total examples = 13120)	Loss: 0.134117
Step #1650 (total examples = 13200)	Loss: 0.076601
Step #1660 (total examples = 13280)	Loss: 0.156215
Step #1670 (total examples = 13360)	Loss: 0.087790
Step #1680 (total examples = 13440)	Loss: 0.004385
Step #1690 (total examples = 13520)	Loss: 0.030767
Step #1700 (total examples = 13600)	Loss: 0.003456
Step #1710 (total examples = 13680)	Loss: 0.006549
Step #1720 (total examples = 13760)	Loss: 0.000430
Step #1730 (total examples = 13840)	Loss: 0.008377
Step #1740 (total examples = 13920)	Loss: 0.062991
Step #1750 (total examples = 14000)	Loss: 0.011813
Step #1760 (total examples = 14080)	Loss: 0.036052
Step #1770 (total examples = 14160)	Loss: 0.004257
Step #1780 (total examples = 14240)	Loss: 0.040763
Step #1790 (total examples = 14320)	Loss: 0.039526
Step #1800 (total examples = 14400)	Loss: 0.052575
Step #1810 (total examples = 14480)	Loss: 0.002093
Step #1820 (total examples = 14560)	Loss: 0.018467
Step #1830 (total examples = 14640)	Loss: 0.383225
Step #1840 (total examples = 14720)	Loss: 0.010101
Step #1850 (total examples = 14800)	Loss: 0.237754
Step #1860 (total examples = 14880)	Loss: 0.000696
Step #1870 (total examples = 14960)	Loss: 0.017527
Step #1880 (total examples = 15040)	Loss: 0.002884
Step #1890 (total examples = 15120)	Loss: 0.508353
Step #1900 (total examples = 15200)	Loss: 0.209971
Step #1910 (total examples = 15280)	Loss: 0.057866
Step #1920 (total examples = 15360)	Loss: 0.073273
Step #1930 (total examples = 15440)	Loss: 0.000458
Step #1940 (total examples = 15520)	Loss: 0.007794
Step #1950 (total examples = 15600)	Loss: 0.064422
Step #1960 (total examples = 15680)	Loss: 0.031674
Step #1970 (total examples = 15760)	Loss: 0.091421
Step #1980 (total examples = 15840)	Loss: 0.846574
Step #1990 (total examples = 15920)	Loss: 0.012238
Step #2000 (total examples = 16000)	Loss: 0.016408
Step #2010 (total examples = 16080)	Loss: 0.528861
Step #2020 (total examples = 16160)	Loss: 0.003099
Step #2030 (total examples = 16240)	Loss: 0.106301
Step #2040 (total examples = 16320)	Loss: 0.008362
Step #2050 (total examples = 16400)	Loss: 0.001826
Step #2060 (total examples = 16480)	Loss: 0.061569
Step #2070 (total examples = 16560)	Loss: 0.004221
Step #2080 (total examples = 16640)	Loss: 0.001231
Step #2090 (total examples = 16720)	Loss: 0.000157
Step #2100 (total examples = 16800)	Loss: 0.001526
Step #2110 (total examples = 16880)	Loss: 0.006970
Step #2120 (total examples = 16960)	Loss: 0.059331
Step #2130 (total examples = 17040)	Loss: 0.000593
Step #2140 (total examples = 17120)	Loss: 0.006372
Step #2150 (total examples = 17200)	Loss: 0.054265
Step #2160 (total examples = 17280)	Loss: 0.002069
Step #2170 (total examples = 17360)	Loss: 0.002052
Step #2180 (total examples = 17440)	Loss: 0.001143
Step #2190 (total examples = 17520)	Loss: 0.000287
Step #2200 (total examples = 17600)	Loss: 0.012895
Step #2210 (total examples = 17680)	Loss: 0.335712
Step #2220 (total examples = 17760)	Loss: 0.002882
Step #2230 (total examples = 17840)	Loss: 0.068555
Step #2240 (total examples = 17920)	Loss: 0.000574
Step #2250 (total examples = 18000)	Loss: 0.008094
Step #2260 (total examples = 18080)	Loss: 0.002508
Step #2270 (total examples = 18160)	Loss: 0.018600
Step #2280 (total examples = 18240)	Loss: 0.030242
Step #2290 (total examples = 18320)	Loss: 0.001038
Step #2300 (total examples = 18400)	Loss: 0.008479
Step #2310 (total examples = 18480)	Loss: 0.006025
Step #2320 (total examples = 18560)	Loss: 0.069437
Step #2330 (total examples = 18640)	Loss: 0.172407
Step #2340 (total examples = 18720)	Loss: 0.011722
Step #2350 (total examples = 18800)	Loss: 0.044450
Step #2360 (total examples = 18880)	Loss: 0.018932
Step #2370 (total examples = 18960)	Loss: 0.190427
Step #2380 (total examples = 19040)	Loss: 0.048198
Step #2390 (total examples = 19120)	Loss: 0.012368
Step #2400 (total examples = 19200)	Loss: 0.525174
Step #2410 (total examples = 19280)	Loss: 0.163979
Step #2420 (total examples = 19360)	Loss: 0.050759
Step #2430 (total examples = 19440)	Loss: 0.030757
Step #2440 (total examples = 19520)	Loss: 0.017997
Step #2450 (total examples = 19600)	Loss: 0.000754
Step #2460 (total examples = 19680)	Loss: 0.006072
Step #2470 (total examples = 19760)	Loss: 0.039316
Step #2480 (total examples = 19840)	Loss: 0.019460
Step #2490 (total examples = 19920)	Loss: 0.062094
Step #2500 (total examples = 20000)	Loss: 0.104464
Step #2510 (total examples = 20080)	Loss: 0.000801
Step #2520 (total examples = 20160)	Loss: 0.006022
Step #2530 (total examples = 20240)	Loss: 0.029105
Step #2540 (total examples = 20320)	Loss: 0.005454
Step #2550 (total examples = 20400)	Loss: 0.304909
Step #2560 (total examples = 20480)	Loss: 0.046098
Step #2570 (total examples = 20560)	Loss: 0.025436
Step #2580 (total examples = 20640)	Loss: 0.002133
Step #2590 (total examples = 20720)	Loss: 0.167402
Step #2600 (total examples = 20800)	Loss: 0.017412
Step #2610 (total examples = 20880)	Loss: 0.004581
Step #2620 (total examples = 20960)	Loss: 0.003504
Step #2630 (total examples = 21040)	Loss: 0.005280
Step #2640 (total examples = 21120)	Loss: 0.112857
Step #2650 (total examples = 21200)	Loss: 0.004304
Step #2660 (total examples = 21280)	Loss: 0.001701
Step #2670 (total examples = 21360)	Loss: 0.279562
Step #2680 (total examples = 21440)	Loss: 0.228304
Step #2690 (total examples = 21520)	Loss: 0.031692
Step #2700 (total examples = 21600)	Loss: 0.083686
Step #2710 (total examples = 21680)	Loss: 0.008716
Step #2720 (total examples = 21760)	Loss: 0.009509
Step #2730 (total examples = 21840)	Loss: 0.025907
Step #2740 (total examples = 21920)	Loss: 0.031892
Step #2750 (total examples = 22000)	Loss: 0.047715
Step #2760 (total examples = 22080)	Loss: 0.001748
Step #2770 (total examples = 22160)	Loss: 0.005660
Step #2780 (total examples = 22240)	Loss: 0.067412
Step #2790 (total examples = 22320)	Loss: 0.000765
Step #2800 (total examples = 22400)	Loss: 0.000688
Step #2810 (total examples = 22480)	Loss: 0.201028
Step #2820 (total examples = 22560)	Loss: 0.025535
Step #2830 (total examples = 22640)	Loss: 0.397406
Step #2840 (total examples = 22720)	Loss: 0.000757
Step #2850 (total examples = 22800)	Loss: 0.005277
Step #2860 (total examples = 22880)	Loss: 0.191940
Step #2870 (total examples = 22960)	Loss: 0.128216
Step #2880 (total examples = 23040)	Loss: 0.053392
Step #2890 (total examples = 23120)	Loss: 0.009172
Step #2900 (total examples = 23200)	Loss: 0.006514
Step #2910 (total examples = 23280)	Loss: 0.024711
Step #2920 (total examples = 23360)	Loss: 0.067304
Step #2930 (total examples = 23440)	Loss: 0.027014
Step #2940 (total examples = 23520)	Loss: 0.045959
Step #2950 (total examples = 23600)	Loss: 0.017031
Step #2960 (total examples = 23680)	Loss: 0.014457
Step #2970 (total examples = 23760)	Loss: 0.009911
Step #2980 (total examples = 23840)	Loss: 0.046777
Step #2990 (total examples = 23920)	Loss: 0.103905
Step #3000 (total examples = 24000)	Loss: 0.165683
Step #3010 (total examples = 24080)	Loss: 0.009263
Step #3020 (total examples = 24160)	Loss: 0.458598
Step #3030 (total examples = 24240)	Loss: 0.003206
Step #3040 (total examples = 24320)	Loss: 0.004161
Step #3050 (total examples = 24400)	Loss: 0.001984
Step #3060 (total examples = 24480)	Loss: 0.004628
Step #3070 (total examples = 24560)	Loss: 0.017683
Step #3080 (total examples = 24640)	Loss: 0.014106
Step #3090 (total examples = 24720)	Loss: 0.000186
Step #3100 (total examples = 24800)	Loss: 0.077727
Step #3110 (total examples = 24880)	Loss: 0.035833
Step #3120 (total examples = 24960)	Loss: 0.001590
Step #3130 (total examples = 25040)	Loss: 0.018539
Step #3140 (total examples = 25120)	Loss: 0.000974
Step #3150 (total examples = 25200)	Loss: 0.043049
Step #3160 (total examples = 25280)	Loss: 0.000457
Step #3170 (total examples = 25360)	Loss: 0.010176
Step #3180 (total examples = 25440)	Loss: 0.080486
Step #3190 (total examples = 25520)	Loss: 0.014354
Step #3200 (total examples = 25600)	Loss: 0.007684
Step #3210 (total examples = 25680)	Loss: 0.017478
Step #3220 (total examples = 25760)	Loss: 0.004393
Step #3230 (total examples = 25840)	Loss: 0.398283
Step #3240 (total examples = 25920)	Loss: 0.007293
Step #1650 (total examples = 13200)	Loss: 0.149612
Step #1660 (total examples = 13280)	Loss: 0.239756
Step #1670 (total examples = 13360)	Loss: 0.125712
Step #1680 (total examples = 13440)	Loss: 0.034865
Step #1690 (total examples = 13520)	Loss: 0.048882
Step #1700 (total examples = 13600)	Loss: 0.146606
Step #1710 (total examples = 13680)	Loss: 0.017817
Step #1720 (total examples = 13760)	Loss: 0.002351
Step #1730 (total examples = 13840)	Loss: 0.333420
Step #1740 (total examples = 13920)	Loss: 0.003746
Step #1750 (total examples = 14000)	Loss: 0.097224
Step #1760 (total examples = 14080)	Loss: 0.018681
Step #1770 (total examples = 14160)	Loss: 0.012667
Step #1780 (total examples = 14240)	Loss: 0.036740
Step #1790 (total examples = 14320)	Loss: 0.010487
Step #1800 (total examples = 14400)	Loss: 0.036975
Step #1810 (total examples = 14480)	Loss: 0.002786
Step #1820 (total examples = 14560)	Loss: 0.010183
Step #1830 (total examples = 14640)	Loss: 0.142153
Step #1840 (total examples = 14720)	Loss: 0.185202
Step #1850 (total examples = 14800)	Loss: 0.006389
Step #1860 (total examples = 14880)	Loss: 0.048352
Step #1870 (total examples = 14960)	Loss: 0.060884
Step #1880 (total examples = 15040)	Loss: 0.230063
Step #1890 (total examples = 15120)	Loss: 0.014597
Step #1900 (total examples = 15200)	Loss: 0.267568
Step #1910 (total examples = 15280)	Loss: 0.003226
Step #1920 (total examples = 15360)	Loss: 0.229120
Step #1930 (total examples = 15440)	Loss: 0.048507
Step #1940 (total examples = 15520)	Loss: 0.334430
Step #1950 (total examples = 15600)	Loss: 0.399308
Step #1960 (total examples = 15680)	Loss: 0.030265
Step #1970 (total examples = 15760)	Loss: 0.039271
Step #1980 (total examples = 15840)	Loss: 0.027850
Step #1990 (total examples = 15920)	Loss: 0.003828
Step #2000 (total examples = 16000)	Loss: 0.055671
Step #2010 (total examples = 16080)	Loss: 0.494475
Step #2020 (total examples = 16160)	Loss: 0.008551
Step #2030 (total examples = 16240)	Loss: 0.000382
Step #2040 (total examples = 16320)	Loss: 0.000977
Step #2050 (total examples = 16400)	Loss: 0.030252
Step #2060 (total examples = 16480)	Loss: 0.002830
Step #2070 (total examples = 16560)	Loss: 0.698071
Step #2080 (total examples = 16640)	Loss: 0.019125
Step #2090 (total examples = 16720)	Loss: 0.019778
Step #2100 (total examples = 16800)	Loss: 0.149174
Step #2110 (total examples = 16880)	Loss: 0.021428
Step #2120 (total examples = 16960)	Loss: 0.007604
Step #2130 (total examples = 17040)	Loss: 0.130106
Step #2140 (total examples = 17120)	Loss: 0.004067
Step #2150 (total examples = 17200)	Loss: 0.025036
Step #2160 (total examples = 17280)	Loss: 0.001001
Step #2170 (total examples = 17360)	Loss: 0.011308
Step #2180 (total examples = 17440)	Loss: 0.000587
Step #2190 (total examples = 17520)	Loss: 0.001677
Step #2200 (total examples = 17600)	Loss: 0.001495
Step #2210 (total examples = 17680)	Loss: 0.087826
Step #2220 (total examples = 17760)	Loss: 0.002561
Step #2230 (total examples = 17840)	Loss: 0.007465
Step #2240 (total examples = 17920)	Loss: 0.000907
Step #2250 (total examples = 18000)	Loss: 0.047380
Step #2260 (total examples = 18080)	Loss: 0.170045
Step #2270 (total examples = 18160)	Loss: 0.006378
Step #2280 (total examples = 18240)	Loss: 0.103468
Step #2290 (total examples = 18320)	Loss: 0.279572
Step #2300 (total examples = 18400)	Loss: 0.006684
Step #2310 (total examples = 18480)	Loss: 0.028052
Step #2320 (total examples = 18560)	Loss: 1.657893
Step #2330 (total examples = 18640)	Loss: 0.471951
Step #2340 (total examples = 18720)	Loss: 0.056533
Step #2350 (total examples = 18800)	Loss: 0.005834
Step #2360 (total examples = 18880)	Loss: 0.180159
Step #2370 (total examples = 18960)	Loss: 0.030116
Step #2380 (total examples = 19040)	Loss: 0.196315
Step #2390 (total examples = 19120)	Loss: 0.001673
Step #2400 (total examples = 19200)	Loss: 0.009310
Step #2410 (total examples = 19280)	Loss: 0.002996
Step #2420 (total examples = 19360)	Loss: 0.474035
Step #2430 (total examples = 19440)	Loss: 0.477525
Step #2440 (total examples = 19520)	Loss: 0.065772
Step #2450 (total examples = 19600)	Loss: 0.836605
Step #2460 (total examples = 19680)	Loss: 0.005939
Step #2470 (total examples = 19760)	Loss: 0.651582
Step #2480 (total examples = 19840)	Loss: 0.007553
Step #2490 (total examples = 19920)	Loss: 0.412362
Step #2500 (total examples = 20000)	Loss: 0.332938
Step #2510 (total examples = 20080)	Loss: 0.016985
Step #2520 (total examples = 20160)	Loss: 0.022218
Step #2530 (total examples = 20240)	Loss: 0.003365
Step #2540 (total examples = 20320)	Loss: 0.030458
Step #2550 (total examples = 20400)	Loss: 0.000849
Step #2560 (total examples = 20480)	Loss: 0.018158
Step #2570 (total examples = 20560)	Loss: 0.078014
Step #2580 (total examples = 20640)	Loss: 0.016605
Step #2590 (total examples = 20720)	Loss: 0.032438
Step #2600 (total examples = 20800)	Loss: 0.043202
Step #2610 (total examples = 20880)	Loss: 0.018055
Step #2620 (total examples = 20960)	Loss: 0.089521
Step #2630 (total examples = 21040)	Loss: 0.000406
Step #2640 (total examples = 21120)	Loss: 0.013430
Step #2650 (total examples = 21200)	Loss: 0.178082
Step #2660 (total examples = 21280)	Loss: 0.076099
Step #2670 (total examples = 21360)	Loss: 0.000373
Step #2680 (total examples = 21440)	Loss: 0.181765
Step #2690 (total examples = 21520)	Loss: 0.008119
Step #2700 (total examples = 21600)	Loss: 0.021044
Step #2710 (total examples = 21680)	Loss: 0.211761
Step #2720 (total examples = 21760)	Loss: 0.001678
Step #2730 (total examples = 21840)	Loss: 0.000380
Step #2740 (total examples = 21920)	Loss: 0.002705
Step #2750 (total examples = 22000)	Loss: 0.019744
Step #2760 (total examples = 22080)	Loss: 0.070719
Step #2770 (total examples = 22160)	Loss: 0.066770
Step #2780 (total examples = 22240)	Loss: 0.086642
Step #2790 (total examples = 22320)	Loss: 0.029361
Step #2800 (total examples = 22400)	Loss: 0.004070
Step #2810 (total examples = 22480)	Loss: 0.182703
Step #2820 (total examples = 22560)	Loss: 0.001333
Step #2830 (total examples = 22640)	Loss: 0.006450
Step #2840 (total examples = 22720)	Loss: 0.178366
Step #2850 (total examples = 22800)	Loss: 0.013517
Step #2860 (total examples = 22880)	Loss: 0.112264
Step #2870 (total examples = 22960)	Loss: 0.058277
Step #2880 (total examples = 23040)	Loss: 0.031542
Step #2890 (total examples = 23120)	Loss: 0.025282
Step #2900 (total examples = 23200)	Loss: 0.000016
Step #2910 (total examples = 23280)	Loss: 0.016926
Step #2920 (total examples = 23360)	Loss: 0.140307
Step #2930 (total examples = 23440)	Loss: 0.106309
Step #2940 (total examples = 23520)	Loss: 0.042105
Step #2950 (total examples = 23600)	Loss: 0.801330
Step #2960 (total examples = 23680)	Loss: 0.000534
Step #2970 (total examples = 23760)	Loss: 0.020968
Step #2980 (total examples = 23840)	Loss: 0.285631
Step #2990 (total examples = 23920)	Loss: 0.007156
Step #3000 (total examples = 24000)	Loss: 0.006408
Step #3010 (total examples = 24080)	Loss: 0.000964
Step #3020 (total examples = 24160)	Loss: 0.005315
Step #3030 (total examples = 24240)	Loss: 0.009310
Step #3040 (total examples = 24320)	Loss: 1.025025
Step #3050 (total examples = 24400)	Loss: 0.003099
Step #3060 (total examples = 24480)	Loss: 0.005902
Step #3070 (total examples = 24560)	Loss: 0.000786
Step #3080 (total examples = 24640)	Loss: 0.000145
Step #3090 (total examples = 24720)	Loss: 0.116593
Step #3100 (total examples = 24800)	Loss: 0.011214
Step #3110 (total examples = 24880)	Loss: 0.001877
Step #3120 (total examples = 24960)	Loss: 0.072923
Step #3130 (total examples = 25040)	Loss: 0.019539
Step #3140 (total examples = 25120)	Loss: 0.204759
Step #3150 (total examples = 25200)	Loss: 0.009681
Step #3160 (total examples = 25280)	Loss: 0.175596
Step #3170 (total examples = 25360)	Loss: 0.129171
Step #3180 (total examples = 25440)	Loss: 1.381951
Step #3190 (total examples = 25520)	Loss: 0.002504
Step #3200 (total examples = 25600)	Loss: 0.002610
Step #3210 (total examples = 25680)	Loss: 0.011504
Step #3220 (total examples = 25760)	Loss: 0.436108
Step #3230 (total examples = 25840)	Loss: 0.002123
Step #3240 (total examples = 25920)	Loss: 0.000087
Step #3250 (total examples = 26000)	Loss: 0.014939
Step #3260 (total examples = 26080)	Loss: 0.000093
Step #3270 (total examples = 26160)	Loss: 0.000290
Step #3280 (total examples = 26240)	Loss: 0.005674
Step #3290 (total examples = 26320)	Loss: 0.011284
Step #3300 (total examples = 26400)	Loss: 0.019371
Step #3310 (total examples = 26480)	Loss: 0.065061
Step #3320 (total examples = 26560)	Loss: 0.018610
Step #3330 (total examples = 26640)	Loss: 0.143917
Step #3340 (total examples = 26720)	Loss: 0.005808
Step #3350 (total examples = 26800)	Loss: 0.007325
Step #3360 (total examples = 26880)	Loss: 0.136675
Step #3370 (total examples = 26960)	Loss: 0.003010
Step #3380 (total examples = 27040)	Loss: 0.020680
Step #3390 (total examples = 27120)	Loss: 0.039380
Step #3400 (total examples = 27200)	Loss: 0.040879
Step #3410 (total examples = 27280)	Loss: 0.000329
Step #3420 (total examples = 27360)	Loss: 0.078771
Step #3430 (total examples = 27440)	Loss: 0.230252
Step #3440 (total examples = 27520)	Loss: 0.259146
Step #3450 (total examples = 27600)	Loss: 0.003135
Step #3460 (total examples = 27680)	Loss: 1.066288
Step #3470 (total examples = 27760)	Loss: 0.271902
Step #3480 (total examples = 27840)	Loss: 0.000534
Step #3490 (total examples = 27920)	Loss: 0.070575
Step #3500 (total examples = 28000)	Loss: 0.000577
Step #3510 (total examples = 28080)	Loss: 0.000655
Step #3520 (total examples = 28160)	Loss: 0.001630
Step #3530 (total examples = 28240)	Loss: 0.718094
Step #3540 (total examples = 28320)	Loss: 0.012076
Step #3550 (total examples = 28400)	Loss: 0.085384
Step #3560 (total examples = 28480)	Loss: 0.000236
Step #3570 (total examples = 28560)	Loss: 0.002553
Step #3580 (total examples = 28640)	Loss: 0.043209
Step #3590 (total examples = 28720)	Loss: 0.107279
Step #3600 (total examples = 28800)	Loss: 0.001944
Step #3610 (total examples = 28880)	Loss: 0.010285
Step #3620 (total examples = 28960)	Loss: 0.022094
Step #3630 (total examples = 29040)	Loss: 0.000056
Step #3640 (total examples = 29120)	Loss: 0.000617
Step #3650 (total examples = 29200)	Loss: 0.348757
Step #3660 (total examples = 29280)	Loss: 0.001932
Step #3670 (total examples = 29360)	Loss: 0.000339
Step #3680 (total examples = 29440)	Loss: 0.002359
Step #3690 (total examples = 29520)	Loss: 0.000384
Step #3700 (total examples = 29600)	Loss: 0.000776
Step #3710 (total examples = 29680)	Loss: 0.000074
Step #3720 (total examples = 29760)	Loss: 0.009729
Step #3730 (total examples = 29840)	Loss: 0.024831
Step #3740 (total examples = 29920)	Loss: 0.001658
Step #3750 (total examples = 30000)	Loss: 0.034415
Step #3760 (total examples = 30080)	Loss: 0.474256
Step #3770 (total examples = 30160)	Loss: 0.000058
Step #3780 (total examples = 30240)	Loss: 0.004407
Step #3790 (total examples = 30320)	Loss: 0.001823
Step #3800 (total examples = 30400)	Loss: 0.127463
Step #3810 (total examples = 30480)	Loss: 0.000971
Step #3820 (total examples = 30560)	Loss: 0.001578
Step #3830 (total examples = 30640)	Loss: 0.002805
Step #3840 (total examples = 30720)	Loss: 0.001710
Step #3850 (total examples = 30800)	Loss: 0.004138
Step #3860 (total examples = 30880)	Loss: 0.000116
Step #3870 (total examples = 30960)	Loss: 0.109944
Step #3880 (total examples = 31040)	Loss: 0.001841
Step #3890 (total examples = 31120)	Loss: 0.168605
Step #3900 (total examples = 31200)	Loss: 0.687365
Step #3910 (total examples = 31280)	Loss: 0.015314
Step #3920 (total examples = 31360)	Loss: 0.004807
Step #3930 (total examples = 31440)	Loss: 0.051552
Step #3940 (total examples = 31520)	Loss: 0.040699
Step #3950 (total examples = 31600)	Loss: 0.001235
Step #3960 (total examples = 31680)	Loss: 0.412956
Step #3970 (total examples = 31760)	Loss: 0.174212
Step #3980 (total examples = 31840)	Loss: 0.000165
Step #3990 (total examples = 31920)	Loss: 0.000229

Step #3250 (total examples = 26000)	Loss: 0.210222
Step #3260 (total examples = 26080)	Loss: 0.000148
Step #3270 (total examples = 26160)	Loss: 0.009007
Step #3280 (total examples = 26240)	Loss: 0.073515
Step #3290 (total examples = 26320)	Loss: 0.138449
Step #3300 (total examples = 26400)	Loss: 0.006303
Step #3310 (total examples = 26480)	Loss: 0.115285
Step #3320 (total examples = 26560)	Loss: 0.011784
Step #3330 (total examples = 26640)	Loss: 0.006312
Step #3340 (total examples = 26720)	Loss: 0.003576
Step #3350 (total examples = 26800)	Loss: 0.019899
Step #3360 (total examples = 26880)	Loss: 0.001019
Step #3370 (total examples = 26960)	Loss: 0.010518
Step #3380 (total examples = 27040)	Loss: 0.580352
Step #3390 (total examples = 27120)	Loss: 0.009271
Step #3400 (total examples = 27200)	Loss: 0.056004
Step #3410 (total examples = 27280)	Loss: 0.004073
Step #3420 (total examples = 27360)	Loss: 0.176114
Step #3430 (total examples = 27440)	Loss: 0.000600
Step #3440 (total examples = 27520)	Loss: 0.178076
Step #3450 (total examples = 27600)	Loss: 0.010665
Step #3460 (total examples = 27680)	Loss: 0.003515
Step #3470 (total examples = 27760)	Loss: 0.013634
Step #3480 (total examples = 27840)	Loss: 0.141415
Step #3490 (total examples = 27920)	Loss: 0.005120
Step #3500 (total examples = 28000)	Loss: 0.002595
Step #3510 (total examples = 28080)	Loss: 0.000177
Step #3520 (total examples = 28160)	Loss: 0.002304
Step #3530 (total examples = 28240)	Loss: 0.151622
Step #3540 (total examples = 28320)	Loss: 0.000083
Step #3550 (total examples = 28400)	Loss: 0.095485
Step #3560 (total examples = 28480)	Loss: 0.001245
Step #3570 (total examples = 28560)	Loss: 0.001810
Step #3580 (total examples = 28640)	Loss: 0.001366
Step #3590 (total examples = 28720)	Loss: 0.348227
Step #3600 (total examples = 28800)	Loss: 0.016895
Step #3610 (total examples = 28880)	Loss: 0.112818
Step #3620 (total examples = 28960)	Loss: 0.003481
Step #3630 (total examples = 29040)	Loss: 0.111148
Step #3640 (total examples = 29120)	Loss: 0.000646
Step #3650 (total examples = 29200)	Loss: 0.641360
Step #3660 (total examples = 29280)	Loss: 0.002777
Step #3670 (total examples = 29360)	Loss: 0.000289
Step #3680 (total examples = 29440)	Loss: 0.016314
Step #3690 (total examples = 29520)	Loss: 0.010573
Step #3700 (total examples = 29600)	Loss: 0.144643
Step #3710 (total examples = 29680)	Loss: 0.002343
Step #3720 (total examples = 29760)	Loss: 0.000819
Step #3730 (total examples = 29840)	Loss: 0.150298
Step #3740 (total examples = 29920)	Loss: 0.000193
Step #3750 (total examples = 30000)	Loss: 0.005282
Step #3760 (total examples = 30080)	Loss: 0.025009
Step #3770 (total examples = 30160)	Loss: 0.182734
Step #3780 (total examples = 30240)	Loss: 0.003042
Step #3790 (total examples = 30320)	Loss: 0.085323
Step #3800 (total examples = 30400)	Loss: 0.066435
Step #3810 (total examples = 30480)	Loss: 0.019689
Step #3820 (total examples = 30560)	Loss: 0.006497
Step #3830 (total examples = 30640)	Loss: 0.009622
Step #3840 (total examples = 30720)	Loss: 0.096254
Step #3850 (total examples = 30800)	Loss: 0.015140
Step #3860 (total examples = 30880)	Loss: 0.026057
Step #3870 (total examples = 30960)	Loss: 0.009224
Step #3880 (total examples = 31040)	Loss: 0.000407
Step #3890 (total examples = 31120)	Loss: 0.393908
Step #3900 (total examples = 31200)	Loss: 0.006508
Step #3910 (total examples = 31280)	Loss: 0.000489
Step #3920 (total examples = 31360)	Loss: 0.070842
Step #3930 (total examples = 31440)	Loss: 0.215214
Step #3940 (total examples = 31520)	Loss: 0.351764
Step #3950 (total examples = 31600)	Loss: 0.000304
Step #3960 (total examples = 31680)	Loss: 0.000883
Step #3970 (total examples = 31760)	Loss: 0.473377
Step #3980 (total examples = 31840)	Loss: 0.010522
Step #3990 (total examples = 31920)	Loss: 0.005441
  1/313 [..............................] - ETA: 1:55 - loss: 13.2192 - accuracy: 0.9688  4/313 [..............................] - ETA: 5s - loss: 4.4011 - accuracy: 0.9844     7/313 [..............................] - ETA: 5s - loss: 2.9532 - accuracy: 0.9866 10/313 [..............................] - ETA: 5s - loss: 2.0673 - accuracy: 0.9906 13/313 [>.............................] - ETA: 5s - loss: 6.7692 - accuracy: 0.9880 16/313 [>.............................] - ETA: 5s - loss: 8.3734 - accuracy: 0.9844 19/313 [>.............................] - ETA: 5s - loss: 7.3674 - accuracy: 0.9852 22/313 [=>............................] - ETA: 5s - loss: 7.1689 - accuracy: 0.9830 25/313 [=>............................] - ETA: 4s - loss: 8.3169 - accuracy: 0.9825 28/313 [=>............................] - ETA: 4s - loss: 7.5948 - accuracy: 0.9833 31/313 [=>............................] - ETA: 5s - loss: 6.8881 - accuracy: 0.9839 33/313 [==>...........................] - ETA: 5s - loss: 8.6473 - accuracy: 0.9830 35/313 [==>...........................] - ETA: 5s - loss: 9.1603 - accuracy: 0.9812 37/313 [==>...........................] - ETA: 5s - loss: 8.6652 - accuracy: 0.9823 39/313 [==>...........................] - ETA: 5s - loss: 9.2433 - accuracy: 0.9816 41/313 [==>...........................] - ETA: 5s - loss: 9.8677 - accuracy: 0.9817 43/313 [===>..........................] - ETA: 6s - loss: 9.7200 - accuracy: 0.9811 45/313 [===>..........................] - ETA: 6s - loss: 10.3386 - accuracy: 0.9812 47/313 [===>..........................] - ETA: 6s - loss: 10.2891 - accuracy: 0.9814 49/313 [===>..........................] - ETA: 6s - loss: 10.8068 - accuracy: 0.9802 51/313 [===>..........................] - ETA: 6s - loss: 10.5622 - accuracy: 0.9804 53/313 [====>.........................] - ETA: 6s - loss: 10.1637 - accuracy: 0.9811 55/313 [====>.........................] - ETA: 6s - loss: 10.7629 - accuracy: 0.9795 57/313 [====>.........................] - ETA: 6s - loss: 10.5842 - accuracy: 0.9792 59/313 [====>.........................] - ETA: 6s - loss: 10.2255 - accuracy: 0.9799 61/313 [====>.........................] - ETA: 6s - loss: 10.3667 - accuracy: 0.9800 64/313 [=====>........................] - ETA: 6s - loss: 10.9857 - accuracy: 0.9805 68/313 [=====>........................] - ETA: 5s - loss: 12.1335 - accuracy: 0.9779 72/313 [=====>........................] - ETA: 5s - loss: 12.1393 - accuracy: 0.9774 76/313 [======>.......................] - ETA: 5s - loss: 12.4865 - accuracy: 0.9770 80/313 [======>.......................] - ETA: 5s - loss: 12.3098 - accuracy: 0.9770 84/313 [=======>......................] - ETA: 5s - loss: 12.5149 - accuracy: 0.9769 88/313 [=======>......................] - ETA: 5s - loss: 11.9460 - accuracy: 0.9780 91/313 [=======>......................] - ETA: 4s - loss: 11.9308 - accuracy: 0.9784 94/313 [========>.....................] - ETA: 4s - loss: 11.9695 - accuracy: 0.9781 98/313 [========>.....................] - ETA: 4s - loss: 11.8787 - accuracy: 0.9783102/313 [========>.....................] - ETA: 4s - loss: 11.5194 - accuracy: 0.9789106/313 [=========>....................] - ETA: 4s - loss: 11.1567 - accuracy: 0.9794109/313 [=========>....................] - ETA: 4s - loss: 11.1963 - accuracy: 0.9796113/313 [=========>....................] - ETA: 4s - loss: 12.6374 - accuracy: 0.9793117/313 [==========>...................] - ETA: 4s - loss: 12.6445 - accuracy: 0.9794120/313 [==========>...................] - ETA: 4s - loss: 13.8000 - accuracy: 0.9794123/313 [==========>...................] - ETA: 3s - loss: 13.4634 - accuracy: 0.9799127/313 [===========>..................] - ETA: 3s - loss: 13.3921 - accuracy: 0.9798131/313 [===========>..................] - ETA: 3s - loss: 13.3557 - accuracy: 0.9800134/313 [===========>..................] - ETA: 3s - loss: 13.3712 - accuracy: 0.9795138/313 [============>.................] - ETA: 3s - loss: 13.0814 - accuracy: 0.9798142/313 [============>.................] - ETA: 3s - loss: 13.0220 - accuracy: 0.9798145/313 [============>.................] - ETA: 3s - loss: 13.0789 - accuracy: 0.9797148/313 [=============>................] - ETA: 3s - loss: 12.8138 - accuracy: 0.9802151/313 [=============>................] - ETA: 3s - loss: 13.2822 - accuracy: 0.9795154/313 [=============>................] - ETA: 3s - loss: 13.2823 - accuracy: 0.9791157/313 [==============>...............] - ETA: 3s - loss: 13.0285 - accuracy: 0.9795161/313 [==============>...............] - ETA: 3s - loss: 12.7425 - accuracy: 0.9798165/313 [==============>...............] - ETA: 2s - loss: 12.4669 - accuracy: 0.9801169/313 [===============>..............] - ETA: 2s - loss: 12.2583 - accuracy: 0.9804173/313 [===============>..............] - ETA: 2s - loss: 11.9749 - accuracy: 0.9809177/313 [===============>..............] - ETA: 2s - loss: 11.9271 - accuracy: 0.9809181/313 [================>.............] - ETA: 2s - loss: 11.6635 - accuracy: 0.9814185/313 [================>.............] - ETA: 2s - loss: 11.5512 - accuracy: 0.9814189/313 [=================>............] - ETA: 2s - loss: 11.9496 - accuracy: 0.9810193/313 [=================>............] - ETA: 2s - loss: 11.8323 - accuracy: 0.9807197/313 [=================>............] - ETA: 2s - loss: 11.5921 - accuracy: 0.9811201/313 [==================>...........] - ETA: 2s - loss: 11.3614 - accuracy: 0.9815205/313 [==================>...........] - ETA: 2s - loss: 11.3018 - accuracy: 0.9817209/313 [===================>..........] - ETA: 1s - loss: 11.5555 - accuracy: 0.9813213/313 [===================>..........] - ETA: 1s - loss: 11.3390 - accuracy: 0.9815217/313 [===================>..........] - ETA: 1s - loss: 11.1300 - accuracy: 0.9819221/313 [====================>.........] - ETA: 1s - loss: 10.9285 - accuracy: 0.9822225/313 [====================>.........] - ETA: 1s - loss: 10.7343 - accuracy: 0.9825229/313 [====================>.........] - ETA: 1s - loss: 10.5468 - accuracy: 0.9828233/313 [=====================>........] - ETA: 1s - loss: 10.5635 - accuracy: 0.9830237/313 [=====================>........] - ETA: 1s - loss: 10.3852 - accuracy: 0.9833241/313 [======================>.......] - ETA: 1s - loss: 10.2128 - accuracy: 0.9835245/313 [======================>.......] - ETA: 1s - loss: 10.0461 - accuracy: 0.9838249/313 [======================>.......] - ETA: 1s - loss: 9.8847 - accuracy: 0.9841 253/313 [=======================>......] - ETA: 1s - loss: 9.8384 - accuracy: 0.9841257/313 [=======================>......] - ETA: 1s - loss: 9.6853 - accuracy: 0.9843261/313 [========================>.....] - ETA: 0s - loss: 9.5642 - accuracy: 0.9844265/313 [========================>.....] - ETA: 0s - loss: 9.4596 - accuracy: 0.9846269/313 [========================>.....] - ETA: 0s - loss: 9.3190 - accuracy: 0.9848273/313 [=========================>....] - ETA: 0s - loss: 9.1824 - accuracy: 0.9850277/313 [=========================>....] - ETA: 0s - loss: 9.0498 - accuracy: 0.9852281/313 [=========================>....] - ETA: 0s - loss: 8.9210 - accuracy: 0.9854285/313 [==========================>...] - ETA: 0s - loss: 9.2517 - accuracy: 0.9852289/313 [==========================>...] - ETA: 0s - loss: 9.1236 - accuracy: 0.9854293/313 [===========================>..] - ETA: 0s - loss: 8.9991 - accuracy: 0.9856297/313 [===========================>..] - ETA: 0s - loss: 8.8779 - accuracy: 0.9858301/313 [===========================>..] - ETA: 0s - loss: 8.8254 - accuracy: 0.9858305/313 [============================>.] - ETA: 0s - loss: 8.9690 - accuracy: 0.9853309/313 [============================>.] - ETA: 0s - loss: 9.1808 - accuracy: 0.9851313/313 [==============================] - ETA: 0s - loss: 9.0942 - accuracy: 0.9851313/313 [==============================] - 6s 18ms/step - loss: 9.0942 - accuracy: 0.9851
Final model accuracy: 0.985100
Total training time: 382.241975
2021-12-03 20:44:04.767315: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/lang/Python/3.7.2-intel-2018.5.274/lib:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib64:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib:/opt/apps/software/math/GMP/6.1.2-GCCcore-6.3.0/lib:/opt/apps/software/tools/XZ/5.2.4-GCCcore-6.3.0/lib:/opt/apps/software/devel/SQLite/3.27.2-GCCcore-6.3.0/lib:/opt/apps/software/lang/Tcl/8.6.9-GCCcore-6.3.0/lib:/opt/apps/software/devel/ncurses/6.1-intel-2018.5.274/lib:/opt/apps/software/lib/libreadline/7.0-GCCcore-6.3.0/lib:/opt/apps/software/lib/zlib/1.2.11-GCCcore-6.3.0/lib:/opt/apps/software/tools/bzip2/1.0.6/lib:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/mkl/lib/intel64:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/lib/intel64:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/lib64:/opt/apps/software/lib/libfabric/1.9.1/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/tbb/lib/intel64/gcc4.4:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/tools/binutils/2.26-GCCcore-6.3.0/lib:/opt/apps/software/compiler/GCCcore/6.3.0/lib/gcc/x86_64-pc-linux-gnu/6.3.0:/opt/apps/software/compiler/GCCcore/6.3.0/lib64:/opt/apps/software/compiler/GCCcore/6.3.0/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/mic/lib
2021-12-03 20:44:04.767436: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-03 20:44:04.774852: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/lang/Python/3.7.2-intel-2018.5.274/lib:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib64:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib:/opt/apps/software/math/GMP/6.1.2-GCCcore-6.3.0/lib:/opt/apps/software/tools/XZ/5.2.4-GCCcore-6.3.0/lib:/opt/apps/software/devel/SQLite/3.27.2-GCCcore-6.3.0/lib:/opt/apps/software/lang/Tcl/8.6.9-GCCcore-6.3.0/lib:/opt/apps/software/devel/ncurses/6.1-intel-2018.5.274/lib:/opt/apps/software/lib/libreadline/7.0-GCCcore-6.3.0/lib:/opt/apps/software/lib/zlib/1.2.11-GCCcore-6.3.0/lib:/opt/apps/software/tools/bzip2/1.0.6/lib:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/mkl/lib/intel64:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/lib/intel64:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/lib64:/opt/apps/software/lib/libfabric/1.9.1/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/tbb/lib/intel64/gcc4.4:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/tools/binutils/2.26-GCCcore-6.3.0/lib:/opt/apps/software/compiler/GCCcore/6.3.0/lib/gcc/x86_64-pc-linux-gnu/6.3.0:/opt/apps/software/compiler/GCCcore/6.3.0/lib64:/opt/apps/software/compiler/GCCcore/6.3.0/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/mic/lib
2021-12-03 20:44:04.774996: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-12-03 20:44:08.948275: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2021-12-03 20:44:08.948451: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: gpu-0001
2021-12-03 20:44:08.948502: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: gpu-0001
2021-12-03 20:44:08.961915: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/lang/Python/3.7.2-intel-2018.5.274/lib:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib64:/opt/apps/software/lib/libffi/3.2.1-GCCcore-6.3.0/lib:/opt/apps/software/math/GMP/6.1.2-GCCcore-6.3.0/lib:/opt/apps/software/tools/XZ/5.2.4-GCCcore-6.3.0/lib:/opt/apps/software/devel/SQLite/3.27.2-GCCcore-6.3.0/lib:/opt/apps/software/lang/Tcl/8.6.9-GCCcore-6.3.0/lib:/opt/apps/software/devel/ncurses/6.1-intel-2018.5.274/lib:/opt/apps/software/lib/libreadline/7.0-GCCcore-6.3.0/lib:/opt/apps/software/lib/zlib/1.2.11-GCCcore-6.3.0/lib:/opt/apps/software/tools/bzip2/1.0.6/lib:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/mkl/lib/intel64:/opt/apps/software/numlib/imkl/2018.4.274-iimpi-2018.4.274/lib/intel64:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/lib64:/opt/apps/software/lib/libfabric/1.9.1/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64:/opt/apps/software/compiler/ifort/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/debugger_2018/libipt/intel64/lib:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/tbb/lib/intel64/gcc4.4:/opt/apps/software/compiler/icc/2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/compiler/lib/intel64:/opt/apps/software/tools/binutils/2.26-GCCcore-6.3.0/lib:/opt/apps/software/compiler/GCCcore/6.3.0/lib/gcc/x86_64-pc-linux-gnu/6.3.0:/opt/apps/software/compiler/GCCcore/6.3.0/lib64:/opt/apps/software/compiler/GCCcore/6.3.0/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/intel64/lib:/opt/apps/software/mpi/impi/2018.4.274-iccifort-2018.5.274-GCC-6.3.0-2.26/compilers_and_libraries_2018.5.274/linux/mpi/mic/lib
2021-12-03 20:44:08.962081: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-12-03 20:44:08.962060: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 465.19.1
2021-12-03 20:44:08.962149: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node-0001): /proc/driver/nvidia/version does not exist
2021-12-03 20:44:08.962186: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 465.19.1
2021-12-03 20:44:08.962233: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 465.19.1
2021-12-03 20:44:08.963180: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
===========
rank: 0
Batch size: 8
Total number of batches: 8000
Total training examples: 64000
Num of workers: 2
===========
Step #0 (total examples = 0)	Loss: 2.280010
Step #10 (total examples = 80)	Loss: 2.124251
Step #20 (total examples = 160)	Loss: 1.836597
Step #30 (total examples = 240)	Loss: 0.540210
Step #40 (total examples = 320)	Loss: 0.251652
Step #50 (total examples = 400)	Loss: 0.566453
Step #60 (total examples = 480)	Loss: 0.196438
Step #70 (total examples = 560)	Loss: 0.071850
Step #80 (total examples = 640)	Loss: 0.599768
Step #90 (total examples = 720)	Loss: 0.158728
Step #100 (total examples = 800)	Loss: 0.452831
Step #110 (total examples = 880)	Loss: 0.288033
Step #120 (total examples = 960)	Loss: 0.212255
Step #130 (total examples = 1040)	Loss: 0.067820
Step #140 (total examples = 1120)	Loss: 1.686031
Step #150 (total examples = 1200)	Loss: 0.078152
Step #160 (total examples = 1280)	Loss: 0.098625
Step #170 (total examples = 1360)	Loss: 0.051183
Step #180 (total examples = 1440)	Loss: 0.438062
Step #190 (total examples = 1520)	Loss: 0.521221
Step #200 (total examples = 1600)	Loss: 0.224092
Step #210 (total examples = 1680)	Loss: 0.219226
Step #220 (total examples = 1760)	Loss: 0.214893
Step #230 (total examples = 1840)	Loss: 0.135507
Step #240 (total examples = 1920)	Loss: 0.010163
Step #250 (total examples = 2000)	Loss: 0.011664
Step #260 (total examples = 2080)	Loss: 0.051802
Step #270 (total examples = 2160)	Loss: 0.432153
Step #280 (total examples = 2240)	Loss: 0.369556
Step #290 (total examples = 2320)	Loss: 0.136203
Step #300 (total examples = 2400)	Loss: 0.161119
Step #310 (total examples = 2480)	Loss: 0.083190
Step #320 (total examples = 2560)	Loss: 0.010031
Step #330 (total examples = 2640)	Loss: 1.016943
Step #340 (total examples = 2720)	Loss: 0.407494
Step #350 (total examples = 2800)	Loss: 0.313824
Step #360 (total examples = 2880)	Loss: 0.129468
Step #370 (total examples = 2960)	Loss: 0.406738
Step #380 (total examples = 3040)	Loss: 0.132815
Step #390 (total examples = 3120)	Loss: 0.021315
Step #400 (total examples = 3200)	Loss: 0.003125
Step #410 (total examples = 3280)	Loss: 0.109048
Step #420 (total examples = 3360)	Loss: 0.352898
Step #430 (total examples = 3440)	Loss: 0.010218
Step #440 (total examples = 3520)	Loss: 0.125268
Step #450 (total examples = 3600)	Loss: 0.530548
Step #460 (total examples = 3680)	Loss: 0.074648
Step #470 (total examples = 3760)	Loss: 0.080680
Step #480 (total examples = 3840)	Loss: 0.120628
Step #490 (total examples = 3920)	Loss: 1.939045
Step #500 (total examples = 4000)	Loss: 0.021380
Step #510 (total examples = 4080)	Loss: 0.011390
Step #520 (total examples = 4160)	Loss: 0.003063
Step #530 (total examples = 4240)	Loss: 0.017023
Step #540 (total examples = 4320)	Loss: 0.352563
Step #550 (total examples = 4400)	Loss: 0.048969
Step #560 (total examples = 4480)	Loss: 0.350279
Step #570 (total examples = 4560)	Loss: 0.135744
Step #580 (total examples = 4640)	Loss: 0.008065
Step #590 (total examples = 4720)	Loss: 0.153704
Step #600 (total examples = 4800)	Loss: 0.048018
Step #610 (total examples = 4880)	Loss: 0.035737
Step #620 (total examples = 4960)	Loss: 0.188309
Step #630 (total examples = 5040)	Loss: 0.002400
Step #640 (total examples = 5120)	Loss: 0.176764
Step #650 (total examples = 5200)	Loss: 0.075645
Step #660 (total examples = 5280)	Loss: 0.117381
Step #670 (total examples = 5360)	Loss: 0.001638
Step #680 (total examples = 5440)	Loss: 0.047425
Step #690 (total examples = 5520)	Loss: 0.002328
Step #700 (total examples = 5600)	Loss: 0.030110
Step #710 (total examples = 5680)	Loss: 0.009003
Step #720 (total examples = 5760)	Loss: 0.756285
Step #730 (total examples = 5840)	Loss: 0.039752
Step #740 (total examples = 5920)	Loss: 0.112703
Step #750 (total examples = 6000)	Loss: 0.037336
Step #760 (total examples = 6080)	Loss: 0.129256
Step #770 (total examples = 6160)	Loss: 0.010545
Step #780 (total examples = 6240)	Loss: 0.010059
Step #790 (total examples = 6320)	Loss: 0.006208
Step #800 (total examples = 6400)	Loss: 0.766615
Step #810 (total examples = 6480)	Loss: 0.019425
Step #820 (total examples = 6560)	Loss: 0.251147
Step #830 (total examples = 6640)	Loss: 0.070211
Step #840 (total examples = 6720)	Loss: 0.343186
Step #850 (total examples = 6800)	Loss: 0.016384
Step #860 (total examples = 6880)	Loss: 0.113905
Step #870 (total examples = 6960)	Loss: 0.003717
Step #880 (total examples = 7040)	Loss: 0.007216
Step #890 (total examples = 7120)	Loss: 0.052915
Step #900 (total examples = 7200)	Loss: 0.063849
Step #910 (total examples = 7280)	Loss: 0.182090
Step #920 (total examples = 7360)	Loss: 0.033622
Step #930 (total examples = 7440)	Loss: 0.044627
Step #940 (total examples = 7520)	Loss: 0.002636
Step #950 (total examples = 7600)	Loss: 0.003406
Step #960 (total examples = 7680)	Loss: 0.661428
Step #970 (total examples = 7760)	Loss: 0.469706
Step #980 (total examples = 7840)	Loss: 0.027957
Step #990 (total examples = 7920)	Loss: 0.604152
Step #1000 (total examples = 8000)	Loss: 0.003416
Step #1010 (total examples = 8080)	Loss: 0.042734
Step #1020 (total examples = 8160)	Loss: 0.104688
Step #1030 (total examples = 8240)	Loss: 0.013947
Step #1040 (total examples = 8320)	Loss: 0.013769
Step #1050 (total examples = 8400)	Loss: 0.092195
Step #1060 (total examples = 8480)	Loss: 0.101608
Step #1070 (total examples = 8560)	Loss: 0.169775
Step #1080 (total examples = 8640)	Loss: 0.028114
Step #1090 (total examples = 8720)	Loss: 0.017928
Step #1100 (total examples = 8800)	Loss: 0.070053
Step #1110 (total examples = 8880)	Loss: 0.108598
Step #1120 (total examples = 8960)	Loss: 0.016925
Step #1130 (total examples = 9040)	Loss: 0.028385
Step #1140 (total examples = 9120)	Loss: 0.020302
Step #1150 (total examples = 9200)	Loss: 0.019414
Step #1160 (total examples = 9280)	Loss: 0.039971
Step #1170 (total examples = 9360)	Loss: 0.064494
Step #1180 (total examples = 9440)	Loss: 0.018977
Step #1190 (total examples = 9520)	Loss: 0.040300
Step #1200 (total examples = 9600)	Loss: 0.006011
Step #1210 (total examples = 9680)	Loss: 0.107068
Step #1220 (total examples = 9760)	Loss: 0.009642
Step #1230 (total examples = 9840)	Loss: 0.001605
Step #1240 (total examples = 9920)	Loss: 0.201142
Step #1250 (total examples = 10000)	Loss: 0.031098
Step #1260 (total examples = 10080)	Loss: 0.179881
Step #1270 (total examples = 10160)	Loss: 0.004942
Step #1280 (total examples = 10240)	Loss: 0.000522
Step #1290 (total examples = 10320)	Loss: 0.240409
Step #1300 (total examples = 10400)	Loss: 0.404564
Step #1310 (total examples = 10480)	Loss: 0.000853
Step #1320 (total examples = 10560)	Loss: 0.550125
Step #1330 (total examples = 10640)	Loss: 0.006354
Step #1340 (total examples = 10720)	Loss: 0.021473
Step #1350 (total examples = 10800)	Loss: 0.011060
Step #1360 (total examples = 10880)	Loss: 0.005666
Step #1370 (total examples = 10960)	Loss: 0.525907
Step #1380 (total examples = 11040)	Loss: 0.046385
Step #1390 (total examples = 11120)	Loss: 0.022738
Step #1400 (total examples = 11200)	Loss: 0.026864
Step #1410 (total examples = 11280)	Loss: 0.005563
Step #1420 (total examples = 11360)	Loss: 0.002335
Step #1430 (total examples = 11440)	Loss: 0.185048
Step #1440 (total examples = 11520)	Loss: 0.118684
Step #1450 (total examples = 11600)	Loss: 0.250702
Step #1460 (total examples = 11680)	Loss: 0.035567
Step #1470 (total examples = 11760)	Loss: 0.092666
Step #1480 (total examples = 11840)	Loss: 0.365610
Step #1490 (total examples = 11920)	Loss: 0.030974
Step #1500 (total examples = 12000)	Loss: 0.005945
Step #1510 (total examples = 12080)	Loss: 0.032072
Step #1520 (total examples = 12160)	Loss: 0.161558
Step #1530 (total examples = 12240)	Loss: 0.003530
Step #1540 (total examples = 12320)	Loss: 0.004187
Step #1550 (total examples = 12400)	Loss: 0.270571
Step #1560 (total examples = 12480)	Loss: 0.232029
Step #1570 (total examples = 12560)	Loss: 0.068837
Step #1580 (total examples = 12640)	Loss: 0.007915
Step #1590 (total examples = 12720)	Loss: 0.003686
Step #1600 (total examples = 12800)	Loss: 0.001571
Step #1610 (total examples = 12880)	Loss: 0.023964
Step #1620 (total examples = 12960)	Loss: 0.002436
Step #1630 (total examples = 13040)	Loss: 0.010021===========
rank: 1
===========
Step #0 (total examples = 0)	Loss: 2.281109
Step #10 (total examples = 80)	Loss: 2.282114
Step #20 (total examples = 160)	Loss: 0.642129
Step #30 (total examples = 240)	Loss: 0.964805
Step #40 (total examples = 320)	Loss: 0.720539
Step #50 (total examples = 400)	Loss: 0.589456
Step #60 (total examples = 480)	Loss: 0.232069
Step #70 (total examples = 560)	Loss: 0.229410
Step #80 (total examples = 640)	Loss: 0.590751
Step #90 (total examples = 720)	Loss: 0.296217
Step #100 (total examples = 800)	Loss: 0.094620
Step #110 (total examples = 880)	Loss: 0.325795
Step #120 (total examples = 960)	Loss: 0.408066
Step #130 (total examples = 1040)	Loss: 0.248128
Step #140 (total examples = 1120)	Loss: 0.131206
Step #150 (total examples = 1200)	Loss: 0.109813
Step #160 (total examples = 1280)	Loss: 0.277136
Step #170 (total examples = 1360)	Loss: 0.125383
Step #180 (total examples = 1440)	Loss: 0.220532
Step #190 (total examples = 1520)	Loss: 0.079709
Step #200 (total examples = 1600)	Loss: 0.374674
Step #210 (total examples = 1680)	Loss: 0.057024
Step #220 (total examples = 1760)	Loss: 0.397346
Step #230 (total examples = 1840)	Loss: 0.759779
Step #240 (total examples = 1920)	Loss: 0.207873
Step #250 (total examples = 2000)	Loss: 0.014965
Step #260 (total examples = 2080)	Loss: 0.750666
Step #270 (total examples = 2160)	Loss: 0.255463
Step #280 (total examples = 2240)	Loss: 0.056047
Step #290 (total examples = 2320)	Loss: 0.113571
Step #300 (total examples = 2400)	Loss: 1.030829
Step #310 (total examples = 2480)	Loss: 0.156585
Step #320 (total examples = 2560)	Loss: 1.048515
Step #330 (total examples = 2640)	Loss: 0.477115
Step #340 (total examples = 2720)	Loss: 0.031863
Step #350 (total examples = 2800)	Loss: 0.490812
Step #360 (total examples = 2880)	Loss: 0.059034
Step #370 (total examples = 2960)	Loss: 0.025518
Step #380 (total examples = 3040)	Loss: 0.022557
Step #390 (total examples = 3120)	Loss: 0.147265
Step #400 (total examples = 3200)	Loss: 0.193944
Step #410 (total examples = 3280)	Loss: 0.454350
Step #420 (total examples = 3360)	Loss: 0.067083
Step #430 (total examples = 3440)	Loss: 0.047618
Step #440 (total examples = 3520)	Loss: 0.847699
Step #450 (total examples = 3600)	Loss: 0.225541
Step #460 (total examples = 3680)	Loss: 0.070670
Step #470 (total examples = 3760)	Loss: 0.122334
Step #480 (total examples = 3840)	Loss: 0.027539
Step #490 (total examples = 3920)	Loss: 0.053746
Step #500 (total examples = 4000)	Loss: 0.189038
Step #510 (total examples = 4080)	Loss: 0.006562
Step #520 (total examples = 4160)	Loss: 0.220791
Step #530 (total examples = 4240)	Loss: 0.079325
Step #540 (total examples = 4320)	Loss: 0.007734
Step #550 (total examples = 4400)	Loss: 0.022373
Step #560 (total examples = 4480)	Loss: 0.094819
Step #570 (total examples = 4560)	Loss: 0.048453
Step #580 (total examples = 4640)	Loss: 0.065734
Step #590 (total examples = 4720)	Loss: 0.017806
Step #600 (total examples = 4800)	Loss: 0.302080
Step #610 (total examples = 4880)	Loss: 0.394593
Step #620 (total examples = 4960)	Loss: 0.047135
Step #630 (total examples = 5040)	Loss: 0.053847
Step #640 (total examples = 5120)	Loss: 0.034399
Step #650 (total examples = 5200)	Loss: 0.259621
Step #660 (total examples = 5280)	Loss: 0.007872
Step #670 (total examples = 5360)	Loss: 0.059141
Step #680 (total examples = 5440)	Loss: 0.317564
Step #690 (total examples = 5520)	Loss: 0.080710
Step #700 (total examples = 5600)	Loss: 0.009482
Step #710 (total examples = 5680)	Loss: 0.184977
Step #720 (total examples = 5760)	Loss: 0.049579
Step #730 (total examples = 5840)	Loss: 1.199213
Step #740 (total examples = 5920)	Loss: 0.084349
Step #750 (total examples = 6000)	Loss: 0.604405
Step #760 (total examples = 6080)	Loss: 0.016406
Step #770 (total examples = 6160)	Loss: 0.139643
Step #780 (total examples = 6240)	Loss: 0.361597
Step #790 (total examples = 6320)	Loss: 0.045089
Step #800 (total examples = 6400)	Loss: 0.449661
Step #810 (total examples = 6480)	Loss: 0.187957
Step #820 (total examples = 6560)	Loss: 0.023486
Step #830 (total examples = 6640)	Loss: 0.018382
Step #840 (total examples = 6720)	Loss: 0.192798
Step #850 (total examples = 6800)	Loss: 0.070009
Step #860 (total examples = 6880)	Loss: 0.041303
Step #870 (total examples = 6960)	Loss: 0.015959
Step #880 (total examples = 7040)	Loss: 0.018315
Step #890 (total examples = 7120)	Loss: 0.217954
Step #900 (total examples = 7200)	Loss: 0.053746
Step #910 (total examples = 7280)	Loss: 0.080294
Step #920 (total examples = 7360)	Loss: 0.132583
Step #930 (total examples = 7440)	Loss: 0.008917
Step #940 (total examples = 7520)	Loss: 0.032010
Step #950 (total examples = 7600)	Loss: 1.090929
Step #960 (total examples = 7680)	Loss: 0.001307
Step #970 (total examples = 7760)	Loss: 0.085828
Step #980 (total examples = 7840)	Loss: 0.241913
Step #990 (total examples = 7920)	Loss: 0.136883
Step #1000 (total examples = 8000)	Loss: 0.134027
Step #1010 (total examples = 8080)	Loss: 0.156006
Step #1020 (total examples = 8160)	Loss: 0.267229
Step #1030 (total examples = 8240)	Loss: 0.057724
Step #1040 (total examples = 8320)	Loss: 0.093877
Step #1050 (total examples = 8400)	Loss: 0.011063
Step #1060 (total examples = 8480)	Loss: 0.046295
Step #1070 (total examples = 8560)	Loss: 0.262599
Step #1080 (total examples = 8640)	Loss: 0.401597
Step #1090 (total examples = 8720)	Loss: 0.005816
Step #1100 (total examples = 8800)	Loss: 0.489956
Step #1110 (total examples = 8880)	Loss: 0.087653
Step #1120 (total examples = 8960)	Loss: 0.009044
Step #1130 (total examples = 9040)	Loss: 0.010017
Step #1140 (total examples = 9120)	Loss: 0.113593
Step #1150 (total examples = 9200)	Loss: 0.555308
Step #1160 (total examples = 9280)	Loss: 0.010577
Step #1170 (total examples = 9360)	Loss: 0.094290
Step #1180 (total examples = 9440)	Loss: 0.114725
Step #1190 (total examples = 9520)	Loss: 0.014288
Step #1200 (total examples = 9600)	Loss: 0.004581
Step #1210 (total examples = 9680)	Loss: 0.014513
Step #1220 (total examples = 9760)	Loss: 0.080056
Step #1230 (total examples = 9840)	Loss: 0.166943
Step #1240 (total examples = 9920)	Loss: 0.124220
Step #1250 (total examples = 10000)	Loss: 0.004495
Step #1260 (total examples = 10080)	Loss: 0.142709
Step #1270 (total examples = 10160)	Loss: 0.158390
Step #1280 (total examples = 10240)	Loss: 0.002461
Step #1290 (total examples = 10320)	Loss: 0.160110
Step #1300 (total examples = 10400)	Loss: 0.001718
Step #1310 (total examples = 10480)	Loss: 0.003811
Step #1320 (total examples = 10560)	Loss: 0.004717
Step #1330 (total examples = 10640)	Loss: 0.004955
Step #1340 (total examples = 10720)	Loss: 0.029100
Step #1350 (total examples = 10800)	Loss: 0.095073
Step #1360 (total examples = 10880)	Loss: 0.003488
Step #1370 (total examples = 10960)	Loss: 0.050891
Step #1380 (total examples = 11040)	Loss: 0.194317
Step #1390 (total examples = 11120)	Loss: 0.063220
Step #1400 (total examples = 11200)	Loss: 0.039572
Step #1410 (total examples = 11280)	Loss: 0.012718
Step #1420 (total examples = 11360)	Loss: 0.005121
Step #1430 (total examples = 11440)	Loss: 0.239218
Step #1440 (total examples = 11520)	Loss: 0.100418
Step #1450 (total examples = 11600)	Loss: 0.001055
Step #1460 (total examples = 11680)	Loss: 0.005982
Step #1470 (total examples = 11760)	Loss: 0.002160
Step #1480 (total examples = 11840)	Loss: 0.120209
Step #1490 (total examples = 11920)	Loss: 0.082318
Step #1500 (total examples = 12000)	Loss: 0.006569
Step #1510 (total examples = 12080)	Loss: 0.013440
Step #1520 (total examples = 12160)	Loss: 0.052152
Step #1530 (total examples = 12240)	Loss: 0.012295
Step #1540 (total examples = 12320)	Loss: 0.113301
Step #1550 (total examples = 12400)	Loss: 0.001879
Step #1560 (total examples = 12480)	Loss: 0.000180
Step #1570 (total examples = 12560)	Loss: 0.194700
Step #1580 (total examples = 12640)	Loss: 0.009079
Step #1590 (total examples = 12720)	Loss: 0.001886
Step #1600 (total examples = 12800)	Loss: 0.266672
Step #1610 (total examples = 12880)	Loss: 0.037237
Step #1620 (total examples = 12960)	Loss: 0.012004
Step #1630 (total examples = 13040)	Loss: 0.071253
Step #1640 (total examples = 13120)	Loss: 0.005234
Step #1640 (total examples = 13120)	Loss: 0.510043
Step #1650 (total examples = 13200)	Loss: 0.075568
Step #1660 (total examples = 13280)	Loss: 0.005596
Step #1670 (total examples = 13360)	Loss: 0.157148
Step #1680 (total examples = 13440)	Loss: 0.136121
Step #1690 (total examples = 13520)	Loss: 0.019119
Step #1700 (total examples = 13600)	Loss: 0.010197
Step #1710 (total examples = 13680)	Loss: 0.017104
Step #1720 (total examples = 13760)	Loss: 0.027085
Step #1730 (total examples = 13840)	Loss: 0.020062
Step #1740 (total examples = 13920)	Loss: 0.650296
Step #1750 (total examples = 14000)	Loss: 0.051925
Step #1760 (total examples = 14080)	Loss: 0.052325
Step #1770 (total examples = 14160)	Loss: 0.000270
Step #1780 (total examples = 14240)	Loss: 0.122130
Step #1790 (total examples = 14320)	Loss: 0.002324
Step #1800 (total examples = 14400)	Loss: 0.006901
Step #1810 (total examples = 14480)	Loss: 0.000530
Step #1820 (total examples = 14560)	Loss: 0.040072
Step #1830 (total examples = 14640)	Loss: 0.794057
Step #1840 (total examples = 14720)	Loss: 0.008265
Step #1850 (total examples = 14800)	Loss: 0.000666
Step #1860 (total examples = 14880)	Loss: 0.128151
Step #1870 (total examples = 14960)	Loss: 0.002250
Step #1880 (total examples = 15040)	Loss: 0.004138
Step #1890 (total examples = 15120)	Loss: 1.129246
Step #1900 (total examples = 15200)	Loss: 0.295612
Step #1910 (total examples = 15280)	Loss: 0.103094
Step #1920 (total examples = 15360)	Loss: 0.074605
Step #1930 (total examples = 15440)	Loss: 0.005264
Step #1940 (total examples = 15520)	Loss: 0.045944
Step #1950 (total examples = 15600)	Loss: 0.004163
Step #1960 (total examples = 15680)	Loss: 0.189294
Step #1970 (total examples = 15760)	Loss: 0.149948
Step #1980 (total examples = 15840)	Loss: 0.127823
Step #1990 (total examples = 15920)	Loss: 0.003615
Step #2000 (total examples = 16000)	Loss: 0.004108
Step #2010 (total examples = 16080)	Loss: 0.464324
Step #2020 (total examples = 16160)	Loss: 0.001995
Step #2030 (total examples = 16240)	Loss: 0.142903
Step #2040 (total examples = 16320)	Loss: 0.285426
Step #2050 (total examples = 16400)	Loss: 0.001192
Step #2060 (total examples = 16480)	Loss: 0.007188
Step #2070 (total examples = 16560)	Loss: 0.037480
Step #2080 (total examples = 16640)	Loss: 0.037883
Step #2090 (total examples = 16720)	Loss: 0.000177
Step #2100 (total examples = 16800)	Loss: 0.064370
Step #2110 (total examples = 16880)	Loss: 0.000616
Step #2120 (total examples = 16960)	Loss: 0.047753
Step #2130 (total examples = 17040)	Loss: 0.005832
Step #2140 (total examples = 17120)	Loss: 0.064829
Step #2150 (total examples = 17200)	Loss: 0.029793
Step #2160 (total examples = 17280)	Loss: 0.006323
Step #2170 (total examples = 17360)	Loss: 0.002859
Step #2180 (total examples = 17440)	Loss: 0.017508
Step #2190 (total examples = 17520)	Loss: 0.029875
Step #2200 (total examples = 17600)	Loss: 0.027353
Step #2210 (total examples = 17680)	Loss: 0.304048
Step #2220 (total examples = 17760)	Loss: 0.019586
Step #2230 (total examples = 17840)	Loss: 0.332719
Step #2240 (total examples = 17920)	Loss: 0.000058
Step #2250 (total examples = 18000)	Loss: 0.156007
Step #2260 (total examples = 18080)	Loss: 0.383425
Step #2270 (total examples = 18160)	Loss: 0.007705
Step #2280 (total examples = 18240)	Loss: 0.059558
Step #2290 (total examples = 18320)	Loss: 0.002548
Step #2300 (total examples = 18400)	Loss: 0.067628
Step #2310 (total examples = 18480)	Loss: 0.003881
Step #2320 (total examples = 18560)	Loss: 0.199132
Step #2330 (total examples = 18640)	Loss: 0.266500
Step #2340 (total examples = 18720)	Loss: 0.025147
Step #2350 (total examples = 18800)	Loss: 0.010761
Step #2360 (total examples = 18880)	Loss: 0.040273
Step #2370 (total examples = 18960)	Loss: 0.008383
Step #2380 (total examples = 19040)	Loss: 0.074363
Step #2390 (total examples = 19120)	Loss: 0.449648
Step #2400 (total examples = 19200)	Loss: 0.349697
Step #2410 (total examples = 19280)	Loss: 0.068878
Step #2420 (total examples = 19360)	Loss: 0.019429
Step #2430 (total examples = 19440)	Loss: 0.011100
Step #2440 (total examples = 19520)	Loss: 0.008722
Step #2450 (total examples = 19600)	Loss: 0.158677
Step #2460 (total examples = 19680)	Loss: 0.104765
Step #2470 (total examples = 19760)	Loss: 0.020186
Step #2480 (total examples = 19840)	Loss: 0.001199
Step #2490 (total examples = 19920)	Loss: 0.143956
Step #2500 (total examples = 20000)	Loss: 0.000621
Step #2510 (total examples = 20080)	Loss: 0.012960
Step #2520 (total examples = 20160)	Loss: 0.013258
Step #2530 (total examples = 20240)	Loss: 0.001280
Step #2540 (total examples = 20320)	Loss: 0.022567
Step #2550 (total examples = 20400)	Loss: 0.179881
Step #2560 (total examples = 20480)	Loss: 0.062638
Step #2570 (total examples = 20560)	Loss: 0.025856
Step #2580 (total examples = 20640)	Loss: 0.003176
Step #2590 (total examples = 20720)	Loss: 0.003075
Step #2600 (total examples = 20800)	Loss: 0.003718
Step #2610 (total examples = 20880)	Loss: 0.000302
Step #2620 (total examples = 20960)	Loss: 0.039807
Step #2630 (total examples = 21040)	Loss: 0.024426
Step #2640 (total examples = 21120)	Loss: 0.012475
Step #2650 (total examples = 21200)	Loss: 0.008714
Step #2660 (total examples = 21280)	Loss: 0.000608
Step #2670 (total examples = 21360)	Loss: 0.027610
Step #2680 (total examples = 21440)	Loss: 0.449732
Step #2690 (total examples = 21520)	Loss: 0.033262
Step #2700 (total examples = 21600)	Loss: 0.003773
Step #2710 (total examples = 21680)	Loss: 0.033019
Step #2720 (total examples = 21760)	Loss: 0.001508
Step #2730 (total examples = 21840)	Loss: 0.008272
Step #2740 (total examples = 21920)	Loss: 0.019946
Step #2750 (total examples = 22000)	Loss: 0.094933
Step #2760 (total examples = 22080)	Loss: 0.000535
Step #2770 (total examples = 22160)	Loss: 0.042846
Step #2780 (total examples = 22240)	Loss: 0.050828
Step #2790 (total examples = 22320)	Loss: 0.005595
Step #2800 (total examples = 22400)	Loss: 0.152659
Step #2810 (total examples = 22480)	Loss: 0.065314
Step #2820 (total examples = 22560)	Loss: 0.253004
Step #2830 (total examples = 22640)	Loss: 0.075534
Step #2840 (total examples = 22720)	Loss: 0.005486
Step #2850 (total examples = 22800)	Loss: 0.190548
Step #2860 (total examples = 22880)	Loss: 0.019416
Step #2870 (total examples = 22960)	Loss: 0.139345
Step #2880 (total examples = 23040)	Loss: 0.116535
Step #2890 (total examples = 23120)	Loss: 0.078231
Step #2900 (total examples = 23200)	Loss: 0.000716
Step #2910 (total examples = 23280)	Loss: 0.119993
Step #2920 (total examples = 23360)	Loss: 0.140492
Step #2930 (total examples = 23440)	Loss: 0.011475
Step #2940 (total examples = 23520)	Loss: 0.001698
Step #2950 (total examples = 23600)	Loss: 0.228715
Step #2960 (total examples = 23680)	Loss: 0.248843
Step #2970 (total examples = 23760)	Loss: 0.019246
Step #2980 (total examples = 23840)	Loss: 0.011857
Step #2990 (total examples = 23920)	Loss: 0.002542
Step #3000 (total examples = 24000)	Loss: 0.231914
Step #3010 (total examples = 24080)	Loss: 0.022623
Step #3020 (total examples = 24160)	Loss: 0.127338
Step #3030 (total examples = 24240)	Loss: 0.003643
Step #3040 (total examples = 24320)	Loss: 0.006993
Step #3050 (total examples = 24400)	Loss: 0.021681
Step #3060 (total examples = 24480)	Loss: 0.003457
Step #3070 (total examples = 24560)	Loss: 0.162763
Step #3080 (total examples = 24640)	Loss: 0.075871
Step #3090 (total examples = 24720)	Loss: 0.000257
Step #3100 (total examples = 24800)	Loss: 0.064989
Step #3110 (total examples = 24880)	Loss: 0.016700
Step #3120 (total examples = 24960)	Loss: 0.004708
Step #3130 (total examples = 25040)	Loss: 0.020084
Step #3140 (total examples = 25120)	Loss: 0.019796
Step #3150 (total examples = 25200)	Loss: 0.001082
Step #3160 (total examples = 25280)	Loss: 0.001084
Step #3170 (total examples = 25360)	Loss: 0.003823
Step #3180 (total examples = 25440)	Loss: 0.185054
Step #3190 (total examples = 25520)	Loss: 0.003329
Step #3200 (total examples = 25600)	Loss: 0.007908
Step #3210 (total examples = 25680)	Loss: 0.001423
Step #3220 (total examples = 25760)	Loss: 0.000129
Step #3230 (total examples = 25840)	Loss: 0.797607
Step #3240 (total examples = 25920)	Loss: 0.200765
Step #1650 (total examples = 13200)	Loss: 0.458731
Step #1660 (total examples = 13280)	Loss: 0.092527
Step #1670 (total examples = 13360)	Loss: 0.240056
Step #1680 (total examples = 13440)	Loss: 0.024070
Step #1690 (total examples = 13520)	Loss: 0.173096
Step #1700 (total examples = 13600)	Loss: 0.126917
Step #1710 (total examples = 13680)	Loss: 0.060429
Step #1720 (total examples = 13760)	Loss: 0.000808
Step #1730 (total examples = 13840)	Loss: 0.364006
Step #1740 (total examples = 13920)	Loss: 0.036802
Step #1750 (total examples = 14000)	Loss: 0.021542
Step #1760 (total examples = 14080)	Loss: 0.000345
Step #1770 (total examples = 14160)	Loss: 0.003598
Step #1780 (total examples = 14240)	Loss: 0.028049
Step #1790 (total examples = 14320)	Loss: 0.000736
Step #1800 (total examples = 14400)	Loss: 0.049635
Step #1810 (total examples = 14480)	Loss: 0.000229
Step #1820 (total examples = 14560)	Loss: 0.001919
Step #1830 (total examples = 14640)	Loss: 0.215916
Step #1840 (total examples = 14720)	Loss: 0.111210
Step #1850 (total examples = 14800)	Loss: 0.011817
Step #1860 (total examples = 14880)	Loss: 0.140237
Step #1870 (total examples = 14960)	Loss: 0.002171
Step #1880 (total examples = 15040)	Loss: 0.028434
Step #1890 (total examples = 15120)	Loss: 0.002194
Step #1900 (total examples = 15200)	Loss: 0.322018
Step #1910 (total examples = 15280)	Loss: 0.170274
Step #1920 (total examples = 15360)	Loss: 0.508430
Step #1930 (total examples = 15440)	Loss: 0.067791
Step #1940 (total examples = 15520)	Loss: 0.566694
Step #1950 (total examples = 15600)	Loss: 0.494778
Step #1960 (total examples = 15680)	Loss: 0.003169
Step #1970 (total examples = 15760)	Loss: 0.050315
Step #1980 (total examples = 15840)	Loss: 0.007015
Step #1990 (total examples = 15920)	Loss: 0.015225
Step #2000 (total examples = 16000)	Loss: 0.027276
Step #2010 (total examples = 16080)	Loss: 0.633936
Step #2020 (total examples = 16160)	Loss: 0.008191
Step #2030 (total examples = 16240)	Loss: 0.000110
Step #2040 (total examples = 16320)	Loss: 0.027235
Step #2050 (total examples = 16400)	Loss: 0.004891
Step #2060 (total examples = 16480)	Loss: 0.017783
Step #2070 (total examples = 16560)	Loss: 0.232705
Step #2080 (total examples = 16640)	Loss: 0.001875
Step #2090 (total examples = 16720)	Loss: 0.010929
Step #2100 (total examples = 16800)	Loss: 0.186138
Step #2110 (total examples = 16880)	Loss: 0.052676
Step #2120 (total examples = 16960)	Loss: 0.047043
Step #2130 (total examples = 17040)	Loss: 0.017084
Step #2140 (total examples = 17120)	Loss: 0.008561
Step #2150 (total examples = 17200)	Loss: 0.131512
Step #2160 (total examples = 17280)	Loss: 0.063839
Step #2170 (total examples = 17360)	Loss: 0.085726
Step #2180 (total examples = 17440)	Loss: 0.001738
Step #2190 (total examples = 17520)	Loss: 0.034066
Step #2200 (total examples = 17600)	Loss: 0.000349
Step #2210 (total examples = 17680)	Loss: 0.000065
Step #2220 (total examples = 17760)	Loss: 0.024680
Step #2230 (total examples = 17840)	Loss: 0.003506
Step #2240 (total examples = 17920)	Loss: 0.025059
Step #2250 (total examples = 18000)	Loss: 0.016217
Step #2260 (total examples = 18080)	Loss: 0.003990
Step #2270 (total examples = 18160)	Loss: 0.049799
Step #2280 (total examples = 18240)	Loss: 0.004313
Step #2290 (total examples = 18320)	Loss: 0.002326
Step #2300 (total examples = 18400)	Loss: 0.000739
Step #2310 (total examples = 18480)	Loss: 0.002373
Step #2320 (total examples = 18560)	Loss: 1.275268
Step #2330 (total examples = 18640)	Loss: 0.131500
Step #2340 (total examples = 18720)	Loss: 0.015154
Step #2350 (total examples = 18800)	Loss: 0.026867
Step #2360 (total examples = 18880)	Loss: 0.123594
Step #2370 (total examples = 18960)	Loss: 0.030887
Step #2380 (total examples = 19040)	Loss: 0.602608
Step #2390 (total examples = 19120)	Loss: 0.020889
Step #2400 (total examples = 19200)	Loss: 0.077563
Step #2410 (total examples = 19280)	Loss: 0.022801
Step #2420 (total examples = 19360)	Loss: 0.625871
Step #2430 (total examples = 19440)	Loss: 0.350801
Step #2440 (total examples = 19520)	Loss: 0.174826
Step #2450 (total examples = 19600)	Loss: 0.009069
Step #2460 (total examples = 19680)	Loss: 0.020238
Step #2470 (total examples = 19760)	Loss: 0.314162
Step #2480 (total examples = 19840)	Loss: 0.002486
Step #2490 (total examples = 19920)	Loss: 0.502877
Step #2500 (total examples = 20000)	Loss: 0.654853
Step #2510 (total examples = 20080)	Loss: 0.006648
Step #2520 (total examples = 20160)	Loss: 0.012942
Step #2530 (total examples = 20240)	Loss: 0.001201
Step #2540 (total examples = 20320)	Loss: 0.003020
Step #2550 (total examples = 20400)	Loss: 0.002582
Step #2560 (total examples = 20480)	Loss: 0.001343
Step #2570 (total examples = 20560)	Loss: 0.000446
Step #2580 (total examples = 20640)	Loss: 0.020092
Step #2590 (total examples = 20720)	Loss: 0.009076
Step #2600 (total examples = 20800)	Loss: 0.008773
Step #2610 (total examples = 20880)	Loss: 0.025713
Step #2620 (total examples = 20960)	Loss: 0.046578
Step #2630 (total examples = 21040)	Loss: 0.013964
Step #2640 (total examples = 21120)	Loss: 0.014930
Step #2650 (total examples = 21200)	Loss: 0.606353
Step #2660 (total examples = 21280)	Loss: 0.007448
Step #2670 (total examples = 21360)	Loss: 0.001429
Step #2680 (total examples = 21440)	Loss: 0.102170
Step #2690 (total examples = 21520)	Loss: 0.181153
Step #2700 (total examples = 21600)	Loss: 0.119749
Step #2710 (total examples = 21680)	Loss: 0.040832
Step #2720 (total examples = 21760)	Loss: 0.000908
Step #2730 (total examples = 21840)	Loss: 0.019844
Step #2740 (total examples = 21920)	Loss: 0.124926
Step #2750 (total examples = 22000)	Loss: 0.008050
Step #2760 (total examples = 22080)	Loss: 0.044031
Step #2770 (total examples = 22160)	Loss: 0.076560
Step #2780 (total examples = 22240)	Loss: 0.006716
Step #2790 (total examples = 22320)	Loss: 0.041037
Step #2800 (total examples = 22400)	Loss: 0.016296
Step #2810 (total examples = 22480)	Loss: 0.400808
Step #2820 (total examples = 22560)	Loss: 0.011579
Step #2830 (total examples = 22640)	Loss: 0.015588
Step #2840 (total examples = 22720)	Loss: 0.091441
Step #2850 (total examples = 22800)	Loss: 0.016603
Step #2860 (total examples = 22880)	Loss: 0.015609
Step #2870 (total examples = 22960)	Loss: 0.070698
Step #2880 (total examples = 23040)	Loss: 0.104797
Step #2890 (total examples = 23120)	Loss: 0.006455
Step #2900 (total examples = 23200)	Loss: 0.000743
Step #2910 (total examples = 23280)	Loss: 0.021608
Step #2920 (total examples = 23360)	Loss: 0.075365
Step #2930 (total examples = 23440)	Loss: 0.002741
Step #2940 (total examples = 23520)	Loss: 0.019192
Step #2950 (total examples = 23600)	Loss: 0.696840
Step #2960 (total examples = 23680)	Loss: 0.008698
Step #2970 (total examples = 23760)	Loss: 0.377933
Step #2980 (total examples = 23840)	Loss: 0.023338
Step #2990 (total examples = 23920)	Loss: 0.022332
Step #3000 (total examples = 24000)	Loss: 0.000769
Step #3010 (total examples = 24080)	Loss: 0.002470
Step #3020 (total examples = 24160)	Loss: 0.015818
Step #3030 (total examples = 24240)	Loss: 0.005847
Step #3040 (total examples = 24320)	Loss: 0.744282
Step #3050 (total examples = 24400)	Loss: 0.058341
Step #3060 (total examples = 24480)	Loss: 0.003316
Step #3070 (total examples = 24560)	Loss: 0.002198
Step #3080 (total examples = 24640)	Loss: 0.000759
Step #3090 (total examples = 24720)	Loss: 0.135939
Step #3100 (total examples = 24800)	Loss: 0.010564
Step #3110 (total examples = 24880)	Loss: 0.021763
Step #3120 (total examples = 24960)	Loss: 0.293309
Step #3130 (total examples = 25040)	Loss: 0.001739
Step #3140 (total examples = 25120)	Loss: 0.540329
Step #3150 (total examples = 25200)	Loss: 0.054836
Step #3160 (total examples = 25280)	Loss: 0.985507
Step #3170 (total examples = 25360)	Loss: 0.054106
Step #3180 (total examples = 25440)	Loss: 0.120285
Step #3190 (total examples = 25520)	Loss: 0.044377
Step #3200 (total examples = 25600)	Loss: 0.143127
Step #3210 (total examples = 25680)	Loss: 0.003385
Step #3220 (total examples = 25760)	Loss: 0.234380
Step #3230 (total examples = 25840)	Loss: 0.064877
Step #3240 (total examples = 25920)	Loss: 0.003784
Step #3250 (total examples = 26000)	Loss: 0.001990
Step #3260 (total examples = 26080)	Loss: 0.000331
Step #3270 (total examples = 26160)	Loss: 0.007668
Step #3280 (total examples = 26240)	Loss: 0.001711
Step #3290 (total examples = 26320)	Loss: 0.000421
Step #3300 (total examples = 26400)	Loss: 0.026878
Step #3310 (total examples = 26480)	Loss: 0.078986
Step #3320 (total examples = 26560)	Loss: 0.004659
Step #3330 (total examples = 26640)	Loss: 0.204734
Step #3340 (total examples = 26720)	Loss: 0.124011
Step #3350 (total examples = 26800)	Loss: 0.002272
Step #3360 (total examples = 26880)	Loss: 0.012441
Step #3370 (total examples = 26960)	Loss: 0.000559
Step #3380 (total examples = 27040)	Loss: 0.005402
Step #3390 (total examples = 27120)	Loss: 0.002217
Step #3400 (total examples = 27200)	Loss: 0.018292
Step #3410 (total examples = 27280)	Loss: 0.006798
Step #3420 (total examples = 27360)	Loss: 0.090490
Step #3430 (total examples = 27440)	Loss: 0.009047
Step #3440 (total examples = 27520)	Loss: 0.462029
Step #3450 (total examples = 27600)	Loss: 0.001538
Step #3460 (total examples = 27680)	Loss: 0.105847
Step #3470 (total examples = 27760)	Loss: 0.101834
Step #3480 (total examples = 27840)	Loss: 0.000375
Step #3490 (total examples = 27920)	Loss: 0.064260
Step #3500 (total examples = 28000)	Loss: 0.000702
Step #3510 (total examples = 28080)	Loss: 0.001966
Step #3520 (total examples = 28160)	Loss: 0.000056
Step #3530 (total examples = 28240)	Loss: 0.615726
Step #3540 (total examples = 28320)	Loss: 0.403097
Step #3550 (total examples = 28400)	Loss: 0.055197
Step #3560 (total examples = 28480)	Loss: 0.000714
Step #3570 (total examples = 28560)	Loss: 0.020128
Step #3580 (total examples = 28640)	Loss: 0.061381
Step #3590 (total examples = 28720)	Loss: 0.023652
Step #3600 (total examples = 28800)	Loss: 0.000397
Step #3610 (total examples = 28880)	Loss: 0.417086
Step #3620 (total examples = 28960)	Loss: 0.000009
Step #3630 (total examples = 29040)	Loss: 0.009737
Step #3640 (total examples = 29120)	Loss: 0.352938
Step #3650 (total examples = 29200)	Loss: 0.305876
Step #3660 (total examples = 29280)	Loss: 0.014606
Step #3670 (total examples = 29360)	Loss: 0.000174
Step #3680 (total examples = 29440)	Loss: 0.000651
Step #3690 (total examples = 29520)	Loss: 0.000274
Step #3700 (total examples = 29600)	Loss: 0.021474
Step #3710 (total examples = 29680)	Loss: 0.003154
Step #3720 (total examples = 29760)	Loss: 0.001354
Step #3730 (total examples = 29840)	Loss: 0.005275
Step #3740 (total examples = 29920)	Loss: 0.062380
Step #3750 (total examples = 30000)	Loss: 0.458417
Step #3760 (total examples = 30080)	Loss: 0.867872
Step #3770 (total examples = 30160)	Loss: 0.001111
Step #3780 (total examples = 30240)	Loss: 0.011796
Step #3790 (total examples = 30320)	Loss: 0.005524
Step #3800 (total examples = 30400)	Loss: 0.404179
Step #3810 (total examples = 30480)	Loss: 0.009253
Step #3820 (total examples = 30560)	Loss: 0.012803
Step #3830 (total examples = 30640)	Loss: 0.004818
Step #3840 (total examples = 30720)	Loss: 0.009994
Step #3850 (total examples = 30800)	Loss: 0.000441
Step #3860 (total examples = 30880)	Loss: 0.000798
Step #3870 (total examples = 30960)	Loss: 0.276029
Step #3880 (total examples = 31040)	Loss: 0.000479
Step #3890 (total examples = 31120)	Loss: 0.214559
Step #3900 (total examples = 31200)	Loss: 0.241798
Step #3910 (total examples = 31280)	Loss: 0.044619
Step #3920 (total examples = 31360)	Loss: 0.176024
Step #3930 (total examples = 31440)	Loss: 0.154504
Step #3940 (total examples = 31520)	Loss: 0.188771
Step #3950 (total examples = 31600)	Loss: 0.001257
Step #3960 (total examples = 31680)	Loss: 0.001534
Step #3970 (total examples = 31760)	Loss: 0.012405
Step #3980 (total examples = 31840)	Loss: 0.000070
Step #3990 (total examples = 31920)	Loss: 0.052527

Step #3250 (total examples = 26000)	Loss: 0.330795
Step #3260 (total examples = 26080)	Loss: 0.001626
Step #3270 (total examples = 26160)	Loss: 0.123490
Step #3280 (total examples = 26240)	Loss: 0.008939
Step #3290 (total examples = 26320)	Loss: 0.000533
Step #3300 (total examples = 26400)	Loss: 0.000342
Step #3310 (total examples = 26480)	Loss: 0.002690
Step #3320 (total examples = 26560)	Loss: 0.003672
Step #3330 (total examples = 26640)	Loss: 0.000822
Step #3340 (total examples = 26720)	Loss: 0.025688
Step #3350 (total examples = 26800)	Loss: 0.001395
Step #3360 (total examples = 26880)	Loss: 0.004159
Step #3370 (total examples = 26960)	Loss: 0.020543
Step #3380 (total examples = 27040)	Loss: 0.005243
Step #3390 (total examples = 27120)	Loss: 0.001685
Step #3400 (total examples = 27200)	Loss: 0.120131
Step #3410 (total examples = 27280)	Loss: 0.014448
Step #3420 (total examples = 27360)	Loss: 0.130796
Step #3430 (total examples = 27440)	Loss: 0.000363
Step #3440 (total examples = 27520)	Loss: 0.092354
Step #3450 (total examples = 27600)	Loss: 0.404130
Step #3460 (total examples = 27680)	Loss: 0.007868
Step #3470 (total examples = 27760)	Loss: 0.071156
Step #3480 (total examples = 27840)	Loss: 0.047980
Step #3490 (total examples = 27920)	Loss: 0.001818
Step #3500 (total examples = 28000)	Loss: 0.002538
Step #3510 (total examples = 28080)	Loss: 0.017070
Step #3520 (total examples = 28160)	Loss: 0.022897
Step #3530 (total examples = 28240)	Loss: 0.106292
Step #3540 (total examples = 28320)	Loss: 0.000015
Step #3550 (total examples = 28400)	Loss: 0.055968
Step #3560 (total examples = 28480)	Loss: 0.002245
Step #3570 (total examples = 28560)	Loss: 0.002266
Step #3580 (total examples = 28640)	Loss: 0.000136
Step #3590 (total examples = 28720)	Loss: 0.107602
Step #3600 (total examples = 28800)	Loss: 0.002829
Step #3610 (total examples = 28880)	Loss: 0.004723
Step #3620 (total examples = 28960)	Loss: 0.006562
Step #3630 (total examples = 29040)	Loss: 0.000570
Step #3640 (total examples = 29120)	Loss: 0.001884
Step #3650 (total examples = 29200)	Loss: 0.786890
Step #3660 (total examples = 29280)	Loss: 0.000342
Step #3670 (total examples = 29360)	Loss: 0.000372
Step #3680 (total examples = 29440)	Loss: 0.002588
Step #3690 (total examples = 29520)	Loss: 0.029665
Step #3700 (total examples = 29600)	Loss: 0.005910
Step #3710 (total examples = 29680)	Loss: 0.005637
Step #3720 (total examples = 29760)	Loss: 0.004947
Step #3730 (total examples = 29840)	Loss: 0.015875
Step #3740 (total examples = 29920)	Loss: 0.004031
Step #3750 (total examples = 30000)	Loss: 0.003230
Step #3760 (total examples = 30080)	Loss: 0.018863
Step #3770 (total examples = 30160)	Loss: 0.617261
Step #3780 (total examples = 30240)	Loss: 0.002480
Step #3790 (total examples = 30320)	Loss: 0.499511
Step #3800 (total examples = 30400)	Loss: 0.128237
Step #3810 (total examples = 30480)	Loss: 0.207276
Step #3820 (total examples = 30560)	Loss: 0.004016
Step #3830 (total examples = 30640)	Loss: 0.115259
Step #3840 (total examples = 30720)	Loss: 0.188030
Step #3850 (total examples = 30800)	Loss: 0.200561
Step #3860 (total examples = 30880)	Loss: 0.048104
Step #3870 (total examples = 30960)	Loss: 0.000465
Step #3880 (total examples = 31040)	Loss: 0.002826
Step #3890 (total examples = 31120)	Loss: 0.009083
Step #3900 (total examples = 31200)	Loss: 0.000254
Step #3910 (total examples = 31280)	Loss: 0.005388
Step #3920 (total examples = 31360)	Loss: 0.122852
Step #3930 (total examples = 31440)	Loss: 0.458138
Step #3940 (total examples = 31520)	Loss: 0.040298
Step #3950 (total examples = 31600)	Loss: 0.000085
Step #3960 (total examples = 31680)	Loss: 0.002160
Step #3970 (total examples = 31760)	Loss: 0.318555
Step #3980 (total examples = 31840)	Loss: 0.000565
Step #3990 (total examples = 31920)	Loss: 0.070292
  1/313 [..............................] - ETA: 1:47 - loss: 0.0000e+00 - accuracy: 1.0000  5/313 [..............................] - ETA: 4s - loss: 0.4106 - accuracy: 0.9875        9/313 [..............................] - ETA: 4s - loss: 4.4449 - accuracy: 0.9861 13/313 [>.............................] - ETA: 4s - loss: 5.1980 - accuracy: 0.9856 17/313 [>.............................] - ETA: 4s - loss: 5.5399 - accuracy: 0.9835 21/313 [=>............................] - ETA: 4s - loss: 7.2947 - accuracy: 0.9821 23/313 [=>............................] - ETA: 5s - loss: 10.2355 - accuracy: 0.9783 25/313 [=>............................] - ETA: 5s - loss: 10.1875 - accuracy: 0.9787 27/313 [=>............................] - ETA: 5s - loss: 9.6680 - accuracy: 0.9792  29/313 [=>............................] - ETA: 5s - loss: 9.5359 - accuracy: 0.9784 31/313 [=>............................] - ETA: 5s - loss: 10.7641 - accuracy: 0.9768 33/313 [==>...........................] - ETA: 6s - loss: 10.6775 - accuracy: 0.9754 35/313 [==>...........................] - ETA: 6s - loss: 11.1859 - accuracy: 0.9750 37/313 [==>...........................] - ETA: 6s - loss: 10.8211 - accuracy: 0.9755 39/313 [==>...........................] - ETA: 6s - loss: 12.2080 - accuracy: 0.9736 41/313 [==>...........................] - ETA: 6s - loss: 14.4664 - accuracy: 0.9733 43/313 [===>..........................] - ETA: 6s - loss: 14.9672 - accuracy: 0.9731 45/313 [===>..........................] - ETA: 6s - loss: 14.8203 - accuracy: 0.9729 47/313 [===>..........................] - ETA: 6s - loss: 14.8036 - accuracy: 0.9734 49/313 [===>..........................] - ETA: 6s - loss: 15.8958 - accuracy: 0.9726 51/313 [===>..........................] - ETA: 6s - loss: 15.4729 - accuracy: 0.9730 53/313 [====>.........................] - ETA: 6s - loss: 15.3702 - accuracy: 0.9729 56/313 [====>.........................] - ETA: 6s - loss: 16.6528 - accuracy: 0.9721 60/313 [====>.........................] - ETA: 6s - loss: 16.1917 - accuracy: 0.9734 64/313 [=====>........................] - ETA: 5s - loss: 15.4724 - accuracy: 0.9736 68/313 [=====>........................] - ETA: 5s - loss: 18.7653 - accuracy: 0.9720 72/313 [=====>........................] - ETA: 5s - loss: 18.3875 - accuracy: 0.9722 76/313 [======>.......................] - ETA: 5s - loss: 17.6535 - accuracy: 0.9729 80/313 [======>.......................] - ETA: 5s - loss: 17.9579 - accuracy: 0.9727 84/313 [=======>......................] - ETA: 5s - loss: 17.6545 - accuracy: 0.9732 87/313 [=======>......................] - ETA: 4s - loss: 17.2964 - accuracy: 0.9738 90/313 [=======>......................] - ETA: 4s - loss: 16.7532 - accuracy: 0.9743 93/313 [=======>......................] - ETA: 4s - loss: 17.7301 - accuracy: 0.9741 96/313 [========>.....................] - ETA: 4s - loss: 17.1768 - accuracy: 0.9746 99/313 [========>.....................] - ETA: 4s - loss: 16.6563 - accuracy: 0.9754102/313 [========>.....................] - ETA: 4s - loss: 16.4155 - accuracy: 0.9758106/313 [=========>....................] - ETA: 4s - loss: 16.1032 - accuracy: 0.9758110/313 [=========>....................] - ETA: 4s - loss: 15.9846 - accuracy: 0.9761114/313 [=========>....................] - ETA: 4s - loss: 16.2602 - accuracy: 0.9759118/313 [==========>...................] - ETA: 3s - loss: 16.1588 - accuracy: 0.9754122/313 [==========>...................] - ETA: 3s - loss: 17.1939 - accuracy: 0.9746126/313 [===========>..................] - ETA: 3s - loss: 17.7985 - accuracy: 0.9745130/313 [===========>..................] - ETA: 3s - loss: 17.3221 - accuracy: 0.9750134/313 [===========>..................] - ETA: 3s - loss: 17.6552 - accuracy: 0.9748138/313 [============>.................] - ETA: 3s - loss: 17.2220 - accuracy: 0.9749142/313 [============>.................] - ETA: 3s - loss: 17.0237 - accuracy: 0.9751146/313 [============>.................] - ETA: 3s - loss: 17.4167 - accuracy: 0.9745150/313 [=============>................] - ETA: 3s - loss: 17.4752 - accuracy: 0.9746154/313 [=============>................] - ETA: 3s - loss: 17.8225 - accuracy: 0.9742158/313 [==============>...............] - ETA: 2s - loss: 17.3713 - accuracy: 0.9749162/313 [==============>...............] - ETA: 2s - loss: 17.0757 - accuracy: 0.9753166/313 [==============>...............] - ETA: 2s - loss: 16.6709 - accuracy: 0.9755170/313 [===============>..............] - ETA: 2s - loss: 16.6179 - accuracy: 0.9759174/313 [===============>..............] - ETA: 2s - loss: 16.2359 - accuracy: 0.9765177/313 [===============>..............] - ETA: 2s - loss: 16.0902 - accuracy: 0.9765180/313 [================>.............] - ETA: 2s - loss: 15.8221 - accuracy: 0.9769183/313 [================>.............] - ETA: 2s - loss: 15.5708 - accuracy: 0.9771186/313 [================>.............] - ETA: 2s - loss: 15.7583 - accuracy: 0.9770189/313 [=================>............] - ETA: 2s - loss: 16.2518 - accuracy: 0.9765192/313 [=================>............] - ETA: 2s - loss: 16.0645 - accuracy: 0.9767195/313 [=================>............] - ETA: 2s - loss: 15.8174 - accuracy: 0.9771198/313 [=================>............] - ETA: 2s - loss: 15.5777 - accuracy: 0.9774201/313 [==================>...........] - ETA: 2s - loss: 15.3452 - accuracy: 0.9778204/313 [==================>...........] - ETA: 2s - loss: 15.2653 - accuracy: 0.9779207/313 [==================>...........] - ETA: 1s - loss: 15.4033 - accuracy: 0.9777210/313 [===================>..........] - ETA: 1s - loss: 15.4013 - accuracy: 0.9778213/313 [===================>..........] - ETA: 1s - loss: 15.2652 - accuracy: 0.9780216/313 [===================>..........] - ETA: 1s - loss: 15.0532 - accuracy: 0.9783219/313 [===================>..........] - ETA: 1s - loss: 14.8470 - accuracy: 0.9786222/313 [====================>.........] - ETA: 1s - loss: 14.6463 - accuracy: 0.9789225/313 [====================>.........] - ETA: 1s - loss: 14.4510 - accuracy: 0.9792228/313 [====================>.........] - ETA: 1s - loss: 14.2609 - accuracy: 0.9794231/313 [=====================>........] - ETA: 1s - loss: 14.0757 - accuracy: 0.9797234/313 [=====================>........] - ETA: 1s - loss: 13.8952 - accuracy: 0.9800237/313 [=====================>........] - ETA: 1s - loss: 13.7193 - accuracy: 0.9802240/313 [======================>.......] - ETA: 1s - loss: 13.5479 - accuracy: 0.9805243/313 [======================>.......] - ETA: 1s - loss: 13.3806 - accuracy: 0.9807246/313 [======================>.......] - ETA: 1s - loss: 13.2174 - accuracy: 0.9809249/313 [======================>.......] - ETA: 1s - loss: 13.0648 - accuracy: 0.9810252/313 [=======================>......] - ETA: 1s - loss: 12.9615 - accuracy: 0.9812255/313 [=======================>......] - ETA: 1s - loss: 12.9421 - accuracy: 0.9811258/313 [=======================>......] - ETA: 1s - loss: 12.7916 - accuracy: 0.9813261/313 [========================>.....] - ETA: 0s - loss: 12.6913 - accuracy: 0.9814265/313 [========================>.....] - ETA: 0s - loss: 12.5875 - accuracy: 0.9816269/313 [========================>.....] - ETA: 0s - loss: 12.5372 - accuracy: 0.9816272/313 [=========================>....] - ETA: 0s - loss: 12.3990 - accuracy: 0.9818275/313 [=========================>....] - ETA: 0s - loss: 12.2637 - accuracy: 0.9820278/313 [=========================>....] - ETA: 0s - loss: 12.1314 - accuracy: 0.9822281/313 [=========================>....] - ETA: 0s - loss: 12.0018 - accuracy: 0.9824284/313 [==========================>...] - ETA: 0s - loss: 12.4021 - accuracy: 0.9822287/313 [==========================>...] - ETA: 0s - loss: 12.2724 - accuracy: 0.9824290/313 [==========================>...] - ETA: 0s - loss: 12.1455 - accuracy: 0.9825294/313 [===========================>..] - ETA: 0s - loss: 11.9802 - accuracy: 0.9828298/313 [===========================>..] - ETA: 0s - loss: 11.8216 - accuracy: 0.9829302/313 [===========================>..] - ETA: 0s - loss: 11.7248 - accuracy: 0.9830306/313 [============================>.] - ETA: 0s - loss: 12.3787 - accuracy: 0.9828310/313 [============================>.] - ETA: 0s - loss: 12.3312 - accuracy: 0.9829313/313 [==============================] - 6s 18ms/step - loss: 12.3451 - accuracy: 0.9829
Final model accuracy: 0.982900
Total training time: 382.217118
